\section{Data preparation facility}

\subsection{Introduction}

[NEW: 31-Mar-2025] The data preparation facility has been revamped. The two
main changes is that the workflow has been converted from a Windows command file
to a GAMS file, and that the secondary aggregation, which used to be incorporated
in the data initialization phase of the model code, now occurs as part of the workflow.
The secondary aggregation is needed for cases when the resulting data aggregation
is no longer 'diagonal'. The filter program, which removes small numbers and is
described further below, requires a diagonal database.\footnote{We are working
to convert the filter program to handle non-diagonal databases.} Thus the user
first prepares an aggregation mapping file which aggregates the GTAP database
to a diagonal aggregated database. A subsequent mapping file, applied after the
filter routine, aggregates the intermediate and diagonal database to the
desired final database. N.B. The secondary aggregation is required even if
the final database is diagonal. This is due to the fact that the \textsc{Envisage}
model requires that the commodity labels differ from the activity labels (as they
are both subsets of a master set of SAM labels). The filter program explicitly
requires that the two sets of labels are identical (or aliased).

The data facility is composed of a number of modules.

\begin{enumerate}
   \item The first is the \emph{primary} aggregation facility. The
   aggregation facility is designed to work with any GTAP-conformable database, including the database produced by the aggregation facility. It reads a user-prepared map
         file that contains the aggregation mappings.
         The aggregation facility aggregates all relevant GTAP data files.
         The \emph{primary} aggregation must lead to a diagonal database for the next step,
         which is the filtering process.
   \item The second module is called the 'filter' module. First developed by Tom
         Rutherford for his 'GTAPinGAMS'
         project\footnote{\cite{LanzRutherfordJGEA2016}} and integrated into
         Wolfgang Britz's CGEBox framework\footnote{
         \url{http://www.ilr.uni-bonn.de/em/rsrch/cgebox/cgebox_GUI.pdf}},
         filtering is designed to remove small numeric values from the database
         that have minimal impact on data balances and model results. The
         'filter' program insures that the resulting database is nonetheless
         balanced. It currently only works with a diagonal GTAP database.
         Subsequent to the filtering routine, another procedure is invoked to
         adjust the emission and energy volume datasets to match the adjusted
         values in the filtered database.
   \item The third module is the \emph{secondary} aggregation facility. This enables
   the user to create a non-diagonal database (for example to collapse all the
   electricity commodities into a single stream). This step is required even if
   the user chooses not to change the aggregation as the \textsc{Envisage} models requires
   the commodity and activity labels to be differentiated. It uses the same code
   as for the \emph{primary} aggregation, but the user needs to provide
   an additional mapping file. The main difference between the \emph{primary} aggregation and
   the \emph{secondary} aggregation is that the latter saves both mapping sets as part of
   the resultant database, which can be used for documentation purposes.
   \item The fourth module is called the 'AlterTax' module. It is described in
         \cite{MalcolmGTAPTP12} and is a procedure to modify an initial GTAP
         database while minimizing changes to the structure of the original
         database. Though designed to change tax rates, it can be used to modify
         other features of a database. This module relies on the standard GTAP
         model itself, which is provided as part of the data preparation
         facility.
   \item The fifth module is optional and is used to aggregate the myriad
   elasticities for the \textsc{Envisage} model. These are originally from
   the OECD's 'circular' economy study---with additional mappings to conform
   to the dimensionality of the chosen GTAP datbase. This step is required to
   run the \textsc{Envisage} model, but not for other purposes.
   \item The sixth module is optional and is used to aggregate the projection
      database. This step is required to run dynamic simulations. The projections
      include the SSPs, various UN population projections, the World Bank GIDD projections
      and various WEO projections from the IMF.

\end{enumerate}

The outputs of each model are contained in different containers. The output from the
\emph{primary} aggregation facility is found in the 'Agg1' folder. The output of the filtering
procedure is found in the 'Flt' folder. The output from the
\emph{secondary} aggregation facility is found in the 'Agg1' folder. And the output of AlterTax is found in
the 'Alt' folder. The end results, assuming all has worked appropriately, will
be found in the 'Fnl' folder.

Each data project is associated with a code name, for example '10x10'. This code
name will be used for all output files and the aggregation facility will prepare
a folder in the 'Data' directory that is named using the code name. All output
folders will be contained in that directory.

\subsection{Preliminaries}

There are no proscribed ways to setup the directory structures for the various
components of Env11 so the setup below is just a suggestion. All of the
components rely on the user providing full path names so it should be flexible
enough to handle most user preferences. Figure~\ref{fig:DirStr} depicts a fairly
standard layout. The root directory is \emph{Env11} and it contains three
obligatory folders: \emph{Data}, \emph{SatAcct} and \emph{Model}. The first
contains the routines for aggregating and preparing the data for the model. It
also contains some sub-folders that will be further described below. The
\emph{SatAcct} contains miscellaneous data that is used by the aggregation
facility and eventually the model. Use of most of the satellite data is optional
and is user-specified. The \emph{Model} folder contains the core code for the
\textsc{Envisage} Model. The remaining folders are user folders and will contain
the files for single projects. Single projects can be identified with a specific
aggregation, different dynamic assumptions and/or a different focus.

\begin{figure}[H]
\center
\begin{forest}
for tree={
   minimum height=1cm,
   font=\scriptsize,
%  font=\sffamily,
   anchor=north,
   align=center,
   child anchor=north,
   s sep=1em,
   l sep=0.75cm
},
%where n children=0{tier=word}{}
[{Env11}, draw, drop shadow, fill=dkBlue, rounded corners=2pt, name=Root
   [{Data}, draw, drop shadow, fill=mdBlue, rounded corners=2pt, name=Data
      [{Filter}, draw, drop shadow, fill=ltBlue, rounded corners=2pt]
      [{Altertax}, draw, drop shadow, fill=ltBlue, rounded corners=2pt]
      [{GTAPModel}, draw, drop shadow, fill=ltBlue, rounded corners=2pt]
   ]
   [{SatAcct}, draw, drop shadow, fill=mdBlue, rounded corners=2pt, name=SatAcct]
   [{Model}, draw, drop shadow, fill=mdBlue, rounded corners=2pt, name=Model]
   [{Proj1}, draw, drop shadow, fill=ltBlue, rounded corners=2pt]
   [{Proj2}, draw, drop shadow, fill=ltBlue, rounded corners=2pt]
   [{$\dots$}, draw, drop shadow, fill=ltBlue, rounded corners=2pt]
   [{Projn}, draw, drop shadow, fill=ltBlue, rounded corners=2pt]
]
\end{forest}
\caption{{Possible directory structure}}
\label{fig:DirStr}
\end{figure}

\subsection{Workflow}

The workflow for the entire aggregation facility is contained
in the GAMS file \texttt{MakeData.gms}. In principle, the only
thing the user needs to modify in the file is the \texttt{BaseName}
parameter, which is at the top of the file. The \texttt{BaseName} typically
reflects the name of a specific aggregation and/or project. Names of all
the relevant input files will assume that the \texttt{BaseName} is part
of the filename, and all output files will also contain \texttt{BaseName}
as part of the output filename---including output folders.

There is a set of flags at the beginning of the file, which allows
users to select which parts of the aggregation facility to skip. One
could in principle skip the filtering process and \texttt{Altertax},
but all other modules should be run.

The only direct input to the \texttt{MakeData} file is
a user prepared \emph{options} file which must be contained
in a sub-folder with the name \texttt{BaseName} and the
options file must have the name \texttt{BaseNameOpt.gms}.
If, for example, \texttt{BaseName} is equal to 'G20', the
option file must be called \texttt{G20Opt.gms} and be located
in the sub-folder 'G20'.

Table~\ref{tab:aggGTAPFiles} provides a list of files distributed with the data
aggregation facility. In addition, the distribution will have a few sample
'MAP' files that users are likely to use as a starting point for new or modified
aggregations. It is assumed that users will have access and appropriate licenses
for the GTAP database files (see below for list of GTAP files). Most files need
no user intervention. The exceptions would be the two base 'sets' definition
files that would need to be updated with new database releases.\footnote{The
'sets' definition files are now configured for the new GTAP database
configuration that accompanies Version~7 of the GTAP model. These 'sets'
definition files have been given the suffix 'F'. The aggregation facility
is not backward compatible and only works with the new database format.}

Listing~\ref{lst:Opt}  is an example of the user options in the 'Opt' file.
The first four relate to the relevant GTAP version. This example
is using version \texttt{V11\_1POW} of the GTAP Data Base, located
in the folder \texttt{V:\textbackslash{}GTAP\textbackslash{V11\_1POW}}, with a base name
of \texttt{GSDF} and a reference year of 2017. Somewhat fortuitously,
the updated SSP projections use the same reference year for prices, i.e.,
the \texttt{PPPYear}. All satellite account data is in the
folder \texttt{satDir}, including the SSP file (\texttt{SSPFile}) and the World Bank's
projections of education and gender (\texttt{GIDDFILE}).

\begin{lstlisting}[language=GAMS, caption={Global options for the workflow}, label=lst:Opt]
$setGlobal ver      V11_1POW
$setGlobal GTAPDir  v:\GTAP11\%ver%
$setGlobal DataBase GSDF
$setGlobal RefYear  2017
$setGlobal PPPYear  2017
$setGlobal satDir   ..\SatAcct
$setGlobal SSPFile  SSPScenOCT2024.gdx
$setGlobal GIDDFile giddProj.gdx
\end{lstlisting}

The first steps to run this code are: (1) create a sub-folder in the 'Data' folder with
the desired \texttt{BaseName} as the sub-folder name; (2) create a file in
the sub-folder using the \texttt{BaseName} appended with '\texttt{Opt}.gms'
and enter the appropriate options as in Listing~\ref{lst:Opt}, and
(3) change the \texttt{BaseName} option in the file \texttt{MakeData.gms}. There
are a few additional steps---described next---that are required before running
the aggregation facility.

\subsection{Primary aggregation}

The first step in the aggregation facility is to run the primary aggregation of
the GTAP Data Base. This is a required step. The output of this aggregation
will be a 'diagonal' database, with the same geometry as the standard
GTAP Data Base, but aggregated. The reason for 'diagonality' is that the
filtering routine, described next, requires diagonality.

Both the primary and secondary aggregation use the same aggregation code,
which is provided in the GAMS file \texttt{AggGTAP.gms}. It is mostly
a stand-alone code, though uses the file \texttt{CheckMap.gms} to
check the user-based mappings.

The only user input into the primary aggregation is a user-prepared map
file, which contains the aggregation mappings for commodities (and activities),
regions and factors of production. The mapping file must be contained
in the sub-folder called \texttt{BaseName} and with the
name \texttt{BaseNameMap1.gms}, e.g., \texttt{G20Map1.gms}. The input
files are typically a version of the GTAP database. The output
files will be saved in the sub-folder \texttt{Agg1} in the
\texttt{BaseName} sub-folder.

The following describes each section of the primary mapping file:

\begin{enumerate}
\item The user must indicate whether this is the primary of secondary aggregation.
Both aggregations use the same GTAP code. The main difference between the two is
that the secondary aggregation will save the various mapping sets to the
resulting GDX file with the aggregate database. These maps can be useful
for downstream processes and for documentation purposes.
\item Definition of commodities, indexed by $i$.
\item Users must declare the margin commodities, but the code will
define this set based on the data.
\item Users must declare the activities set, but it will be identical
to the commodities set.
\item Definition of regions, indexed by $r$.
\item Definition of the factors of production (or endowments), indexed
by $\mathit{fp}$.
\item Subsets of the factors, $l$ for labor, $\mathit{cap}$ for
capital, $\mathit{lnd}$ for land, and $\mathit{nrs}$ for natural
resources. N.B. Users are free to use any labels for the factors of production,
for example, \texttt{lnd(fp) / terre "Facteur de production 'la terre' /"}.
\item Default CET transformation elasticities for allocation factors of production.
The user enters this when declaring the parameter \texttt{etrae0}. Perfect
mobility is assumed when the elasticity is given by \texttt{INF}. At this
stage, the process uses the GTAP convention of entering CET elasticities
as a negative number. It also retains the convention that natural resources
have very low mobility.\footnote{The \textsc{Envisage} model assumes
that natural resources are sector-specific and have sector-specific
supply elasticities.} The data defined in the parameter \texttt{etrae0}
is transferred to the parameter \texttt{etrae1}, which is indexed by $r$.
\item Subsets of the factors of production. Sector-specific factors
are assumed for all factors with a
transformation elasticity of less than 0.01. Mobile factors are
assumed when the elasticity is \texttt{INF}. Partially mobile
factors are not sector-specific or mobile.
\item The 'make' elasticities are entered next. The transformation
elasticity defaults to -5 and the CES elasticity to \texttt{INF}. With
a diagonal matrix, these values are irrelevant. The user can also
override these values in the \textsc{Envisage} parameter file.
\item The non-household expenditure elasticities are entered next with
default values of 1 for government expenditures, 0 for investment expenditures
and 1 for the allocation of international trade and transport services across
regions.
\item The aggregation facility allows for combining the returns to
land and natural resources with capital returns.\footnote{One would want to
do this in the case the sectors where these flows appear are aggregated
into a large sector, e.g., other mining with manufacturing. Unless
the elasticity of supply is very high, one could be implausibly constraining the
supply of the aggregate sector.} In the example in the listing, the
natural resource payment is merged in the aggregate \texttt{pfd} (processed food),
which includes the fisheries sector from the GTAP Data Base.
\item The commodity mapping is provided next. Each GTAP commodity is
mapped once to an aggregate commodity. All mappings are verified for
consistency.
\item The activity mapping is provided next. In the primary aggregation,
code is provided that explicitly assumes a diagonal output database, i.e.,
a 1-to-1 correspondence between aggregate activities and aggregate commodities.
In the secondary aggregation, users have to provide the aggregation
mapping explicitly as the activity labels must differ from commodity
labels, even in the case of a diagonal output database.
\item The regional mapping is next. Each GTAP region must be assigned
to one, and only one, aggregate region.
\item The factor mapping is next, with each GTAP endowment being
mapped to one aggregate factor.
\item The last item is for the AEZ version of the database. At the moment,
the AEZ version of the \textsc{Envisage} model is under review.
\end{enumerate}

\begin{lstlisting}[language=GAMS, caption={Mapping file for primary aggregation}, label=lst:PrimAgg]
$onempty

$setGlobal aggStep aggPrimary

sets
   i  "Commodities"   /
         crp      "Crops"
         lvs      "Livestock and dairy"
         frs      "Forestry"
         coa      "Coal extraction"
         oil      "Oil extraction"
         gas      "Gas extraction"
         oxt      "Other pimary sectors"
         pfd      "Processed food"
         xlm      "Other light manufacturing"
         ppp      "Paper products & publishing"
         chp      "Chemicals, rubber and plastics"
         nmm      "Non-metallic minerals"
         i_s      "Ferrous metals"
         nfm      "Other metals"
         xmn      "Other manufacturing"
         p_c      "Refined oil"
         etd      "Electricity transmission and distribution"
         els      "Solar power"
         elw      "Wind power"
         elr      "Other renewable power"
         elh      "Hydro power"
         elc      "Coal-fired power"
         elg      "Gas power"
         elo      "Oil power"
         eln      "Nuclear power"
         cns      "Construction"
         atp      "Air transport"
         wtp      "Water transport"
         otp      "Other transport"
         srv      "Services"
      /

   m(i)  "Margin commodities"

   a  "Activities"   /
         set.i
      /

   r  "Regions" /
         ARG      "Argentina"
         AUS      "Australia"
         BRA      "Brazil"
         CAN      "Canada"
         CHN      "China"
         DEU      "Germany"
         FRA      "France"
         ITA      "Italy"
         IND      "India"
         IDN      "Indonesia"
         JPN      "Japan"
         MEX      "Mexico"
         RUS      "Russian Federation"
         SAU      "Saudi Arabia"
         ZAF      "South Africa"
         KOR      "South Korea"
         TUR      "Türkiye"
         GBR      "United Kingdom"
         USA      "United States"
         XEA      "Rest of East Asia and Pacific"
         XSA      "Rest of South Asia"
         XEC      "Rest of Europe and Central Asia"
         XMN      "Rest of Middle East and North Africa"
         XSS      "Rest of Sub-Saharan Africa"
         XLC      "Rest of Latin America and Caribbean"
         XEU      "Rest of the European Union"
         XHY      "Rest of high-income countries"
       /

   fp  "Factors of production"  /
         NSK     "Unskilled labor"
         SKL     "Skilled labor"
         CAP     "Capital"
         LND     "Land"
         NRS     "Natural resources"
      /

   l(fp)  "Labor factors" /
         NSK     "Unskilled labor"
         SKL     "Skilled labor"
      /
   cap(fp) "Capital" /
         CAP     "Capital"
      /
   lnd(fp) "Land endowment" /
         LND     "Land"
      /
   nrs(fp) "Natural resources" /
         NRS     "Natural resources"
      /
;

Parameter
   etrae1(fp,r) "CET transformation elasticities for factor allocation"
;

*  Use the GTAP convention that CET elastities are entered as negative numbers

parameter etrae0(fp) "CET transformation elasticities for factor allocation" /
   NSK      inf
   SKL      inf
   CAP      inf
   LND     -1
   NRS     -0.001
/ ;

etrae1(fp,r) = etrae0(fp) ;

set
   fpf(fp)     "Sector specific factors"
   fps(fp)     "Sluggish factors"
   fpm(fp)     "Mobile factors"
;

fpf(fp)$(abs(etrae0(fp)) lt 0.01) = yes ;
fpm(fp)$(etrae0(fp) eq inf)       = yes ;
fps(fp)$(not fpf(fp) and not fpm(fp)) = yes ;

*  NEW -- MAKE ELASTICITIES

Parameter
   etraq1(a,r)       "MAKE CET Elasticity"
   esubq1(i,r)       "MAKE CES Elasticity"
;
etraq1(a,r) = -5 ;
esubq1(i,r) = inf ;

*  NEW -- EXPENDITURE ELASTICITIES

Parameter
   esubg1(r)         "Government expenditure CES elasticity"
   esubi1(r)         "Investment expenditure CES elasticity"
   esubs1(i)         "Transport margins CES elasticity"
;

esubg1(r) = 1 ;
esubi1(r) = 0 ;
esubs1(i) = 1 ;

set mapt(a) "Merge land and capital payments in the following sectors" /

/ ;

set mapn(a) "Merge natl. res. and capital payments in the following sectors" /
   pfd
/ ;

*  Commodity mappings: from GTAP (comm) to modeled commodities (i)
set mapi(i,comm) /
   crp.PDR
   crp.WHT
   crp.GRO
   crp.V_F
   crp.OSD
   crp.C_B
   crp.PFB
   crp.OCR
   lvs.CTL
   lvs.OAP
   lvs.RMK
   lvs.WOL
   frs.FRS
   pfd.FSH
   coa.COA
   oil.OIL
   gas.GAS
   oxt.OXT
   pfd.CMT
   pfd.OMT
   pfd.VOL
   pfd.MIL
   pfd.PCR
   pfd.SGR
   pfd.OFD
   pfd.B_T
   xlm.TEX
   xlm.WAP
   xlm.LEA
   xlm.LUM
   ppp.PPP
   p_c.P_C
   chp.CHM
   chp.BPH
   chp.RPP
   nmm.NMM
   i_s.I_S
   nfm.NFM
   xmn.FMP
   xmn.ELE
   xmn.EEQ
   xmn.OME
   xmn.MVH
   xmn.OTN
   xmn.OMF
   etd.TnD
   eln.NuclearBL
   elc.CoalBL
   elg.GasBL
   elw.WindBL
   elh.HydroBL
   elo.OilBL
   elr.OtherBL
   elg.GasP
   elh.HydroP
   elo.OilP
   els.SolarP
   gas.GDT
   srv.WTR
   cns.CNS
   srv.TRD
   srv.AFS
   otp.OTP
   wtp.WTP
   atp.ATP
   srv.WHS
   srv.CMN
   srv.OFI
   srv.INS
   srv.RSA
   srv.OBS
   srv.ROS
   srv.OSG
   srv.EDU
   srv.HHT
   srv.DWE
/ ;

*  Primary aggregation assumes diagonality: i.e., 1-to-1 mapping of activities and commodities
set mapa(a,acts) ;
loop(sameas(a,i),
   loop((acts,comm)$(mapi(i,comm) and sameas(acts,comm)),
      mapa(a,acts) = yes ;
   ) ;
) ;

*  Regional mapping: from GTAP (reg) to modeled regions (r)
set mapr(r,reg) /
   AUS.AUS
   XHY.NZL
   XEA.XOC
   CHN.CHN
   XHY.HKG
   JPN.JPN
   KOR.KOR
   XEA.MNG
   XHY.TWN
   XEA.XEA
   XEA.BRN
   XEA.KHM
   IDN.IDN
   XEA.LAO
   XEA.MYS
   XEA.PHL
   XHY.SGP
   XEA.THA
   XEA.VNM
   XEA.XSE
   XSA.AFG
   XSA.BGD
   IND.IND
   XSA.NPL
   XSA.PAK
   XSA.LKA
   XSA.XSA
   CAN.CAN
   USA.USA
   MEX.MEX
   XHY.XNA
   ARG.ARG
   XLC.BOL
   BRA.BRA
   XLC.CHL
   XLC.COL
   XLC.ECU
   XLC.PRY
   XLC.PER
   XLC.URY
   XLC.VEN
   XLC.XSM
   XLC.CRI
   XLC.GTM
   XLC.HND
   XLC.NIC
   XLC.PAN
   XLC.SLV
   XLC.XCA
   XLC.DOM
   XLC.JAM
   XLC.HTI
   XLC.PRI
   XLC.TTO
   XLC.XCB
   XEU.AUT
   XEU.BEL
   XEU.CYP
   XEU.CZE
   XEU.DNK
   XEU.EST
   XEU.FIN
   FRA.FRA
   DEU.DEU
   XEU.GRC
   XEU.HUN
   XEU.IRL
   ITA.ITA
   XEU.LVA
   XEU.LTU
   XEU.LUX
   XEU.MLT
   XEU.NLD
   XEU.POL
   XEU.PRT
   XEU.SVK
   XEU.SVN
   XEU.ESP
   XEU.SWE
   GBR.GBR
   XHY.CHE
   XHY.NOR
   XHY.XEF
   XEC.ALB
   XEC.SRB
   XEU.BGR
   XEC.BLR
   XEU.HRV
   XEU.ROU
   RUS.RUS
   XEC.UKR
   XHY.XEE
   XHY.XER
   XEC.KAZ
   XEC.KGZ
   XEC.TJK
   XEC.UZB
   XEC.XSU
   XEC.ARM
   XEC.AZE
   XEC.GEO
   XMN.BHR
   XMN.IRN
   XMN.IRQ
   XMN.ISR
   XMN.JOR
   XMN.KWT
   XMN.LBN
   XMN.OMN
   XMN.PSE
   XMN.QAT
   SAU.SAU
   XMN.SYR
   TUR.TUR
   XMN.ARE
   XMN.XWS
   XMN.DZA
   XMN.EGY
   XMN.MAR
   XMN.TUN
   XMN.XNF
   XSS.BEN
   XSS.BFA
   XSS.CMR
   XSS.CIV
   XSS.GHA
   XSS.GIN
   XSS.MLI
   XSS.NER
   XSS.NGA
   XSS.SEN
   XSS.TGO
   XSS.XWF
   XSS.AGO
   XSS.CAF
   XSS.TCD
   XSS.COG
   XSS.COD
   XSS.GNQ
   XSS.GAB
   XSS.STP
   XSS.BDI
   XSS.COM
   XSS.ETH
   XSS.KEN
   XSS.MDG
   XSS.MWI
   XSS.MUS
   XSS.MOZ
   XSS.RWA
   XSS.SDN
   XSS.TZA
   XSS.UGA
   XSS.ZMB
   XSS.ZWE
   XSS.XEC
   XSS.BWA
   XSS.SWZ
   XSS.NAM
   ZAF.ZAF
   XSS.XSC
   XSS.XTW
/ ;

*  Factor mapping: from GTAP (endw) to modeled factors (fp)
set mapf(fp, endw) /
   NSK.ag_othlowsk
   NSK.service_shop
   NSK.clerks
   SKL.tech_aspros
   SKL.off_mgr_pros
   CAP.Capital
   LND.Land
   NRS.NatlRes
/ ;

*  Only used if the LU database exists

set AEZ  / AEZ1*AEZ18 / ;
set AEZ1 / AEZ1*AEZ18 / ;
set mapLU(aez1,aez) ; mapLU(aez1,aez)$sameas(aez,aez1) = yes ;
\end{lstlisting}


\subsection{Filtering}

The \emph{filter} procedure is used to remove very small transactions
from the aggregated (and diagonal) database. It is based
on the procedure developed by Tom Rutherford (\cite{LanzRutherfordJGEA2016}),
integrated into CGEBox (\cite{BritzvdMJGEA2018}) and further
modified for use with this aggregation facility. The user
can set tolerance levels, as well as regions and/or sectors
to exempt from the filtering procedure.

The calling procedure is in the main folder and named \texttt{filter.gms},
which will in turn run the filtering program that is contained
in the \texttt{filter} sub-folder. The user must prepare
a file with filter options. This file must be in the project sub-folder
named \texttt{BaseName} and it must be named \texttt{BaseNameFlt.gms},
for example \texttt{G20Flt.gms}. Listing~\ref{lst:Filter} provides
an example of the user options. Users are referred to the original
documentation for a description of most of the options. The one
that is most used are the exempted sectors, which typically
will include the new electricity activities as in many
countries these are at relatively low levels and we do
not wish to drop them. The input files for the filtering
procedure are in the sub-folder \texttt{Agg1} and
the output files will be in the sub-folder \texttt{Flt}.

The \texttt{filter} folder contains the remaining GAMS code files,
which includes \texttt{filter.gms}, \texttt{itrlog.gms}, \texttt{title.gms},
and \texttt{remTinyValues.gms}.

Beyond the listing file, the user should take a brief look at the two log
files that are part of the output. The file \texttt{BaseNameFlt.prn} in
the \texttt{BaseName} sub-folder contains the key statistics emerging from
the filtering routine. The file \texttt{BaseNameLog.txt} contains
information that is sent to the standard GAMS \texttt{log} file.

\begin{lstlisting}[language=GAMS, caption={User option file for the filter program}, label=lst:Filter]
$setGlobal excCombined  0

$setglobal excSecs "els, elw, elr"
$setglobal excRegs

scalars
   ifKeepIntermediateConsumption / 1 /
   ifKeepPrivateconsumption      / 1 /
   ifKeepGovernmentconsumption   / 1 /
   ifKeepInvestments             / 1 /
   ifGDPKeep                     / 1 /
   ifKeepFactorincomeplusbop     / 1 /
   ifAdjDepr                     / 1 /
   abstol                        / 1e-10 /
   relTol                        / 0.005 /
   relTolRed                     / 1e-6  /
   nsteps                        / 5 /
   minNumTransactions            / 50000 /
;

file log / %baseName%\%baseName%Log.txt / ;
put log ;
\end{lstlisting}

After the filtering process, the energy and emissions databases are
adjusted to be consistent with the post-filtered data. In essence,
the pre-filtered coefficients are calculated and applied to
the post-filtered values to provide a new set of energy and
emission volumes. The adjustment is done with the
\texttt{AdustAuxAccounts.gms} GAMS code.

\subsection{Secondary aggregation}

The secondary aggregation takes the results from the
filtering process and provides the final aggregated database.
It is a necessary step irrespective of whether the
final database is diagonal as the \textsc{Envisage}
model requires different labels for commodities and activities.

The format of the mapping file is nearly identical to the format
of the mapping file for the primary aggregation---described above with
the following exceptions:

\begin{enumerate}
\item The \texttt{aggStep} parameter at the beginning of the
user file (\texttt{BaseNameMap2.gms}) must have the value
\texttt{aggSecondary}.
\item Activities must be explicitly defined and the labels
must differ from the commodity labels.
\item Typically the regional and factor aggregations are
not re-defined and simple code can be used to define the mappings.
\end{enumerate}

There are some output differences with the secondary aggregation.
Whereas the primary aggregation only saves the original sets and mappings,
the secondary aggregation will save both the original sets and mappings,
as well as the intermediate sets and mappings. This is potentially useful
downstream and for documentation purposes. The only other difference
between the primary and secondary aggregation is the calculation
of energy combustion. In the case of the primary aggregation, this
is calculated using the original database. In the case of the
secondary aggregation, it will be based on an aggregation
of the energy combustion calculated from the primary aggregation.

\begin{lstlisting}[language=GAMS, caption={Map file example for the secondary aggregation}, label=lst:Agg2]
$onempty

$setGlobal aggStep aggSecondary

sets
   i  "Commodities"   /
         crp-c    "Crops"
         lvs-c    "Livestock and dairy"
         frs-c    "Forestry"
         coa-c    "Coal extraction"
         oil-c    "Oil extraction"
         gas-c    "Gas extraction"
         oxt-c    "Other pimary sectors"
         pfd-c    "Processed food"
         xlm-c    "Other light manufacturing"
         ppp-c    "Paper products & publishing"
         chp-c    "Chemicals, rubber and plastics"
         nmm-c    "Non-metallic minerals"
         i_s-c    "Ferrous metals"
         nfm-c    "Other metals"
         xmn-c    "Other manufacturing"
         p_c-c    "Refined oil"
         ely-c    "Electricity"
         cns-c    "Construction"
         atp-c    "Air transport"
         wtp-c    "Water transport"
         otp-c    "Other transport"
         srv-c    "Services"
      /

   m(i)  "Margin commodities"

   a  "Activities"   /
         crp-a    "Crops"
         lvs-a    "Livestock and dairy"
         frs-a    "Forestry"
         coa-a    "Coal extraction"
         oil-a    "Oil extraction"
         gas-a    "Gas extraction"
         oxt-a    "Other pimary sectors"
         pfd-a    "Processed food"
         xlm-a    "Other light manufacturing"
         ppp-a    "Paper products & publishing"
         chp-a    "Chemicals, rubber and plastics"
         nmm-a    "Non-metallic minerals"
         i_s-a    "Ferrous metals"
         nfm-a    "Other metals"
         xmn-a    "Other manufacturing"
         p_c-a    "Refined oil"
         etd-a    "Electricity transmission and distribution"
         els-a    "Solar power"
         elw-a    "Wind power"
         elr-a    "Other renewable power"
         elh-a    "Hydro power"
         elc-a    "Coal-fired power"
         elg-a    "Gas power"
         elo-a    "Oil power"
         eln-a    "Nuclear power"
         cns-a    "Construction"
         atp-a    "Air transport"
         wtp-a    "Water transport"
         otp-a    "Other transport"
         srv-a    "Services"
      /

   r  "Regions" /
         ARG      "Argentina"
         AUS      "Australia"
         BRA      "Brazil"
         CAN      "Canada"
         CHN      "China"
         DEU      "Germany"
         FRA      "France"
         ITA      "Italy"
         IND      "India"
         IDN      "Indonesia"
         JPN      "Japan"
         MEX      "Mexico"
         RUS      "Russian Federation"
         SAU      "Saudi Arabia"
         ZAF      "South Africa"
         KOR      "South Korea"
         TUR      "Türkiye"
         GBR      "United Kingdom"
         USA      "United States"
         XEA      "Rest of East Asia and Pacific"
         XSA      "Rest of South Asia"
         XEC      "Rest of Europe and Central Asia"
         XMN      "Rest of Middle East and North Africa"
         XSS      "Rest of Sub-Saharan Africa"
         XLC      "Rest of Latin America and Caribbean"
         XEU      "Rest of the European Union"
         XHY      "Rest of high-income countries"
       /

   fp  "Factors of production"  /
         NSK     "Unskilled labor"
         SKL     "Skilled labor"
         CAP     "Capital"
         LND     "Land"
         NRS     "Natural resources"
      /

   l(fp)  "Labor factors" /
         NSK     "Unskilled labor"
         SKL     "Skilled labor"
      /
   cap(fp) "Capital" /
         CAP     "Capital"
      /
   lnd(fp) "Land endowment" /
         LND     "Land"
      /
   nrs(fp) "Natural resources" /
         NRS     "Natural resources"
      /
;

Parameter
   etrae1(fp,r) "CET transformation elasticities for factor allocation"
;

*  Use the GTAP convention that CET elastities are entered as negative numbers

parameter etrae0(fp) "CET transformation elasticities for factor allocation" /
   NSK      inf
   SKL      inf
   CAP      inf
   LND     -1
   NRS     -0.001
/ ;

etrae1(fp,r) = etrae0(fp) ;

set
   fpf(fp)     "Sector specific factors"
   fps(fp)     "Sluggish factors"
   fpm(fp)     "Mobile factors"
;

fpf(fp)$(abs(etrae0(fp)) lt 0.01) = yes ;
fpm(fp)$(etrae0(fp) eq inf)       = yes ;
fps(fp)$(not fpf(fp) and not fpm(fp)) = yes ;

*  NEW -- MAKE ELASTICITIES

Parameter
   etraq1(a,r)       "MAKE CET Elasticity"
   esubq1(i,r)       "MAKE CES Elasticity"
;
etraq1(a,r) = -5 ;
esubq1(i,r) = inf ;

*  NEW -- EXPENDITURE ELASTICITIES

Parameter
   esubg1(r)         "Government expenditure CES elasticity"
   esubi1(r)         "Investment expenditure CES elasticity"
   esubs1(i)         "Transport margins CES elasticity"
;

esubg1(r) = 1 ;
esubi1(r) = 0 ;
esubs1(i) = 1 ;

set mapt(a) "Merge land and capital payments in the following sectors" /

/ ;

set mapn(a) "Merge natl. res. and capital payments in the following sectors" /

/ ;

*  Commodity mapping
set mapi(i,comm) /
   crp-c.crp
   lvs-c.lvs
   frs-c.frs
   coa-c.coa
   oil-c.oil
   gas-c.gas
   oxt-c.oxt
   pfd-c.pfd
   xlm-c.xlm
   ppp-c.ppp
   chp-c.chp
   nmm-c.nmm
   i_s-c.i_s
   nfm-c.nfm
   xmn-c.xmn
   p_c-c.p_c
   ely-c.etd
   ely-c.els
   ely-c.elw
   ely-c.elr
   ely-c.elh
   ely-c.elc
   ely-c.elg
   ely-c.elo
   ely-c.eln
   cns-c.cns
   atp-c.atp
   wtp-c.wtp
   otp-c.otp
   srv-c.srv
/ ;

set mapa(a,acts) /
   crp-a.crp
   lvs-a.lvs
   frs-a.frs
   coa-a.coa
   oil-a.oil
   gas-a.gas
   oxt-a.oxt
   pfd-a.pfd
   xlm-a.xlm
   ppp-a.ppp
   chp-a.chp
   nmm-a.nmm
   i_s-a.i_s
   nfm-a.nfm
   xmn-a.xmn
   p_c-a.p_c
   etd-a.etd
   els-a.els
   elw-a.elw
   elr-a.elr
   elh-a.elh
   elc-a.elc
   elg-a.elg
   elo-a.elo
   eln-a.eln
   cns-a.cns
   atp-a.atp
   wtp-a.wtp
   otp-a.otp
   srv-a.srv
/ ;

set mapr(r,reg) ; mapr(r,reg)$sameas(r,reg) = yes ;

set mapf(fp,endw) ; mapf(fp,endw)$sameas(fp,endw) = yes ;

*  Only used if the LU database exists

set AEZ  / AEZ1*AEZ18 / ;
set AEZ1 / AEZ1*AEZ18 / ;
set mapLU(aez1,aez) ; mapLU(aez1,aez)$sameas(aez1,aez) = yes ;
\end{lstlisting}

\subsection{Altering the aggregated database}

The fourth step in the data processing facility is the ability
to make adjustments to the aggregated database. This
optional step is known as the \emph{Altertax} procedure
described in \cite{MalcolmGTAPTP12}. It is typically
used as a pre-processing step to adjust tax rates to
a new reference point, for example to modify tariff rates.
The \emph{Altertax} procedure uses a GAMS version of
the standard GTAP model. All the standard elasticities
are over-ridden and set to (near) 1 to minimize deviations
in the initial budget shares. The input
database for the \emph{Altertax} procedure is in the
sub-folder \texttt{Agg2} and the output will be in the
folder \texttt{Alt}. Similar to the filtering procedure,
a post-process procedure is implemented to adjust the
energy and emissions volumes using the
\texttt{AdjustAuxAccounts.gms} code.

The calling code is in the main data folder and
called \texttt{AlterTax.gms}. In principle, the user
does not need to modify this file.
However, the model code does require a
user file to define some key sets used by the model.
The user sets need to be defined in a file
with the name \texttt{BaseNameSets.gms}, which
needs to be located in the \texttt{BaseName} sub-folder.
The sets that need to be defined by the user are the following:
\begin{enumerate}
\item \texttt{rres}. The model requires a residual region, which
is a singleton set. Typically, it will be the largest economy.
\item \texttt{rmuv(r)}. The model defines a global price index
known as the Manufacturing Unit Value (MUV), which is an index
of export prices of manufactured goods for key industrial economies. This
index can be used to deflate real international values, such as net capital
flows. Typically, this index is defined over the major industrial economies.
\item \texttt{imuv(i)}. This set is also linked to the MUV index
and defines the industries included in the calculation of the MUV index.
\end{enumerate}

\begin{lstlisting}[language=GAMS, caption={User defined sets for the AlterTax procedure}, label=lst:AlterTaxUserSets]
*  Additional sets that are aggregation dependent

singleton Sets
   rres(r)     "Residual region"    / usa /
;

Sets
   rmuv(r)     "MUV regions"        / AUS, CAN, CHN, DEU, FRA, ITA, JPN, KOR, GBR, USA, XHY /
   imuv(i)     "MUV commodities"    / pfd-c, xlm-c, ppp-c, chp-c, nmm-c, i_s-c, nfm-c, xmn-c /
;
\end{lstlisting}

The rest of the code for the GTAP model is
provided in the sub-folder \texttt{GTAPModel}. The core
model code is in the file \texttt{Model.gms}. The database
is read in the file \texttt{getData.gms} and the model
parameters and variables are initialized and calibrated
in the file \texttt{cal.gms}.
There are some updating statements at the beginning
of each solution period that are contained
in the file \texttt{iterloop.gms}. This file
also calls \texttt{mvar.gms} to initialize model variables
between periods. The model
is solved from code in the file \texttt{solve.gms}.
The output database is created with the file \texttt{saveData.gms}.\footnote{The
code in \texttt{postsim.gms} is not currently being used, but it can
be included at the end of the main file (i.e., \texttt{AlterTax.gms}) to
produce a CSV file with the model's core indicators, including the SAM.}
The file \texttt{AlterTaxPrm.gms} contains the parameter overrides for
the \emph{AlterTax} procedure.

The key user input is the \emph{AlterTax} shock file, which
should be in the project sub-folder and called
\texttt{BaseNameAlt.gms}.\footnote{This file has to be created, even
if there is no shock implemented. At a minimum, it
should have a single empty line.} This file is
included in the core \texttt{AlterTax.gms} file for the simulation
year with the label '\texttt{Shock}'. In the standard version of
\texttt{AlterTax.gms}, time is defined over three periods:
'\texttt{Base}', '\texttt{Check}' and '\texttt{Shock}'. The '\texttt{Base}'
period contains the initialized model solution, essentially the base data.
The '\texttt{Check}' period solves the model with no shocks. In essence, this should
simply re-produce the base solution. If looking at the GAMS residual
check\footnote{Set the GAMS options \texttt{limrow} to a positive value.},
all residuals should be close to zero. It is a good validation test for
the model initialization and calibration. The '\texttt{Shock}' period
solves the model with a user specified shock. If the shock is
using a time-based variable or parameter, the appropriate time should
be specified as either '\texttt{Shock}', or '\texttt{tsim}'. A very simple
example is:

\begin{verbatim}

    imptax.fx(s,i,"IDN",tsim)$ASEAN(s) = 0.5 * imptax.l(s,i,"IDN",t0) ;

\end{verbatim}

\noindent which cuts import tariffs by 50\% for all imports from
ASEAN regions into Indonesia. A more complicated example comes from
a potential initialization of marginal abatement cost curves (MACC)
for abating non-combustion greenhouse gas emissions. The MACCs are
initialized with a negligible carbon price.\footnote{This is necessary
because the MACCs are based on a CES technology in which the initial
price must differ from zero.} The code below introduces the shock.

\begin{lstlisting}[language=GAMS, caption={Using AlterTax to initialize carbon prices}, label=lst:AlterTaxExample]
    ytax0(r,"ct")     = 1 ;

    execute_load "%inDir%/%BaseName%NCO2.gdx", gwp, emi_iop, emi_endw, emi_qo ;

    ProcEmi0(r,em,a)  = gwp(em,r,"AR4")*cscale
                  *  (sum(i, emi_iop(em, i, a, r))
                  +   sum(fp, emi_endw(em, fp, a, r))
                  +   emi_qo(em, a, r)) ;

    pcarb0(r) = 0.25 ;

    ctaxFlag(r,a)$sum(em, pcarb0(r)*(inscale/cscale)*procEmi0(r,em,a) and xp0(r,a)) = yes ;
    ctax.l(r,a,tsim)$ctaxFlag(r,a)  = 0.0003 ;
    ctax.lo(r,a,tsim)$ctaxFlag(r,a) = -inf ;
    ctax.up(r,a,tsim)$ctaxFlag(r,a) = +inf ;

\end{lstlisting}

\noindent First, it calculates the level of process emissions for each sector.\footnote{The
non-normalized level of carbon price revenues must be set to 1 since its default value is 0.}
It
reads emissions from the \texttt{NCO2} file and sums over all possible
sources and converts to $\textnormal{CO}_2$-equivalent using the IPCC's
global warming potential. We set the initial carbon price to \$0.25. This version of the GTAP model
is not 'emissions' aware. We have added an equation that calculates an output tax
(\texttt{ctax}) that would yield the same revenue as the carbon price. This introduces
a wedge, in the database, between the unit cost of production and the value of sales, which,
when introduced in the \textsc{Envisage} model is exactly equal to the revenues
generated by the initial process emissions when priced at \$0.25 per ton of
CO2e.

\subsection{Preparing data for the \textsc{Envisage} model}

This section is used to prepare sets and aggregate parameters for
use by the \textsc{Envisage} model. The driving code is
contained in the GAMS file \texttt{AggEnvElast.gms}, which
is in the main \texttt{Data} folder.

The core input files are:

\begin{enumerate}
\item The original GTAP Data Base, where the user provides a specific version number.
\item The disaggregated \textsc{Envisage} elasticities that are provided in the
satellite data folder. The disaggregated \textsc{Envisage} elasticities
are originally sourced from the OECD circular economy project. A new
version is created with each new GTAP version, where the user provides
a set mapping between the circular economy database and the targeted
GTAP version.\footnote{Not currently publicly available, but the
codes are typically provided in the folder \texttt{GTAP11/Elast}.}
\item The aggregated database, which is in folder \texttt{Fnl}.
\end{enumerate}

The user prepares a 'sets' file, which will be used by both the
aggregation facility and the \textsc{Envisage} model, i.e., the
user should prepare the 'sets' file in the project folder itself,
not the project sub-folder in the \texttt{Data} folder. Using
the default folder configuration, the sets folder will be in
\texttt{../BaseName/} and called \texttt{BaseNameSets.gms}.\footnote{The
previous aggregation facility had two user defined sets, one in the
data folder and one in the project folder. This involved significant
duplication, so this has been rationalized and there is now a single
user input file.} The following describe the main elements
of the '\texttt{Sets}' file:

\begin{enumerate}
\item The unskilled (\texttt{ul}) and skilled (\texttt{sl}) labor sets are there for
backward compatibility, but are no longer used.
\item The labor nesting in the production structure has two main labor bundles,
which appear in different levels of the production nest---with
$\mathit{LAB1}$ typically towards the top in a traditional capital+energy vs. labor
substitution and $\mathit{LAB2}$ more closely directly linked with capital. Intuitively,
capital requires skilled labor for operations and the skill+capital
bundle is a substitute for unskilled labor.
The model also includes an \emph{intermediate}
demand bundle labeled $\mathit{LABB}$. This is to allow for more
subtle distinctions across labor types, for example gender and/or
native- vs. foreign-born workers. The user specifies the
intermediate labor bundles using a new set $\mathit{wb}$. Each
granular labor category is mapped to one, and only one labor bundle
indexed by $\mathit{wb}$. And each of the $\mathit{LABB}$ bundles is mapped to
either $\mathit{LAB1}$ or $\mathit{LAB2}$. Examples are provided below
after Listing~\ref{lst:SetsFileExample}.
\item Similar to the \emph{AlterTax} procedure and the GTAP model used therein, the
user needs to define a residual region (\texttt{rres}) as well as the
relevant set definitions for the MUV index (\texttt{rmuv} and \texttt{imuv}).
\item Versions of the model may use definitions for education (\texttt{iedu}) and/or health
services (\texttt{ihht}).
\item The post-simulation process will prepare pre-defined sector and regional
aggregations of most model indicators. The user defines these aggregate
sets for commodities (\texttt{ia}), activities (\texttt{aga}) and regions (\texttt{ra}).
Though not required, in each case it is useful to include the individual labels
for each set, which can be accomplished by including the GAMS code \texttt{set.xxx},
replacing \texttt{xxx} with the relevant set, e.g., \texttt{set.comm} for commodities,
\texttt{set.acts} for activities and \texttt{set.reg} for the regions.
The user also needs to provide the relevant mappings, which can be
hard-coded or defined using GAMS code. The example file in the
listing provides examples of both. The set mappings are
\texttt{mapia}, \texttt{mapaga} and \texttt{mapra} respectively for
commodities, activities and regions.
\item The post-simulation processing also uses aggregations for labor (\texttt{lagg})
using the mapping \texttt{maplagg}.
\item The baseline scenario may use the \texttt{nsk} and \texttt{skl} sets of
labor to map to education projections.
\item The model has different production nestings for crops,
livestock and all other sectors. These are defined respectively
by the sets \texttt{acr}, \texttt{alv} and \texttt{ax}.
\item The post-simulation processing may use a standard decomposition
of activities into agriculture (\texttt{agr}), manufacturing (\texttt{man})
and services (\texttt{srv}).
\item The user can define the energy activities (\texttt{aenergy}) and the fossil fuel
activities (\texttt{affl}).
\item The user can define the water-related activities (\texttt{aw}). N.B. The
current version of the model needs to be reviewed in order to model water-use
adequately.
\item The model allows for labor market segmentation, which can differ
across labor types. The model uses the concepts of zones ($z$), of
which there are three types: rural (\texttt{rur}), urban (\texttt{urb})
and non-segmented (\texttt{nsg}) or economy-wide.
The mapping set \texttt{mapz} allows the user to define the labor market
segmentation. The model will use the labor 'migration' elasticity to define
the implementation of segmentation. If the elasticity is set to \texttt{INF}, the
model assumes perfect mobility across segments.
\item The crop production structure identifies agricultural chemicals
as a special input (\texttt{frt}) and the livestock production
structure identifies feed (\texttt{feed}). The water services
input (\texttt{iw}) is not currently in use.
\item The energy commodities are identified and bundled. The set
\texttt{e} is the full set of energy commodities, of which
\texttt{eylc} is the electricity commodity. There is also
a subset for the fuel commodities (\texttt{fuel}).
\item The \textsc{Envisage} model allows for a separate classification
of consumed commodities and uses a transition matrix (or consumer make)
matrix approach to convert consumed commodities ($k$) to marketed commodities ($i$).
In the ideal approach, the transition matrix would be relatively dense and
among other things, clearly identify the energy mix for the different
consumption bundles (transportation, heating and air conditioning, cooking, etc.).
In the absence of such detailed data, the approach to defining the set $k$ focuses
on two objectives---at least identify an aggregate energy bundle that has
the usual substitution possibilities across energy carriers, and a judicious
aggregation of other sectors in order to keep the top-level utility function
relatively small and perhaps lined up with existing econometric estimates of
consumer income and price elasticities. The subsequent consumer demand nesting
will assume a CES structure for the sub-nests. The user thus needs to
define $k$ and the mapping from $i$ to $k$ (\texttt{mapk})---which at the moment
is an n-to-1 mapping, i.e., the transition matrix has only 0's and 1's.
The user can also include definitions for various CPI indices, used for
post-simulation processing.
\item The next sub-section identifies the power activities and is related
to the power version of the GTAP Data Base. The set \texttt{elya} represents
all of the power activities, \texttt{etd} represents the transmission
and distribution activity, and primary power activities are identified with
\texttt{primElya}. The power activities are bundled in the production make matrix.
The user defines so-called power bundles (\texttt{pb}). Each power activity, apart from
transmission and distribution is then mapped to one of the power bundles.
\item The next section refers to the allocation of land, which uses a nested
CET structure. The user defines land bundles (\texttt{lb}) and a top bundle (\texttt{lb1}).
Then land in each activity is mapped to one of the bundles. Examples are provided below.
\item The water sets and bundles are currently ignored.
\item At the bottom of each energy bundle is a set of four bundles
designated by \texttt{COA}, \texttt{OIL}, \texttt{GAS} and \texttt{ELY}. The
user needs to provide a mapping (\texttt{mape}) between the
primary energy carriers and the four bundles.
\item Non-energy intermediate demand is mapped to either the
\texttt{ND1} bundle or the \texttt{ND2} bundle. For example, in the
livestock sector, the \texttt{ND2} bundle would have the feed commodities.
\item The next section initializes the emissions cap and trade system. The
user-defined set \texttt{ra}, should have all combinations of regions
that might be part of a cap and trade system. The set \texttt{rq} defines
the potential carbon clubs, initially set to the empty set. The set
\texttt{aets} should have all potential combinations of activities/agents that would
participate in an ETS.
\item The remaining sets are only defined for the model and not used
by the aggregation facility. The first is a mapping of labor types
to potential education levels. This is used for the education-based
projections.
\item The final item is the sort order for the labels of the SAM. This
is useful for loading the SAM-based pivot tables in Excel as the labels
will be automatically sorted by Excel.
\end{enumerate}

\begin{lstlisting}[language=GAMS, caption={Example 'Sets' file for the \textsc{Envisage} model}, label=lst:SetsFileExample]
$onempty
*/ ---------------------------------------------------------------------------------------
*
*     Sets needed for the ENVISAGE model, i.e., not defined for the GTAP Model
*     Only sets that are aggregation dependent.
*     Non-aggregation dependent sets are defined in getData.gms
*
*/ ---------------------------------------------------------------------------------------

*   Subsets ul(l) and sl(l) included for backward compatibility
*  !!!! This should come from somewhere else--not part of GTAP

set ul(l) "Unskilled labor" /
   set.lab
/ ;

set sl(l) "Skilled labor" ; sl(l)$(not ul(l)) = yes ;

*  !!!! This should come from somewhere else--not part of GTAP
*  !!!! Solved with flexible nesting

set wb "Intermediate labor bundle(s)" /
   Single       "Single intermediate labor bundle"
/ ;

set maplab1(wb) "Mapping of intermediate labor demand bundle(s) to LAB1" /
   Single       "Single intermediate labor bundle"
/ ;

set mapl(wb,l) "Mapping of labor categories to intermedate demand bundle(s)" /
   Single   .nsk
   Single   .skl
/ ;

set lr(l) "Reference labor for skill premium" /
   skl          "Skilled labor"
/ ;

* >>>> MUST INSERT RESIDUAL REGION (ONLY ONE)

singleton set rres(r) "Residual region" /
   USA          "United States"
/ ;

* >>>> MUST INSERT MUV REGIONS (ONE OR MORE)

set rmuv(r) "MUV regions" / AUS, CAN, CHN, DEU, FRA, ITA, JPN, KOR, GBR, USA, XHY / ;

* >>>> MUST INSERT MUV COMMODITIES (ONE OR MORE)

set imuv(i) "MUV commodities" / pfd-c, xlm-c, ppp-c, chp-c, nmm-c, i_s-c, nfm-c, xmn-c / ;

set iedu(i) "Education sector(s)" /
   SRV-c
/ ;

set ihht(i) "Health sector(s)" /
   SRV-c
/ ;

set ia "Aggregate commodities for model output" /
   set.comm
   tagr-c       "Agriculture"
   tman-c       "Manufacturing"
   tnrg-c       "Energy"
   tsrv-c       "Services"
   tprm-c       "Primary commodities"
   tind-c       "Industrial commodities"
   tsvc-c       "Services"
   ttot-c       "Total"
/ ;

set mapia(ia,i) "Mapping for aggregate commodities" /
   tagr-c   .(crp-c, lvs-c, frs-c)
   tman-c   .(oxt-c, pfd-c, xlm-c, ppp-c, chp-c, nmm-c, i_s-c, nfm-c, xmn-c)
   tnrg-c   .(coa-c, oil-c, gas-c, p_c-c, ely-c)
   tsrv-c   .(cns-c, atp-c, wtp-c, otp-c, srv-c)
   tprm-c   .(crp-c, lvs-c, frs-c, oxt-c, coa-c, oil-c, gas-c)
   tind-c   .(pfd-c, xlm-c, ppp-c, chp-c, nmm-c, i_s-c, nfm-c, p_c-c, xmn-c)
   tsvc-c   .(ely-c, cns-c, atp-c, wtp-c, otp-c, srv-c)
/ ;
mapia(ia,i)$sameas(ia,i) = yes ;
mapia("ttot-c",i) = yes ;

set iaa(ia) "Aggregate commodities only" ;
loop((i,ia)$(not sameas(i,ia)), iaa(ia) = yes ; ) ;

set aga "Aggregate activities for model output" /
   set.acts
   tagr-a       "Agriculture"
   tman-a       "Manufacturing"
   tsrv-a       "Services"
   tnrg-a       "Other"
   tprm-a       "Primary activities"
   tind-a       "Industrial activities"
   tsvc-a       "Services"
   ttot-a       "Total"
/ ;

set mapaga(aga,a) "Mapping for aggregate activities" /
   tagr-a   .(crp-a, lvs-a, frs-a)
   tman-a   .(oxt-a, pfd-a, xlm-a, ppp-a, chp-a, nmm-a, i_s-a, nfm-a, xmn-a)
   tnrg-a   .(coa-a, oil-a, gas-a, p_c-a,
              etd-a, els-a, elw-a, elr-a, elh-a, elc-a, elg-a, elo-a, eln-a)
   tsrv-a   .(cns-a, atp-a, wtp-a, otp-a, srv-a)
   tprm-a   .(crp-a, lvs-a, frs-a, oxt-a, coa-a, oil-a, gas-a)
   tind-a   .(pfd-a, xlm-a, ppp-a, chp-a, nmm-a, i_s-a, nfm-a, p_c-a, xmn-a)
   tsvc-a   .(etd-a, els-a, elw-a, elr-a, elh-a, elc-a, elg-a, elo-a, eln-a
              cns-a, atp-a, wtp-a, otp-a, srv-a)
/ ;
mapaga(aga,a)$sameas(aga,a) = yes ;
mapaga("ttot-a",a) = yes ;

set agaa(aga) "Aggregate activities only" ;
loop((a,aga)$(not sameas(a,aga)), agaa(aga) = yes ; ) ;

set ra "Aggregate regions for emission regimes and model output" /
   set.reg
   hic          "High-income countries"
   g20          "G20 countries"
   row          "Non G20 countries"
   lmy          "Developing countries"
   e27          "European Union-27"
   eap          "Developing East Asia"
   sas          "South Asia"
   eca          "Eastern Europe & Central Asia"
   mna          "Middle East & North Africa"
   ssa          "Sub-Saharan Africa"
   lac          "Latin America & Caribbean"
   wld          "World total"
/ ;

set mapra(ra,r) "Mapping for aggregate regions" /
   e27.(deu, fra, ita, xeu)
   hic.(aus, can, deu, fra, ita, xeu, gbr, jpn, sau, kor, usa, xhy)
   g20.(arg, aus, bra, can, chn, deu, fra, ita, ind, idn, jpn, mex, rus, sau, zaf, kor, tur, gbr, usa)
   eap.(chn, idn, xea)
   sas.(ind, xsa)
   eca.(rus, tur, xec)
   mna.(sau, xmn)
   ssa.(zaf, xss)
   lac.(arg, bra, mex, xlc)
/ ;
mapra(ra,r)$sameas(ra,r) = yes ;
mapra("lmy",r)$(not mapra("hic",r)) = yes ;
mapra("row",r)$(not mapra("g20",r)) = yes ;
mapra("wld",r) = yes ;

set rra(ra) "Aggregate regions only" ;
loop((r,ra)$(not sameas(r,ra)), rra(ra) = yes ; ) ;

set lagg "Aggregate labor for output" /
   set.lab
   tot          "Total labor"
/ ;

set maplagg(lagg,l) "Mapping for aggregate labor" ;
maplagg(lagg,l)$sameas(lagg,l) = yes ;
maplagg("tot",l) = yes ;

set nsk(l) "Unskilled types for labor growth assumptions" /
   nsk          "Unskilled labor"
/ ;

set skl(l)  "Skill types for labor growth assumptions" /
   skl          "Skilled labor"
/ ;

set acr(a) "Crop activities" /
   crp-a
/ ;

set alv(a) "Livestock activities" /
   lvs-a
/ ;

set ax(a) "All other activities" /
   frs-a    "Forestry"
   coa-a    "Coal extraction"
   oil-a    "Oil extraction"
   gas-a    "Gas extraction"
   oxt-a    "Other pimary sectors"
   pfd-a    "Processed food"
   xlm-a    "Other light manufacturing"
   ppp-a    "Paper products & publishing"
   chp-a    "Chemicals, rubber and plastics"
   nmm-a    "Non-metallic minerals"
   i_s-a    "Ferrous metals"
   nfm-a    "Other metals"
   xmn-a    "Other manufacturing"
   p_c-a    "Refined oil"
   etd-a    "Electricity transmission and distribution"
   els-a    "Solar power"
   elw-a    "Wind power"
   elr-a    "Other renewable power"
   elh-a    "Hydro power"
   elc-a    "Coal-fired power"
   elg-a    "Gas power"
   elo-a    "Oil power"
   eln-a    "Nuclear power"
   cns-a    "Construction"
   atp-a    "Air transport"
   wtp-a    "Water transport"
   otp-a    "Other transport"
   srv-a    "Services"
/ ;

set agr(a) "Agricultural activities" /
   crp-a, lvs-a, frs-a
/ ;

set man(a) "Manufacturing activities" /
   coa-a    "Coal extraction"
   oil-a    "Oil extraction"
   gas-a    "Gas extraction"
   oxt-a    "Other pimary sectors"
   pfd-a    "Processed food"
   xlm-a    "Other light manufacturing"
   ppp-a    "Paper products & publishing"
   chp-a    "Chemicals, rubber and plastics"
   nmm-a    "Non-metallic minerals"
   i_s-a    "Ferrous metals"
   nfm-a    "Other metals"
   xmn-a    "Other manufacturing"
   p_c-a    "Refined oil"
/ ;

set srv(a) "Service activities" /
   etd-a    "Electricity transmission and distribution"
   els-a    "Solar power"
   elw-a    "Wind power"
   elr-a    "Other renewable power"
   elh-a    "Hydro power"
   elc-a    "Coal-fired power"
   elg-a    "Gas power"
   elo-a    "Oil power"
   eln-a    "Nuclear power"
   cns-a    "Construction"
   atp-a    "Air transport"
   wtp-a    "Water transport"
   otp-a    "Other transport"
   srv-a    "Services"
/ ;

set aenergy(a) "Energy activities" /
   coa-a    "Coal extraction"
   oil-a    "Oil extraction"
   gas-a    "Gas extraction"
   p_c-a    "Refined oil"
   etd-a    "Electricity transmission and distribution"
   els-a    "Solar power"
   elw-a    "Wind power"
   elr-a    "Other renewable power"
   elh-a    "Hydro power"
   elc-a    "Coal-fired power"
   elg-a    "Gas power"
   elo-a    "Oil power"
   eln-a    "Nuclear power"
/ ;

set affl(a) "Fossil fuel activities" /
   coa-a    "Coal extraction"
   oil-a    "Oil extraction"
   gas-a    "Gas extraction"
/ ;

set aw(a) "Water services activities" /
/ ;

set z "Labor market zones" /
   rur          "Agricultural sectors"
   urb          "Non-agricultural sectors"
   nsg          "Non-segmented labor markets"
/ ;

singleton set rur(z) "Rural zone" /
   rur          "Agricultural sectors"
/ ;

singleton set urb(z) "Urban zone" /
   urb          "Non-agricultural sectors"
/ ;

singleton set nsg(z) "Both zones" /
   nsg          "Non-segmented labor markets"
/ ;

set mapz(z,a) "Mapping of activities to zones" /
   rur.(crp-a, lvs-a, frs-a)
/ ;

mapz("urb", a)$(not mapz("rur",a)) = yes ;
mapz("nsg", a) = yes ;

set frt(i) "Fertilizer commodities" /
   chp-c
/ ;

set feed(i) "Feed commodities" /
   crp-c, pfd-c
/ ;

set iw(i) "Water services commodities" /
/ ;

set e(i) "Energy commodities" /
   COA-c        "Coal"
   OIL-c        "Oil"
   GAS-c        "Gas"
   P_C-c        "Petroleum and coal products"
   ELY-c        "Electricity"
/ ;

set elyc(i) "Electricity commodities" /
   ELY-c        "Electricity"
/ ;

set fuel(e) "Fuel commodities" /
   COA-c        "COA"
   OIL-c        "OIL"
   GAS-c        "GAS"
   P_C-c        "P_C"
/ ;

set k "Household commodities" /
   agr-k       "Primary agriculture"
   fud-k       "Other food"
   lmn-k       "Light manufacturing"
   dur-k       "Durable goods"
   trp-k       "Transport services"
   cns-k       "Construction"
   srv-k       "Other services"
   nrg-k       "Energy"
/ ;

set fud(k) "Household food commodities" /
   agr-k       "Primary agriculture"
   fud-k       "Other food"
/ ;

set mapk(k,i) "Mapping from i to k" /
   agr-k . (crp-c, lvs-c, frs-c)
   fud-k . (pfd-c)
   lmn-k . (oxt-c, xlm-c, ppp-c, chp-c)
   dur-k . (nmm-c, i_s-c, nfm-c, xmn-c)
   trp-k . (atp-c, wtp-c, otp-c)
   cns-k . cns-c
   srv-k . srv-c
   nrg-k . (coa-c, oil-c, gas-c, p_c-c, ely-c)
/ ;

set CPINDX "Categories of CPI indices" /
   fud         "Food price index"
   tot         "Total price index"
/ ;

set mapCPI(cpindx,i) "Mapping from i to CPINDX" /
   fud    .(crp-c, lvs-c, pfd-c)
/ ;
mapCPI("tot", i) = yes ;

set elya(a) "Power activities" /
   etd-a    "Electricity transmission and distribution"
   els-a    "Solar power"
   elw-a    "Wind power"
   elr-a    "Other renewable power"
   elh-a    "Hydro power"
   elc-a    "Coal-fired power"
   elg-a    "Gas power"
   elo-a    "Oil power"
   eln-a    "Nuclear power"
/ ;

set etd(a) "Electricity transmission and distribution activities" /
   ETD-a        "Electricity transmission"
/ ;

set primElya(a) "Primary power activities" /
   els-a    "Solar power"
   elw-a    "Wind power"
   elr-a    "Other renewable power"
   elh-a    "Hydro power"
   eln-a    "Nuclear power"

/ ;

set pb "Power bundles in power aggregation" /
   GasP         "Gas bundle"
   OilP         "Oil bundle"
   coap         "Coal bundle"
   nucp         "Nuclear"
   hydp         "Hydro"
   renp         "Renewables"
/ ;

set mappow(pb,elya) "Mapping of power activities to power bundles" /
   GasP     .elg-a
   OilP     .elo-a
   coap     .elc-a
   nucp     .eln-a
   hydp     .elh-a
   renp     .els-a
   renp     .elw-a
   renp     .elr-a
/ ;

set lb "Land bundles" /
   AGR          "Agriculture"
/ ;

set lb1(lb) "First land bundle" /
   AGR          "Agriculture"
/ ;

set maplb(lb,a) "Mapping of activities to land bundles" /
   AGR      .(crp-a, lvs-a)
/ ;

set wbnd "Aggregate water markets" /
   N_A          "N_A"
/ ;

set wbnd1(wbnd) "Top level water markets" /
/ ;

set wbnd2(wbnd) "Second level water markets" /
/ ;

set wbndex(wbnd) "Second level water markets" /
/ ;

set mapw1(wbnd,wbnd) "Mapping of first level water bundles" /
/ ;

set mapw2(wbnd,a) "Mapping of second level water bundle" /
/ ;

set wbnda(wbnd) "Water bundles mapped one-to-one to activities" /
/ ;

set wbndi(wbnd) "Water bundles mapped to aggregate output" /
/ ;

set mape(NRG,e) "Mapping of energy commodities to energy bundles" /
   COA      .COA-c
   OIL      .OIL-c
   OIL      .P_C-c
   GAS      .GAS-c
   ELY      .ELY-c
/ ;

set mapnd1(i,a) "Mapping of commodities to ND1 bundle" ;
set mapnd2(i,a) "Mapping of commodities to ND2 bundle" / / ;

mapnd1(i,a)$(not mapnd2(i,a) and not e(i)) = yes ;

set rq(ra) "Regions submitted to an emissions cap" ;
rq(ra) = no ;

set aets "Agent specific ETS coalitions" /
   All        "ALL agents"
/ ;

$iftheni.modSets %ifModel% == 1
set mapETS(aets,aa) "Mapping of agents to ETS coalitions" ;
mapETS("All", aa) = yes ;

set educMap(r,l,ed) "Mapping of skills to education levels" ;
educMap(r,"nsk","elev0")$mapra("lmy",r) = yes ;
educMap(r,"skl","elev1")$mapra("lmy",r) = yes ;
educMap(r,"skl","elev2")$mapra("lmy",r) = yes ;

educMap(r,"nsk","elev0")$mapra("hic",r) = yes ;
educMap(r,"nsk","elev1")$mapra("hic",r) = yes ;
educMap(r,"skl","elev2")$mapra("hic",r) = yes ;

set sortOrder / sort1*sort106 / ;

*  !!!! We might be able to replace this with code

set mapOrder(sortOrder,is) /
   sort1.crp-a
   sort2.lvs-a
   sort3.frs-a
   sort4.coa-a
   sort5.oil-a
   sort6.gas-a
   sort7.oxt-a
   sort8.pfd-a
   sort9.xlm-a
   sort10.ppp-a
   sort11.chp-a
   sort12.nmm-a
   sort13.i_s-a
   sort14.nfm-a
   sort15.xmn-a
   sort16.p_c-a
   sort17.etd-a
   sort18.els-a
   sort19.elw-a
   sort20.elr-a
   sort21.elh-a
   sort22.elc-a
   sort23.elg-a
   sort24.eln-a
   sort25.cns-a
   sort26.atp-a
   sort27.wtp-a
   sort28.otp-a
   sort29.srv-a
   sort30.crp-c
   sort31.lvs-c
   sort32.frs-c
   sort33.coa-c
   sort34.oil-c
   sort35.gas-c
   sort36.oxt-c
   sort37.pfd-c
   sort38.xlm-c
   sort39.ppp-c
   sort40.chp-c
   sort41.nmm-c
   sort42.i_s-c
   sort43.nfm-c
   sort44.xmn-c
   sort45.p_c-c
   sort46.ely-c
   sort47.cns-c
   sort48.atp-c
   sort49.wtp-c
   sort50.otp-c
   sort51.srv-c
   sort52.NSK
   sort53.SKL
   sort54.CAP
   sort55.LND
   sort56.NRS
   sort57.itax
   sort58.ptax
   sort59.mtax
   sort60.etax
   sort61.vtax
   sort62.ltax
   sort63.ktax
   sort64.rtax
   sort65.vsub
   sort66.wtax
   sort67.dtax
   sort68.ctax
   sort69.ntmY
   sort70.regY
   sort71.hhd
   sort72.gov
   sort73.r_d
   sort74.inv
   sort75.deprY
   sort76.tmg
   sort77.TRD
   sort78.ARG
   sort79.AUS
   sort80.BRA
   sort81.CAN
   sort82.CHN
   sort83.DEU
   sort84.FRA
   sort85.ITA
   sort86.IND
   sort87.IDN
   sort88.JPN
   sort89.MEX
   sort90.RUS
   sort91.SAU
   sort92.ZAF
   sort93.KOR
   sort94.TUR
   sort95.GBR
   sort96.USA
   sort97.XEA
   sort98.XSA
   sort99.XEC
   sort100.XMN
   sort101.XSS
   sort102.XLC
   sort103.XEU
   sort104.XHY
   sort105.BoP
   sort106.tot
/ ;
$endif.ModSets
\end{lstlisting}

\begin{lstlisting}[language=GAMS, caption={Simplest labor bundle}]
   set wb "Intermediate labor bundle(s)" /
      Single       "Single intermediate labor bundle"
   /

   set maplab1(wb) "Mapping of intermediate labor demand bundle(s) to LAB1" /
      Single       "Single intermediate labor bundle"
   /

   set maplab(wb,l) "Mapping of labor types to intermedate demand bundle(s)" /
      Single   .Labour
   /
\end{lstlisting}

\begin{lstlisting}[language=GAMS, caption={Two labor categories in one bundle}]
   set wb "Intermediate labor bundle(s)" /
      Single       "Single intermediate labor bundle"
   /

   set maplab1(wb) "Mapping of intermediate labor demand bundle(s) to LAB1" /
      Single       "Single intermediate labor bundle"
   /

   set maplab(wb,l) "Mapping of labor types to intermedate demand bundle(s)" /
      Single   .NSK
      Single   .SKL
   /
\end{lstlisting}

\begin{lstlisting}[language=GAMS, caption={Two labor categories in separate bundles}]
   set wb "Intermediate labor bundle(s)" /
      Unskilled       "Unskilled labor bundle"
      Skilled         "Skilled labor bundle"
   /

   set maplab1(wb) "Mapping of intermediate labor demand bundle(s) to LAB1" /
      Unskilled       "Map unskilled to LAB1"
   /

   set maplab(wb,l) "Mapping of labor types to intermedate demand bundle(s)" /
      Unskilled   .NSK
      Skilled     .SKL
   /
\end{lstlisting}

\begin{lstlisting}[language=GAMS, caption={Two labor skills by gender}]
   set wb "Intermediate labor bundle(s)" /
      Unskilled       "Unskilled labor bundle"
      Skilled         "Skilled labor bundle"
   /

   set maplab1(wb) "Mapping of intermediate labor demand bundle(s) to LAB1" /
      Unskilled       "Map unskilled to LAB1"
   /

   set maplab(wb,l) "Mapping of labor types to intermedate demand bundle(s)" /
      Unskilled   .(NSK-MAL, NSK-FEM)
      Skilled     .(SKL-MAL, SKL-FEM)
   /
\end{lstlisting}


\begin{table}[H]
\caption{Files distributed with the aggregation facility}
\label{tab:aggGTAPFiles}
\begin{center}
\small
\rowcolors{2}{TableOdd}{TableEven}
\rowcolors{1}{}{lightblue}
\begin{tabular}{p{4.0cm} p{11.0cm}}
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
{\normalsize \textbf{\emph{File name}}} & {\normalsize \textbf{\emph{Description}}} \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\multicolumn{2}{l}{\textbf{\emph{Core code}}} \\
AggGTAP.gms & Main aggregation program \\
aggSAM.gms  & Code to output aggregate SAM in a CSV file \\
aggNRG.gms  & Code to output aggregate energy and emissions in a CSV file \\
SSPSets.gms & Set definitions for reading SSP data file \\
saveMap.gms & Code to save aggregation mappings to be loaded into either Word/Excel or \LaTeX \\
makeset.gms & Code to write out core set definitions for models, both GTAP and \textsc{Envisage} \\
{} & {} \\
\multicolumn{2}{l}{\textbf{\emph{Additional code for \textsc{Envisage} Model}}} \\
makesetEnv.gms   & Code to write additional sets for \textsc{Envisage} \\
AggEnvElast.gms  & Code to aggregate \textsc{Envisage} elasticities \\
aggra.gms        & Batinclude code for aggregating elasticities \\
aggrav.gms       & Batinclude code for aggregating elasticities \\
aggrave.gms      & Batinclude code for aggregating elasticities \\
makeAggSets.gms  & Code to write final sets with appropriate suffixes \\
ConvertLabel.gms & Code to convert labels in aggregated parameter data file \\
{} & {} \\
\multicolumn{2}{l}{\textbf{\emph{Base data set definitions}}} \\
GTAPSets9\_2F.gms   & {Set definitions for standard GTAP database V9.2 ($141 \times 57$)} \\
GTAPSets9\_2PF.gms & {Set definitions for power+water GTAP database V9.0} \\
{} & {} \\
GTAPSets10AF.gms   & {Set definitions for standard GTAP database V10A ($141 \times 65$)} \\
GTAPSets10APOWF.gms & {Set definitions for power GTAP database V10A} \\
{} & {} \\
\multicolumn{2}{l}{\textbf{\emph{Miscellaneous}}} \\
makedata.cmd & Windows command file for facilitating all data processing \\
Macro.gms        & A basic macro model used to calculate potential investment paths for dynamic scenarios \\
nipa.gms     & Optional GAMS code that will output (in CSV format) the national income
and product accounts for the base regions/countries in the GTAP database \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\end{tabular}
\end{center}
\end{table}

The aggregation facility assumes that all of the GTAP-based data files have the
same base name and are located in the same folder.\footnote{Referred to as
'\%GTAPBASE\%' and '\%gtpDir\%, respectively, in the GAMS code.} Note that some
of the files downloaded from GAMS may not follow this convention, in which case
they need to be renamed. The aggregation facility is designed to work
with the GTAP-provided GDX containers, i.e., there is no need to
convert the HAR files.

Table~\ref{tab:GTAPFiles} provides a list of all possible data files that can be
used with the data aggregation facility. Some are required, for obvious reasons.
Others are optional and will depend on user-based options. Note that the
power+water version of the GTAP database includes three extra headers compared
to the standard GTAP database. It has total power generated by electricity in
Gwhr, water withdrawals in irrigated crops and aggregate water withdrawals from
other sectors of the economy.

\begin{table}[H]
\caption{Base Data Files }
\label{tab:GTAPFiles}
\begin{center}
\small
\rowcolors{2}{TableOdd}{TableEven}
\rowcolors{1}{}{lightblue}
\begin{tabular}{p{5.5cm} p{9.5cm}}
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
{\normalsize \textbf{\emph{File name}}} & {\normalsize \textbf{\emph{Description}}} \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\multicolumn{2}{l}{\textbf{\emph{Required GTAP files}}} \\
\%GTAPBASE\%DAT.gdx   & File containing base SAM data \\
\%GTAPBASE\%PAR.gdx   & File containing base parameter values for GTAP model \\
\%GTAPBASE\%VOLE.gdx  & File containing base energy volume data \\
\%GTAPBASE\%EMISS.gdx & File containing base $\textrm{CO}_2$ emissions data \\
{} & {} \\
\multicolumn{2}{l}{\textbf{\emph{Optional data files}}} \\
\%GTAPBASE\%NCO2.gdx   & File containing base non-$\textrm{CO}_2$ emissions data \\
\%GTAPBASE\%BOP.gdx    & File containing remittances and cross-border profit flows. The former
is sourced from the 'GMIG' database and the latter from the 'GDYN' database. \\
\%GTAPBASE\%ELAST.gdx  & Data file containing key land and natural resource supply parameters.
This file is not part of the standard GTAP suite and is described in more detail below [TBD].
If the file does not exist, these parameters will be set to default values. \\
\%GTAPBASE\%WAGES.gdx  & File containing wage/employment splits for labor remuneration. This
file is part of the 'GMIG' database. Its use is described below [TBD]. \\
\%GTAPBASE\%MRIO.gdx  & File containing the split of import demand by
end-user. This data is used for the Multi-Regional Input-Output version
of the model, also referred to as the Global Value Chain (GVC) version. Note that
the MRIO database has only three end-users: 'INT' for all intermediate demand;
'CONS' for private and public expenditures; and 'CGDS' for investment
expenditures. The initialization module of the CGE models assumes
proportionality across end-users within each of the broad categories. Use of this
module requires setting the \texttt{ifMRIO} flag (see below).\footnote{At the moment,
neither the Filter or the Altertax modules use the MRIO data.} \\
{} & {} \\
\multicolumn{2}{l}{\textbf{\emph{Other data files}}} \\
\%SSPFILE\%   & Data file containing projections for population and GDP for 230
countries for all 5 Shared Socio-Economic Pathways (SSPs)---further described
below [TBD]. In addition, the file contains the UN's population projections for
the 2010, 2012, 2015 and 2017 revisions. \\
\%GIDDLAB\%   & Data file containing an alternative wage/employment split. The World Bank's
Global Income Distribution Dynamics (GIDD) Model provides an alternative
set for employment levels. Note that the GIDD data is only provided for
two types of labor---unskilled and skilled. \\
\%GIDDPROJ\%  & Data file containing population projections (including
education levels) from the GIDD. \\
{} & {} \\
\multicolumn{2}{l}{\textbf{\emph{Parameter files}}} \\
\%EnvElast\%  & File containing disaggregated elasticities for use with the \textsc{Envisage} Model. Two
files are distributed. One for the standard GTAP database and the other for the power+water version. \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\end{tabular}
\end{center}
\end{table}

The SSP file is a combination of data from different sources and time
periods. The following describes the data in the file.
\begin{enumerate}
\item \emph{PopHist} This matrix contains population from 1950 through 2100,
normally sourced from the last available UN population projection.\footnote{Currently
the 2019 revision (\url{https://population.un.org/wpp/})}. The projections are
for the Medium variant. It is provided for each of
230 countries\footnote{The country definition for this file continues to hone
to the 2010 UN definitions. With Revision 2019, the UN has 235 countries. We map
5 to the original definition. Thus Saint {Barth\'elemy} and Saint Martin
(French Part) are mapped to Guadeloupe (GLP), {Cura\c{c}ao} and Sint Maarten (Dutch part)
are mapped to the Netherlands Antilles (ANT) and South Sudan is mapped to Sudan (SDN).}
for an aggregation of four cohorts: aged between 0 and 14 inclusive (\texttt{PLT15}),
aged between 15 and 64 inclusive (\texttt{P1564}) typically associated with the
working age population, aged 65 and above (\texttt{P65UP}), and all ages (\texttt{PTOTL}).
\item \emph{Pop} This matrix contains the population projections
from 2007 through 2100. It is defined for all 5 SSPs and also
includes 5 UN projections: Revision 2010, 2012, 2015, 2017 and 2019.
The 2007 through 2010 period is from the UN. The 2010-2100 SSP data
is from the SSP database, using the growth rates---the 2010 level
is based on UN numbers. The SSP database has been annualized using
cubic splines and gap filled for missing countries.\footnote{Database
construction details are available from the author.} The population
projections have the same 4 cohorts as defined above.
\item \emph{PopScen} This is essentially the same data as in the
previous item with additional information for each cohort: gender (\texttt{MAL}, \texttt{FEM},
\texttt{BOTH}), and educational attainment (\texttt{ENONE}, \texttt{EPRIM}, \texttt{ESECN}, \texttt{ETERT}, \texttt{ETOTL}).
It includes the UN projections as well, but only for \texttt{ETOTL}.
All data is annualized and gap filled.
\item \emph{GDPScen} This matrix contains GDP projections from 2007 through
2100. The standard data (\texttt{GDP} and \texttt{GDPPC}) use 2007
prices and market exchange rates (MER). Growth from 2007 through 2010
is based on observed rates. There are two versions of the 2010 through 2100
growth rates. The first (V9\_1) uses the original SSP database for the entire
period (annualized and gap filled for missing countries). It only uses
the growth rates as the reference level is 2010 (albeit in 2007 prices
and MER). An alternative version (V9\_2) still has the 2010 reference
year, but uses the Fall 2019 World Economic Outlook (WEO) forecast from
the International Monetary Fund (IMF) to replace the 2010-2020 SSP
projections with the observed trends (albeit with a projection for 2019
and 2020---excluding the Covid-19 pandemic). The SSP projections
include projections from two models: OECD and IIASA.\footnote{The PIK SSP forecasts
were not included because they are available only at a 32-region aggregate
level unlike the OECD and IIASA projections. We are also considering
adding the CEPII SSP projections.} There could be sharp
discontinuities in the growth rates at the 2020 transition
point. The matrix also contains the data
evaluated at 2005 prices and purchasing power parity exchange rates
(\texttt{GDPPPP05} and \texttt{GDPPCPPP05}).
\item \emph{GHGHist} This matrix contains historical data for GHG emissions.
It should be used with caution as it is new and not thoroughly vetted.
Most of the data is sourced from the World Bank's WDI database. It includes
emissions of carbon dioxide (\COT{}), methane ($\textrm{CH}_4$),
nitrous oxide ($\textrm{N}_2\textrm{O}$) and a composite of
fluorinated gases (\texttt{FGAS}). It also includes
energy use per capita (\texttt{NRGUSE}) in tons of oil equivalent
per capita.\footnote{The data also contains HFC, PFC, SF6, LUCFNET
and GHGT.} All greenhouse gases are measured in megatons of
\COT{}-equivalent. WDI is missing data for key countries---mostly
due to the transition economies in Europe. For the Annex I
countries, the data is sourced from the UNFCCC.
\end{enumerate}

\subsubsection{Optional backstop fuel files}

[This is ongoing work]

Each backstop is associated with the cost structure of an initial energy source,
for example coal-power with CCS is associated with coal-power thermal
generation. For the moment, it is assumed that all the increase in cost
is embedded in the capital cost. Thus if the total cost
of the backstop is twice the 'conventional' cost, all of the increase
is embedded in the cost of capital. If $\chi$ is the cost multiplier,
we have the following formula for the cost shares all the non-capital inputs:
\[
X_{i,b} = \frac{X_{i,a}} { \mathit{VOS}_{a}}
\]

\noindent where, $b$ is the backstop,
$a$ is the associated cost activity,
$X$ is the value of the input and $\mathit{VOS}$ is
the total cost. The capital share formula is:

\[
X_{k,b} = \chi_b - \left( 1 - \frac{X_{k,a}}{\mathit{VOS}_{a}}\right)
\]

\noindent where $k$ is the capital input.

\subsubsection{Filter module files}

The filter module files are scattered in two
folders---see Table~\ref{tab:fltGTAPFiles}. The \emph{Data} folder contains the
calling \texttt{filter} routine and two user prepared files. The core files for
the Filter module are all in the \emph{Filter} sub-folder.

\begin{table}[H]
\caption{Files distributed with the Filter module}
\label{tab:fltGTAPFiles}
\begin{center}
\small
\rowcolors{2}{TableOdd}{TableEven}
\rowcolors{1}{}{lightblue}
\begin{tabular}{p{4.0cm} p{11.0cm}}
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
{\normalsize \textbf{\emph{File name}}} & {\normalsize \textbf{\emph{Description}}} \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\multicolumn{2}{l}{\textbf{\emph{Files in core 'Data' directory}}} \\
Filter.gms & GAMS file invoking core filter code \\
\emph{basename}Flt.gms & User prepared file with filter options \\
\emph{basename}Map.gms & User prepared file with key mappings---same file used for Aggregation facility \\
{} & {} \\
\multicolumn{2}{l}{\textbf{\emph{Additional code for Filter module in the 'Filter' directory}}} \\
filter.gms        & GAMS code containing core filter algorithm \\
remTinyValues.gms & Code to remove tiny value flows \\
itrlog.gms        & Code that creates diagnostics for the Filter module \\
title.gms         & Code mostly intended for the CGEBox GUI \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\end{tabular}
\end{center}
\end{table}

\subsubsection{Altertax module files}

The Altertax files are scattered in three folders,
see Table~\ref{tab:AltGTAPFiles}. The main \emph{Data} folder contains
\texttt{Altertax.gms} and the user options file \texttt{[basename]Alt.gms}.
The sub-folder \emph{GTAPModel} contains the core code for the GAMS-based GTAP
model. The sub-folder \emph{Altertax} contains a single file with the parameter
definitions needed to run the GTAP model. Note that many of the parameters will
be over-ridden by Altertax to make all CES functions (and the utility function)
Cobb-Douglas, further described below.

\begin{table}[H]
\caption{Files distributed with the Altertax module}
\label{tab:AltGTAPFiles}
\begin{center}
\small
\rowcolors{2}{TableOdd}{TableEven}
\rowcolors{1}{}{lightblue}
\begin{tabular}{p{4.0cm} p{11.0cm}}
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
{\normalsize \textbf{\emph{File name}}} & {\normalsize \textbf{\emph{Description}}} \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\multicolumn{2}{l}{\textbf{\emph{Files in core 'Data' directory}}} \\
Altertax.gms & GAMS file invoking core GTAP model code \\
\emph{basename}Alt.gms & User prepared file with the Altertax shock \\
{} & {} \\
\multicolumn{2}{l}{\textbf{\emph{Additional code for Altertax module in the 'GTAPModel' directory}}} \\
model.gms & GAMS code containing core GTAP model specification \\
getData.gms & GAMS code to read core database(s) \\
cal.gms & GAMS code containing variable and parameter initialization and calibration \\
iterloop.gms & Code containing instructions to prepare a new solve statement \\
solve.gms & Code invoking a GAMS solver \\
postsim.gms & Code saving model results in a CSV-formatted file \\
emiCSV.gms & Code to save emission results in a CSV-formatted file \\
saveData.gms & Code saving model results in GDX-formatted files with
the same structure as the input GTAP-based data files \\
{} & {} \\
\multicolumn{2}{l}{\textbf{\emph{Additional code for Altertax module in the 'AlterTax' directory}}} \\
AlterTaxPrm.gms & GAMS code containing default elasticities for GTAP model. \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\end{tabular}
\end{center}
\end{table}

\subsubsection{Data sub-folders}
Each aggregation project, with its code, will be associated with a data folder
that has the same name as the project. So if the code for the project is
'10x10', for example, the data from the data preparation modules will be
contained in the folder '10x10'. The output from each module is contained in
its own sub-folder of which there are four named \texttt{Agg}, \texttt{Flt},
\texttt{Alt} and \texttt{Fnl}. The last folder contains the final results from
running the three modules. If a module is skipped, all the data files from the
previous module should be copied over to the next folder. Users can create these
folders, or use the automated Windows command file called \texttt{makedata.cmd}
that is further described below. The \texttt{makeData} command file also
automates the moving of files across folders. Figure~\ref{fig:DataDirStr}
provides a visual guide to the directory structure of the output data.

\begin{figure}[H]
\center
\begin{forest}
for tree={
   minimum height=1cm,
   font=\scriptsize,
%  font=\sffamily,
   anchor=north,
   align=center,
   child anchor=north,
   s sep=1em,
   l sep=0.75cm
},
%where n children=0{tier=word}{}
[{[basename] \\ 10x10 for example}, draw, drop shadow, fill=dkBlue, rounded corners=2pt, name=Root
   [{Agg}, draw, drop shadow, fill=mdBlue, rounded corners=2pt]
   [{Flt}, draw, drop shadow, fill=mdBlue, rounded corners=2pt]
   [{Alt}, draw, drop shadow, fill=mdBlue, rounded corners=2pt]
   [{Fnl}, draw, drop shadow, fill=mdBlue, rounded corners=2pt]
]
\end{forest}
\caption{{Directory structure of output data}}
\label{fig:DataDirStr}
\end{figure}

\subsection{Aggregation}

From the user perspective aggregation involves the preparation of the map file
that will contain the aggregation mappings as well as miscellaneous other
information required for the data facility. The mapping file has two components.
The first part relates to a generic aggregation of the GTAP database and its
components. It hones closely to the GTAPAgg and FlexAgg facilities available for
GEMPACK users. The second component is specific to aggregation for the
\textsc{Envisage} Model.

\subsubsection{Global options}

The first part of a map file contains global options for the aggregation.
Listing~\ref{lst:MapOpt} provides an example of the preamble statements for a
mapping file.
\begin{lstlisting}[language=GAMS, caption={Global options for the MAP file}, label=lst:MapOpt]
$setGlobal DIAG          ON
$setGlobal DYN           ON
$setGlobal MACRO         ON
$setGlobal ifPower       ON
$setGlobal ifWater       OFF
$setGlobal NCO2          ON
$setGlobal ELAST         OFF
$setGlobal LAB           ON
$setGlobal BoP           ON
$setGlobal SAVEMAP       TXT
$setGlobal LU_MODULE     OFF
$setGlobal RD_MODULE     OFF
$setGlobal DEPL_MODULE   OFF
$setGlobal MRIO_MODULE   OFF
$setGlobal ifGENDER      OFF
$setGlobal ifBKSTOP      OFF
$setGlobal ifMultH       OFF
$setGlobal ifDAMAGE      ON

*  Only used to override GTAP parameters for Env model

$setGlobal OVRRIDEGTAPARM 1
$setGlobal OVRRIDEGTAPINC 1

*  Select a labor option
*  Valid options are:
*     noLab  -- ignore employment volumes (all wages are set to 1)
*     agLab  -- calculate ag and non-ag employment (wages uniform within zones)
*     allLab -- assume employment data is correct for each sector (wages differ for each sector)
*     giddLab -- Use the GIDD labor data

$macro IFLABOR noLab

$include "GTAPSets10APOWF.gms"

$setGlobal gtpDir    "V:/GTAP10/V10APOW"
$setGlobal GTAPBASE  "GSDF"
$setGlobal SSPFile   "../SatAcct/sspScenV9.gdx"
$setGLobal DEPLFile  "../SatAcct/RystadGTAP2014.gdx"
$setGlobal giddLab   "../SatAcct/giddLab.gdx"
$setGlobal giddProj  "../SatAcct/giddProj.gdx"
$setGlobal EnvElast  "../SatAcct/EnvLinkElast10APOW.gdx"
$onempty
\end{lstlisting}

The first set of options turn on or off various
features of the aggregation. These are described in further detail in
Table~\ref{tab:MAPopt}.

\begin{table}[H]
\caption{Global options for the MAP file}
\label{tab:MAPopt}
\small
\begin{center}
\rowcolors{2}{TableOdd}{TableEven}
\rowcolors{1}{}{lightblue}
\begin{tabular}{p{3.4cm} p{12.1cm}}
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
{\normalsize \textbf{\emph{Option name}}} & {\normalsize \textbf{\emph{Description}}} \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
DIAG     &  Assumes input database if diagonal. (Alternatives are not yet in use.) \\
DYN      &  If this option is set to ON, the aggregation facility will read the
            SSP and GIDD projection files and create an aggregated scenario file. \\
MACRO    &  If this option is set to ON, the aggregation facility use the
SSP projections and the aggregated database to run a simple macro model, the purpose
of which is to calculate a plausible target path for investment from the reference year to
2100. This further described elsewhere [TBD]. \\
ifPower  &  If this option is set to ON, the aggregation facility will retrieve
            the Gwhr information from the GTAP (power) database and
            aggregate. \\
ifWater  &  If this option is set to ON, the aggregation facility will retrieve
            the water volume information from the GTAP (water) database and
            aggregate. \\
NCO2     &  If this option is set to ON, the aggregation facility will retrieve
            the non-$\textrm{CO}_2$  information from the non-$\textrm{CO}_2$
            database and aggregate. \\
ELAST    &  If this option is set to ON, the aggregation facility will retrieve
            the land and natural resource parameters from the relevant 'ELAST'
            file. It should be set to OFF for an \textsc{Envisage} aggregation
               as the same parameters are contained in the parameter file. \\
LAB      &  If this option is set to ON, the aggregation facility will retrieve
            the employment data from one of the available databases---either
            GTAP or the GIDD---and aggregate. The exact type of aggregation will
            depend on the IFLABOR option described below. \\
BOP      &  If this option is set to ON, the aggregation facility will retrieve
            the additional balance of payments data from the 'BOP' database and
            aggregate. \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\end{tabular}
\end{center}
\end{table}

\begin{table}[H]
\caption*{Table~\ref{tab:MAPopt} Global options for the MAP file, ctd.}
\small
\begin{center}
\rowcolors{2}{TableOdd}{TableEven}
\rowcolors{1}{}{lightblue}
\begin{tabular}{p{3.4cm} p{12.1cm}}
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
{\normalsize \textbf{\emph{Option name}}} & {\normalsize \textbf{\emph{Description}}} \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
SAVEMAP  &  This option takes two values: 'TXT' and 'LATEX'. The 'TXT' option
            will save the aggregation mappings in a file called
            '[baseBame]Sets.txt'. It is a comma delimited text file (CSV) that
            contains the aggregation mappings from the original GTAP database to
            the model-level aggregation. It can be loaded into Excel and the
            \texttt{Data|Convert to Columns} command can be used to convert the
            data into a table with three columns, using the 'comma' delimiter
            option. It is then easy to copy the table into Word. The 'LATEX'
            option creates a file with the name '[baseName]Sets.tex' and creates
            three relatively generic tables that can be included in a
            \LaTeX{} file. The user may have to edit the file to convert special
            characters---such as underscores ('\_') and ampersands ('\&'). \\
LU\_MODULE       &  If this option is set to ON, the aggregation facility will make use
of the GTAP AEZ land-use database. [This is under development.] \\
RD\_MODULE       &  If this option is set to ON, the aggregation facility will include
a new final demand agent labeled \texttt{R\_D}. N.B. This requires that
the label is part of the main \emph{'Sets'} file, e.g., \texttt{GTAPSets10AF}. \\
DEPL\_MODULE       &  This turns on the resource depletion
module for coal, oil and gas. \\
MRIO\_MODULE       &  This turns on the MRIO module. Requires the MRIO database. \\
ifGENDER & This turns on the gender-aware database for labor. It requires
the GIDD employment database. \\
ifBKSTOP & Creates backstop technologies. Under development. \\
ifMultH & Used for multi-household databases. Under development. \\
ifDamage & Turns on the climate damage and adaptation module. Under development.\\
OVRRIDEGTAPARM & Currently ignored and to be reviewed. \\
OVRRIDEGTAPINC &  If this option is set to 1, the income elasticities will be
                  taken from the input base parameter file. If the option is set
                  to 0, the GTAP income elasticities prevail and override the
                  income elasticities from the parameter file. \\
IFLABOR        &  This option takes four possible values. The first value is
                  'noLab'. In this case the employment volumes are ignored and
                  in effect all wages are set to 1. The second value is 'agLab'.
                  In this case the volume data is used to aggregate agricultural
                  and non-agricultural employment. Within each of these two
                  broad sectors wages are assumed to be uniform across sectors
                  and in effect the implicit inter-sectoral wage differences are
                  ignored. The purpose of this is to minimize potential welfare
                  implications by assuming heterogeneous inter-sectoral wages
                  (apart from the ag/non-ag distinction). The third option is
                  'allLab' in which case the employment volume data is fully
                  utilized and explicit inter-sectoral wages are assumed to
                  hold. The fourth option is 'giddLab' in which case the GIDD
                  employment volumes are used to determine the wage/employment
                  split. Note that the GIDD option implies a skill/non-skilled
                  labor aggregation. \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\end{tabular}
\end{center}
\end{table}

Following the global options, the next line is an include file for the base data's set
definitions. The distribution comes with two prepared set definition
files---one for the standard GTAP database and the other for the power
database.\footnote{These are currently available for Version 10A of the GTAP Data Base.
Please contact the Center for prior versions.}
The following set of lines provide information for locating the input
databases. The first is the location of all of the GTAP data files (DAT, PAR,
VOLE, EMISS, NCO2, BOP, ELAST and WAGES). The second line provides the base name
for the GTAP files, for example GSDF or GSDFP---the latter stands for the
power database. The remaining four lines refer to the path name of
the other input databases---the SSP projection file,
the natural resource depletion data (if the
depletion module is being used), the two GIDD databases and
the file of disaggregated \textsc{Envisage} elasticities.

\subsubsection{Standard mappings}

The second part of the mapping file contains the standard mappings---this is
aimed for the GTAP model and hones very closely to GTAPAGG, the GEMPACK-based
aggregation facility.\footnote{The current mappings rely
on V10A of the GTAP Data Base.}
Users define the aggregated sets for
activities/commodities, regions and factors of production---with their
respective mappings to the full GTAP database. Users have some flexibility in
how to define these sets and mappings and the distribution comes with two
examples.

Listing~\ref{lst:StdMap} provides an example that is virtually identical to the
10x10 mapping example from GTAP. A first set \emph{i} is defined that contains
the 10 aggregate sectors. Note that since the current database is diagonal, as
is the output from the aggregation facility, the set for activities (\emph{a})
is aliased with the set for sectors (\emph{i}). Similarly, the user defines set
\emph{r} for regions and $\mathit{fp}$ for the factors of production. These
basic sets are subsequently decomposed into a number of subsets---most of which
are fairly obvious. Some do have implications for the model:

\begin{itemize}
   \item The user has flexibility in defining the labor bundles. The model has
   two fixed labor bundles: $\mathit{LAB1}$ and $\mathit{LAB2}$. Subordinate labor
   bundles are user-defined and then two mappings are required. The first
   maps the subordinate labor bundles to either $\mathit{LAB1}$ or $\mathit{LAB2}$.
   The second mapping maps the specific labor types to one (and only one) of the
   subordinate bundles. Say for example there are two skills: \texttt{UnSkLab} and
   \texttt{SkLab}---and both are mapped to a single bundle, i.e. are directly
   substitutable. One subordinate bundle is needed, call is \texttt{SINGLE} and
   it is mapped to $\mathit{LAB1}$ (using the mapping set \texttt{mapLAB1}).
   The other mapping maps both skill types to \texttt{SINGLE}. An alternative
   is to map \texttt{UnSkLab} to $\mathit{LAB1}$ and \texttt{SkLab} to $\mathit{LAB2}$.
   In this case, two subordinate bundles are required, say \texttt{NSK}
   and \texttt{SKL} and \texttt{UnSkLab} is mapped to the bundle \texttt{NSK}
   and \texttt{SkLab} is mapped to \texttt{SKL}. Finally, the \texttt{NSK} subordinate
   bundle needs to be mapped to $\mathit{LAB1}$ using the  mapping set \texttt{mapLAB1}. (Any
   subordinate bundle not mapped to $\mathit{LAB1}$ will automatically be mapped to $\mathit{LAB2}$.)
   This implementation of the labor bundles appears redundant as the subordinate mappings,
   in either case, are not adding to the model specification. It can help when labor
   has additional characteristics---such as gender, origin of the worker, or
   the level of formality. Take the gender example. One could have the subordinate
   bundles be skilled and unskilled labor, both mapped to $\mathit{LAB1}$, and then
   have a subsequent mapping that maps the skill/gender qualifications to the
   relevant subordinate bundles. One would map \texttt{UnSkLab\_M} and \texttt{UnSkLab\_F}
   to \texttt{NSK} and \texttt{SkLab\_M} and \texttt{SkLab\_F} to \texttt{SKL}.
   It is the user's responsibility to make sure that the substitution elasticities
   are appropriately set for the respective bundles---in the case of the
   gender-based bundles, one needs a substitution elasticity between skilled and
   unskilled workers and two subsidiary elasticities: (1) across gender for
   unskilled workers; and (2) across gender for skilled workers.
   \item The subset $\mathit{lr}$ determines the labor types used to calculate
         the skill premium. This became necessary with the new GTAP database
         that has 5 labor types. \item The $\mathit{wat}$ subset should be empty
         in the absence of the water factor---only available with the
         power+water database.
   \item The $\mathit{mapz}$ mapping defines the ag vs. non-ag activities. This
         is only used to determine ag vs. non-ag wages in the case the 'IFLABOR'
         option is set to \emph{agLab}.
   \item The set $\mathit{mapt}$ will instruct the aggregation facility to merge
         land and capital payments into capital payments only---for the selected
         activities. For example, it is possible to remove the land payment in
         other livestock (the \texttt{oap} sector).
   \item The set $\mathit{mapn}$ has the same purpose, but for the natural
         resource factor. For example, one may wish to delete the natural
         resource factor payment if the \texttt{omn} activity is merged with
         manufacturing; as depending on the supply elasticity of the natural
         resource, this may overly restrict output expansion (or contraction).
\end{itemize}

Post-simulation analysis of the results allow for aggregation of activities,
commodities, regions and labor. These are at the full discretion of the user.
The aggregate sets are given respectively by $\mathit{aga}$, $\mathit{ia}$,
$\mathit{ra}$ and $\mathit{lagg}$. The aggregation facility will automatically
append the suffixes '-a' and '-c' for the individual activities and commodities,
respectively. So it would be usual practice to define the aggregation set items
with the '-a' and '-c' suffixes for compatibility. For purposes of
post-simulation, these sets will also include the individual set items. For
example, the aggregation facility will write out the final set $\mathit{ra}$ as
the union of the set $\mathit{r}$ and $\mathit{ra}$, but the user only needs to
provide the definitions for the aggregate items as the aggregation facility will
take care of merging the two sets. The definition of these aggregations (with
their respective mappings) simplifies the output code. For example, the code to
aggregate GDP across regions takes the form:

\begin{lstlisting}[language=GAMS]

loop(ra, put ra.tl, (sum(r$mapra(ra,r), gdp(r)) / ; ) ;

\end{lstlisting}

\noindent where the mapping $\mathit{mapra}$ defines the aggregation mapping for
each region $\mathit{ra}$, including the individually modeled regions.

The aggregation facility requires the factor mobility parameters for the GTAP
model. This is given in the parameter \texttt{etrae1}. In the sample map file,
\texttt{etrae1} is initilized with \texttt{etrae0} that has no regional index
and thus the key factor mobility elasticities in all regions are identical, but
this is not a requirement.

The new GTAP standard model has an explicit make matrix. Multi-product
activities are governed by a CET function with the transformation elasticity
provided by \texttt{etraq1} with a default value of 5. The formation of supply
from production of multiple activities is governed by a CES function with a
substitution provided by \texttt{esubq1} with a default elasticity of $\infty$.
Similarly, the new GTAP standard model has new flexibility regarding the CES
expenditure elasticities for government, investment and the formation of
transportation margins. These are represented respectively in the parameters
\texttt{esubg1}, \texttt{esubi1} and \texttt{esubs1}. These are initialized to
their default values. At the moment it is best to assume that the input
database is diagonal. This is guaranteed by adding code to make
the commodity mapping identical to the activity mapping (see lines 266-271).

The aggregation mappings are relatively self-explanatory. The exception may be
the mapping $\mathit{mapl}$ that will match the user-input labor types to the
GIDD labor labels that are fixed.

\begin{lstlisting}[language=GAMS, caption={Standard mappings}, label=lst:StdMap]
sets

   i  "Commodities"   /
      GrainsCrops    "Grains and Crops"
      MeatLstk       "Livestock and Meat Products"
      Extraction     "Mining and Extraction"
      ProcFood       "Processed Food"
      TextWapp       "Textiles and Clothing"
      LightMnfc      "Light Manufacturing"
      HeavyMnfc      "Heavy Manufacturing"
      Util_Cons      "Utilities and Construction"
      TransComm      "Transport and Communication"
      OthServices    "Other Services"
      /

   r  "Regions" /
      Oceania        "Australia, New Zealand"
      EastAsia       "East Asia"
      SEAsia         "Southeast Asia"
      SouthAsia      "South Asia"
      NAmerica       "North America"
      LatinAmer      "Latin America"
      EU_28          "European Union 28"
      MENA           "Middle East and North Africa"
      SSA            "Sub-Saharan Africa"
      RestofWorld    "Rest of World"
      /

   fp  "Factors of production"  /
      UnSkLab        "Unskilled labor"
      SkLab          "Skilled labor"
      Capital        "Capital"
$iftheni.ifLU "%LU%" == "ON"
      AEZ1           "LGP000_060"
      AEZ2           "LGP060_119"
      AEZ3           "LGP120_179"
      AEZ4           "LGP180_239"
      AEZ5           "LGP240_299"
      AEZ6           "LGP300PLUS"
$else.ifLU
      Land           "Land"
$endif.ifLU
      NatRes         "Natural resource"
      /

   l(fp)  "Labor factors" /
      UnSkLab        "Unskilled labor"
      SkLab          "Skilled labor"
      /
   lr(l) "Reference labor for skill premium" /
      SkLab          "Skilled labor"
      /
   wb "Intermediate labor bundle(s)" /
      Single         "Single intermediate labor bundle"
   /
   maplab1(wb) "Mapping of intermediate labor demand bundle(s) to LAB1" /
      Single
   /
   mapl(wb,l) "Mapping of labor categories to intermedate demand bundle(s)" /
      Single.(UnSkLab, SkLab)
   /
   cap(fp) "Capital" /
      Capital        "Capital"
      /
   lnd(fp) "Land endowment" /
$iftheni.ifLU "%LU%" == "ON"
      AEZ1           "LGP000_060"
      AEZ2           "LGP060_119"
      AEZ3           "LGP120_179"
      AEZ4           "LGP180_239"
      AEZ5           "LGP240_299"
      AEZ6           "LGP300PLUS"
$else.ifLU
      Land           "Land"
$endif.ifLU
      /
   nrs(fp) "Natural resource" /
      NatRes         "Natural resource"
      /
   wat(fp) "Water resource" /
      /

   ra "Aggregate regions for emission regimes and model output" /
      hic   "High-income countries"
      lmy   "Developing countries"
      wld   "World Total"
      /
   ia "Aggregate commodities for model output" /
      tagr-c      "Agriculture"
      tman-c      "Manufacturing"
      tsrv-c      "Services"
      toth-c      "Other"
      ttot-c      "Total"
      /
   aga  "Aggregate activities for model output" /
      tagr-a      "Agriculture"
      tman-a      "Manufacturing"
      tsrv-a      "Services"
      toth-a      "Other"
      ttot-a      "Total"
      /
   lagg "Aggregate labor for model output" /
      tot         "Total labor"
      /
;

*  !!!! Explicit assumption about diagonality

alias(i,a) ;

alias(m,i) ;

*  User defined parameters (i.e. not aggregated by aggregation facility)
*  NEW -- New region specific

Parameter
   etrae1(fp,r) "CET transformation elasticities for factor allocation"
;

parameter etrae0(fp) "CET transformation elasticities for factor allocation" /
   UnSkLab   inf
   SkLab     inf
   Capital   inf
$iftheni.ifLU "%LU%" == "ON"
      AEZ1   1.0
      AEZ2   1.0
      AEZ3   1.0
      AEZ4   1.0
      AEZ5   1.0
      AEZ6   1.0
$else.ifLU
      Land   1.0
$endif.ifLU
   NatRes   0.001
/ ;

etrae1(fp,r) = etrae0(fp) ;

*  NEW -- MAKE ELASTICITIES

Parameter
   etraq1(a,r)       "MAKE CET Elasticity"
   esubq1(i,r)       "MAKE CES Elasticity"
;
etraq1(a,r) = 5 ;
esubq1(i,r) = inf ;

*  NEW -- EXPENDITURE ELASTICITIES

Parameter
   esubg1(r)         "Government expenditure CES elasticity"
   esubi1(r)         "Investment expenditure CES elasticity"
   esubs1(m)         "Transport margins CES elasticity"
;

esubg1(r) = 1 ;
esubi1(r) = 0 ;
esubs1(m) = 1 ;

*  This zonal mapping is for labor/volume splits between agriculture and other

set mapz(z,a)  "Mapping of activities to zones" /
   rur.(GrainsCrops,MeatLstk)
/ ;

mapz("urb",a) = not mapz("rur",a) ;
mapz("nsg",a) = yes ;

* >>>> MUST INSERT RESIDUAL REGION (ONLY ONE)

set rres(r) "Residual region" /

   NAmerica

/ ;

* >>>> MUST INSERT MUV REGIONS (ONE OR MORE)

set rmuv(r) "MUV regions" /

   Oceania
   EastAsia
   NAmerica
   EU_28

/ ;

set mapt(a) "Merge land and capital payments in the following sectors" /

/ ;

set mapn(a) "Merge natl. res. and capital payments in the following sectors" /

/ ;

*  MAPPINGS TO GTAP

set mapa(acts,a) /
   pdr . GrainsCrops
   wht . GrainsCrops
   gro . GrainsCrops
   v_f . GrainsCrops
   osd . GrainsCrops
   c_b . GrainsCrops
   pfb . GrainsCrops
   ocr . GrainsCrops
   ctl . MeatLstk
   oap . MeatLstk
   rmk . MeatLstk
   wol . MeatLstk
   frs . Extraction
   fsh . Extraction
   coa . Extraction
   oil . Extraction
   gas . Extraction
   oxt . Extraction
   cmt . MeatLstk
   omt . MeatLstk
   vol . ProcFood
   mil . ProcFood
   pcr . GrainsCrops
   sgr . ProcFood
   ofd . ProcFood
   b_t . ProcFood
   tex . TextWapp
   wap . TextWapp
   lea . LightMnfc
   lum . LightMnfc
   ppp . LightMnfc
   p_c . HeavyMnfc
   chm . HeavyMnfc
   bph . HeavyMnfc
   rpp . HeavyMnfc
   nmm . HeavyMnfc
   i_s . HeavyMnfc
   nfm . HeavyMnfc
   fmp . LightMnfc
   mvh . LightMnfc
   otn . LightMnfc
   ele . HeavyMnfc
   eeq . HeavyMnfc
   ome . HeavyMnfc
   omf . LightMnfc
   ely . Util_Cons
   gdt . Util_Cons
   wtr . Util_Cons
   cns . Util_Cons
   trd . TransComm
   afs . TransComm
   otp . TransComm
   wtp . TransComm
   atp . TransComm
   whs . TransComm
   cmn . TransComm
   ofi . OthServices
   ins . OthServices
   rsa . OthServices
   obs . OthServices
   ros . OthServices
   osg . OthServices
   edu . OthServices
   hht . OthServices
   dwe . OthServices
/ ;

$iftheni "%DIAG%" == ON
   set mapi(comm,i) ;
   loop((acts,comm)$sameas(acts,comm),
      mapi(comm,i) = mapa(acts,i) ;
   ) ;
$endif

set mapr(reg,r) /
   aus . Oceania
   nzl . Oceania
   xoc . Oceania
   chn . EastAsia
   hkg . EastAsia
   jpn . EastAsia
   kor . EastAsia
   mng . EastAsia
   twn . EastAsia
   xea . EastAsia
   brn . EastAsia
   khm . SEAsia
   idn . SEAsia
   lao . SEAsia
   mys . SEAsia
   phl . SEAsia
   sgp . SEAsia
   tha . SEAsia
   vnm . SEAsia
   xse . SEAsia
   bgd . SouthAsia
   ind . SouthAsia
   npl . SouthAsia
   pak . SouthAsia
   lka . SouthAsia
   xsa . SouthAsia
   can . NAmerica
   usa . NAmerica
   mex . NAmerica
   xna . NAmerica
   arg . LatinAmer
   bol . LatinAmer
   bra . LatinAmer
   chl . LatinAmer
   col . LatinAmer
   ecu . LatinAmer
   pry . LatinAmer
   per . LatinAmer
   ury . LatinAmer
   ven . LatinAmer
   xsm . LatinAmer
   cri . LatinAmer
   gtm . LatinAmer
   hnd . LatinAmer
   nic . LatinAmer
   pan . LatinAmer
   slv . LatinAmer
   xca . LatinAmer
   dom . LatinAmer
   jam . LatinAmer
   pri . LatinAmer
   tto . LatinAmer
   xcb . LatinAmer
   aut . EU_28
   bel . EU_28
   cyp . EU_28
   cze . EU_28
   dnk . EU_28
   est . EU_28
   fin . EU_28
   fra . EU_28
   deu . EU_28
   grc . EU_28
   hun . EU_28
   irl . EU_28
   ita . EU_28
   lva . EU_28
   ltu . EU_28
   lux . EU_28
   mlt . EU_28
   nld . EU_28
   pol . EU_28
   prt . EU_28
   svk . EU_28
   svn . EU_28
   esp . EU_28
   swe . EU_28
   gbr . EU_28
   che . RestofWorld
   nor . RestofWorld
   xef . RestofWorld
   alb . RestofWorld
   bgr . EU_28
   blr . RestofWorld
   hrv . EU_28
   rou . EU_28
   rus . RestofWorld
   ukr . RestofWorld
   xee . RestofWorld
   xer . RestofWorld
   kaz . RestofWorld
   kgz . RestofWorld
   tjk . RestofWorld
   xsu . RestofWorld
   arm . RestofWorld
   aze . RestofWorld
   geo . RestofWorld
   bhr . MENA
   irn . MENA
   isr . MENA
   jor . MENA
   kwt . MENA
   omn . MENA
   qat . MENA
   sau . MENA
   tur . MENA
   are . MENA
   xws . MENA
   egy . MENA
   mar . MENA
   tun . MENA
   xnf . MENA
   ben . SSA
   bfa . SSA
   cmr . SSA
   civ . SSA
   gha . SSA
   gin . SSA
   nga . SSA
   sen . SSA
   tgo . SSA
   xwf . SSA
   xcf . SSA
   xac . SSA
   eth . SSA
   ken . SSA
   mdg . SSA
   mwi . SSA
   mus . SSA
   moz . SSA
   rwa . SSA
   tza . SSA
   uga . SSA
   zmb . SSA
   zwe . SSA
   xec . SSA
   bwa . SSA
   nam . SSA
   zaf . SSA
   xsc . SSA
   xtw . RestofWorld
/ ;

set mapf(endw, fp) /
   ag_othlowsk  . UnSkLab
   service_shop . UnSkLab
   clerks       . UnSkLab
   tech_aspros  . SkLab
   off_mgr_pros . SkLab
   Capital      . Capital
$iftheni.ifLU "%LU%" == "ON"
   Land         . (AEZ1*AEZ6)
$else.ifLU
   Land         . Land
$endif.ifLU
   NatlRes      . NatRes
/ ;

set mapaez(fpa0, fp) /
$iftheni.ifLU "%LU%" == "ON"
      AEZ1   . AEZ1
      AEZ2   . AEZ2
      AEZ3   . AEZ3
      AEZ4   . AEZ4
      AEZ5   . AEZ5
      AEZ6   . AEZ6
      AEZ7   . AEZ1
      AEZ8   . AEZ2
      AEZ9   . AEZ3
      AEZ10  . AEZ4
      AEZ11  . AEZ5
      AEZ12  . AEZ6
      AEZ13  . AEZ1
      AEZ14  . AEZ2
      AEZ15  . AEZ3
      AEZ16  . AEZ4
      AEZ17  . AEZ5
      AEZ18  . AEZ6

      UnSkLab  . UnSkLab
      SkLab    . SkLab

      Capital . Capital
      NatlRes . NatRes
$else.ifLU
      (AEZ1*AEZ18). Land
$endif.ifLU
/ ;


set maplGIDD(lg, l) "Mapping to GIDD labor database" /
   nsk.UnSkLab
   skl.SkLab
/ ;
\end{lstlisting}

\subsubsection{Sets and mappings for model aggregation}

As noted above, the model aggregation can differ from the data aggregation. The
data aggregation is built around the concept of a diagonal make matrix---this
ensures that the output from any of the three modules always has the same
'geometry'. The model aggregation is intended to allow for a non-diagonal make
matrix---this can vastly simplify a model, for example in incorporating the
recent GTAP power database. This section allows the user to input the sets and
mappings for the model aggregation. Listing~\ref{lst:ModAgg} has an example from
the '10x10' map file.

Most of the entries in the listing file should be fairly self-explanatory. The
user defines two sets, \texttt{actf} and \texttt{commf}, that will represent the
model aggregation. They can replicate the set \emph{i} from the first section,
in which case the make matrix will be the standard diagonal. In the example from
the listing file, the two agricultural activities from the data aggregation are
merged into one activity called \texttt{Agriculture}. Thus the single activity
\texttt{Agriculture} will produce two commodities: \texttt{GrainsCrops} and
\texttt{MeatLstk}. This is reflected in the two mapping sets \texttt{mapaf} and
\texttt{mapif}. Note that the mappings are based on the data aggregation and not
the original GTAP database.\footnote{The aggregation facility will automatically
append the '-a' and '-c' suffixes to activities and commodities, respectively,
except for the user-defined aggregations.}

The model needs an \texttt{imuvf} subset based on the final model aggregation.
This is followed by the definition of the aggregations of commodities,
activities and regions, i.e. the set mappings \texttt{mapia}, \texttt{mapaga}
and \texttt{mapra}. Note that these mappings are ignored by the model and
typically are only used for post-processing of results.

The latest version of the model includes a climate damages and
adaption module. This is still under development. The module
may use special sector(s) for education and health services. These
are provided as subsets \texttt{iedu} and \texttt{ihht} (see lines 73--81).

The mapping file also includes a user-determined sort order for regions,
activities and commodities. GAMS does not preserve the order of set labels. The
sort orders can be used upon output to guarantee that output will be sorted
according to user preferences. The sort order can also be used to sort labels
for Excel (for example in the creation of Pivot tables.).

\begin{lstlisting}[language=GAMS, caption={Sets for model aggregation}, label=lst:ModAgg]
* ----------------------------------------------------------------------------------------
*
*     Section dealing with model aggregations (to handle non-diagonal make matrix)
*
* ----------------------------------------------------------------------------------------

*  Model aggregation(s)

set actf "Model activities" /
      Agriculture    "Agriculture"
      Extraction     "Mining and Extraction"
      ProcFood       "Processed Food"
      TextWapp       "Textiles and Clothing"
      LightMnfc      "Light Manufacturing"
      HeavyMnfc      "Heavy Manufacturing"
      Util_Cons      "Utilities and Construction"
      TransComm      "Transport and Communication"
      OthServices    "Other Services"
/ ;

set commf "Model commodities" /
      GrainsCrops    "Grains and Crops"
      MeatLstk       "Livestock and Meat Products"
      Extraction     "Mining and Extraction"
      ProcFood       "Processed Food"
      TextWapp       "Textiles and Clothing"
      LightMnfc      "Light Manufacturing"
      HeavyMnfc      "Heavy Manufacturing"
      Util_Cons      "Utilities and Construction"
      TransComm      "Transport and Communication"
      OthServices    "Other Services"
/ ;

set mapaf(i, actf) "Mapping from original to modeled activities" /
      GrainsCrops  .Agriculture
      MeatLstk     .Agriculture
      Extraction   .Extraction
      ProcFood     .ProcFood
      TextWapp     .TextWapp
      LightMnfc    .LightMnfc
      HeavyMnfc    .HeavyMnfc
      Util_Cons    .Util_Cons
      TransComm    .TransComm
      OthServices  .OthServices
/ ;

set mapif(i, commf) "Mapping from original to modeled commodities" /
      GrainsCrops  .GrainsCrops
      MeatLstk     .MeatLstk
      Extraction   .Extraction
      ProcFood     .ProcFood
      TextWapp     .TextWapp
      LightMnfc    .LightMnfc
      HeavyMnfc    .HeavyMnfc
      Util_Cons    .Util_Cons
      TransComm    .TransComm
      OthServices  .OthServices
/ ;

* >>>> MUST INSERT MUV COMMODITIES (ONE OR MORE)
*      !!!! Be careful of compatibility with modeled imuv
*           This one is intended for AlterTax

set imuvf(commf) "MUV commodities" /

   ProcFood
   TextWapp
   LightMnfc
   HeavyMnfc

/ ;

*  For adaptation module

set iedu(commf) "Education sector(s)" /
   OthServices
/ ;

set ihht(commf) "Health sector(s)" /
   OthServices
/ ;

*  >>>> Aggregation of modeled sectors and regions

set mapia(ia,commf)"mapping of individual comm to aggregate comm" /
   tagr-c.GrainsCrops
   tagr-c.MeatLstk
   tman-c.ProcFood
   tman-c.TextWapp
   tman-c.LightMnfc
   tman-c.HeavyMnfc
   toth-c.Extraction
   tsrv-c.Util_Cons
   tsrv-c.TransComm
   tsrv-c.OthServices
/ ;
mapia("ttot-c",commf) = yes ;

set mapaga(aga,actf)"mapping of individual comm to aggregate comm" /
   tagr-a.Agriculture
   tman-a.ProcFood
   tman-a.TextWapp
   tman-a.LightMnfc
   tman-a.HeavyMnfc
   toth-a.Extraction
   tsrv-a.Util_Cons
   tsrv-a.TransComm
   tsrv-a.OthServices
/ ;
mapaga("ttot-a",actf) = yes ;

set mapra(ra,r) "Mapping of model regions to aggregate regions" /
   hic.(Oceania, NAmerica, EU_28)
/ ;
mapra("lmy", r)$(not mapra("hic",r)) = yes ;
mapra("wld", r) = yes ;

set maplagg(lagg,l) "Mapping of model labor to aggregate labor" ;
maplagg("Tot",l) = yes ;

set sortOrder / sort1*sort500 / ;
set mapRegSort(sortOrder,r) /

   sort1 .  Oceania
   sort2 .  EastAsia
   sort3 .  SEAsia
   sort4 .  SouthAsia
   sort5 .  NAmerica
   sort6 .  LatinAmer
   sort7 .  EU_28
   sort8 .  MENA
   sort9 .  SSA
   sort10.  RestofWorld

/ ;

set mapActSort(sortOrder,actf) /

   sort1   .Agriculture
   sort2   .Extraction
   sort3   .ProcFood
   sort4   .TextWapp
   sort5   .LightMnfc
   sort6   .HeavyMnfc
   sort7   .Util_Cons
   sort8   .TransComm
   sort9   .OthServices

/ ;

set mapCommSort(sortOrder,commf) /
   sort1   .GrainsCrops
   sort2   .MeatLstk
   sort3   .Extraction
   sort4   .ProcFood
   sort5   .TextWapp
   sort6   .LightMnfc
   sort7   .HeavyMnfc
   sort8   .Util_Cons
   sort9   .TransComm
   sort10  .OthServices
/ ;
\end{lstlisting}

\subsubsection{Sets and mappings for the \textsc{Envisage} Model}

The final part of the map file is specific to the \textsc{Envisage} Model. Many
are critical components of \textsc{Envisage} as they often determine model
specification. For example, the first two subsets, \texttt{acr} and \texttt{alv}
determine which activities use the crop and livestock production structure,
respectively. All other activities will be assigned to the subset \texttt{ax}
that is the default production structure. Listing~\ref{lst:EnvSets} provides an
example for the 10x10 map file, though we will provide additional snippets below
for a different aggregation tuned to the power and water modules of the model.

The subsets \texttt{agr} and \texttt{man} are not formally part of the model.
These subsets are currently being used to determine activity-specific
productivity shifters in dynamic scenarios.\footnote{See the model file
\texttt{initScen.gms}} They could potentially be used as well in post-simulation
processing. The subsets \texttt{aenergy}, \texttt{affl} and \texttt{aw} are
currently not being used.

\begin{lstlisting}[language=GAMS, caption={Sets for the \textsc{Envisage} Model aggregation}, label=lst:EnvSets]
 ----------------------------------------------------------------------------------------
*
*     Envisage section
*
* ----------------------------------------------------------------------------------------

*  >>>> Activity related sets and subsets

set acr(actf)  "Crop activities" /
/ ;

set alv(actf)  "Livestock activities" /
/ ;

set agr(actf)  "Agricultural activities" /
      Agriculture    "Agriculture"
/ ;

set man(actf)  "Manufacturing activities" /
      Extraction     "Mining and Extraction"
      ProcFood       "Processed Food"
      TextWapp       "Textiles and Clothing"
      LightMnfc      "Light Manufacturing"
      HeavyMnfc      "Heavy Manufacturing"
/ ;

set aenergy(actf) "Energy activities" /
      Extraction     "Mining and Extraction"
      Util_Cons      "Utilities and Construction"
/ ;

set affl(actf) "Fossil fuel activities" /
      Extraction     "Mining and Extraction"
/ ;

set aw(actf)   "Water services activities" /
/ ;

set elya(actf) "Power activities" /
/ ;

set etd(actf)  "Electricity transmission and distribution activities" /
/ ;

set primElya(actf) "Primary power activities" /
/ ;

set pb   "Power bundles" /
   othp     "Other power"
/ ;

set mappow(pb,elya) "Mapping of power activities to power bundles" /
/ ;

*  >>>> Commodity sets and subsets

set frt(commf) "Fertilizer commodities" /
/ ;

set feed(commf) "Feed commodities" /
/ ;

set iw(commf) "Water services commodities" /
/ ;

set e(commf) "Energy commodities" /
$ontext
      Extraction     "Mining and Extraction"
      Util_Cons      "Utilities and Construction"
$offtext
/ ;

set elyc(commf) "Electricity commodities" /
      Util_Cons      "Utilities and Construction"
/ ;

set f(commf) "Fuel commodities" /
*     Extraction     "Mining and Extraction"
/ ;

*  This zonal mapping is for labor market segmentation in final model

set mapzf(z,actf)  "Mapping of activities to zones" /
   rur.Agriculture
/ ;

mapzf("urb",actf) = not mapzf("rur",actf) ;
mapzf("nsg",actf) = yes ;

* >>>> Household commodity section

set k "Household commodities" /
      GrainsCrops    "Grains and Crops"
      MeatLstk       "Livestock and Meat Products"
      ProcFood       "Processed Food"
      TextWapp       "Textiles and Clothing"
      LightMnfc      "Light Manufacturing"
      HeavyMnfc      "Heavy Manufacturing"
      TransComm      "Transport and Communication"
      OthServices    "Other Services"
      Energy         "Energy"
/ ;

set fud(k) "Household food commodities" /
      GrainsCrops    "Grains and Crops"
      MeatLstk       "Livestock and Meat Products"
      ProcFood       "Processed Food"
/ ;

set mapk(commf,k) "Mapping from i to k" /
      GrainsCrops  .GrainsCrops
      MeatLstk     .MeatLstk
      Extraction   .Energy
      ProcFood     .ProcFood
      TextWapp     .TextWapp
      LightMnfc    .LightMnfc
      HeavyMnfc    .HeavyMnfc
      Util_Cons    .Energy
      TransComm    .TransComm
      OthServices  .OthServices
/ ;

set cpindx  "CPI indices to be derived by the model" /
   fud      "Food price index"
   nfd      "Non-food price index"
   tot      "Total price index"
/ ;

set mapCPI(cpindx,commf)   "Mapping from commf to CPI index" /
      fud.GrainsCrops
      fud.MeatLstk
      nfd.Extraction
      fud.ProcFood
      nfd.TextWapp
      nfd.LightMnfc
      nfd.HeavyMnfc
      nfd.Util_Cons
      nfd.TransComm
      nfd.OthServices

/ ;
mapCPI("tot",commf) = yes ;

set lb "Land bundles" /
   agr         "Agriculture"
/ ;

set lb1(lb) "First land bundle" /
   agr         "Livestock"
/ ;

set maplb(lb,actf) "Mapping of activities to land bundles" /
   agr         .Agriculture
/ ;

*  !!!! TO BE REVIEWED

set lb0   "Default land bundles" / lb1*lb1 / ;
set maplb0(lb, lb0) "Mapping of land bundles to original" /
   agr.lb1
/ ;

set wbnd "Aggregate water markets" /
   N_A         "N_A"
/ ;

set wbnd1(wbnd) "Top level water markets" /
/ ;

set wbnd2(wbnd) "Second level water markets" /
/ ;

set wbndEx(wbnd) "Exogenous water markets" /
/ ;

set mapw1(wbnd,wbnd) "Mapping of first level water bundles" /
/ ;

set mapw2(wbnd,actf) "Mapping of second level water bundle" /
/ ;

set wbnda(wbnd) "Water bundles mapped one-to-one to activities" /
/ ;

set wbndi(wbnd) "Water bundles mapped to aggregate output" /
/ ;

set NRG "Energy bundles used in model" /
   coa         "Coal"
   oil         "Oil"
   gas         "Gas"
   ely         "Electricity"
/ ;

set coa(NRG) "Coal bundle used in model" /
   coa         "Coal"
/ ;

set oil(NRG) "Oil bundle used in model" /
   oil         "Oil"
/ ;

set gas(NRG) "Gas bundle used in model" /
   gas         "Gas"
/ ;

set ely(NRG) "Electricity bundle used in model" /
   ely         "Electricity"
/ ;

set mape(NRG,e) "Mapping of energy commodities to energy bundles" /
*  oil         .Extraction
*  ely         .Util_Cons
/ ;

*  >>>> Sets required for 'growing' labor by skill

set skl(l)  "Skill types for labor growth assumptions" /
   SkLab
/ ;

set elev / elev0*elev3 / ;

set educMap(r,l,elev) "Mapping of skills to education levels" ;

*  Use GIDD definitions (i.e. "elev3" has no meaning)

educMap(r,"UnSkLab","elev0")$mapra("lmy",r) = yes ;
educMap(r,"SkLab","elev1")$mapra("lmy",r)   = yes ;
educMap(r,"SkLab","elev2")$mapra("lmy",r)   = yes ;

educMap(r,"UnSkLab","elev0")$mapra("hic",r) = yes ;
educMap(r,"UnSkLab","elev1")$mapra("hic",r) = yes ;
educMap(r,"SkLab","elev2")$mapra("hic",r)   = yes ;

$offempty
\end{lstlisting}

The subsets \texttt{elya} and \texttt{etd} are used by the power module.
The first contains all of the (aggregate) power activities and the second
contains the electricity transmission and distribution activity (normally a
single activity). If these sets are empty, the distribution of power will be
modeled using the standard 'make' specification, i.e. a single CES nest for
aggregation. An additional subset, \texttt{primElya}, is used post-simulation to
calculate primary energy demand. The latter is composed of all combusted fossil
fuels and primary electricity production, which excludes thermal power plants to
avoid double counting.

The power module allows for a multiple nested CES structure for power
aggregation. The example below, Listing~\ref{lst:PowBnd}, shows the power
nesting for a different map file. There are eight power activities (coal, oil,
gas, nuclear, hydro, wind, solar, and other renewable), plus the transmission
and distribution activity. The eight activities will be mapped to five power
bundles (coal, gas, oil, nuclear and renewables), see set \texttt{pb}. The power
aggregation is based on three nests, see figure~\ref{fig:PowNest}---that is
fully defined with the subsets n the power module of the map file. The subset
\texttt{elyc} is designed to contain the single electricity commodity that is
the output of aggregating electricity output across all electricity activities.

\begin{lstlisting}[language=GAMS, caption={A power bundle example}, label=lst:PowBnd]
set elya(actf) "Power activities" /
      clp
      olp
      gsp
      nuc
      hyd
      wnd
      sol
      xel
      etd
/ ;

set etd(actf)  "Electricity transmission and distribution activities" /
      etd
/ ;

set primElya(elya) "Primary energy power activities" /
      nuc
      hyd
      wnd
      sol
      xel
      etd
/ ;

set pb   "Power bundles" /
      coap     "Coal power"
      gasp     "Gas power"
      oilp     "Oil power"
      nucp     "Nuclear power"
      othp     "Other power"
/ ;

set mappow(pb,elya) "Mapping of power activities to power bundles" /
      coap.clp
      gasp.gsp
      oilp.olp
      nucp.nuc
      othp.(hyd, wnd, sol, xel)
/ ;

set elyc(commf) "Electricity commodities" /
      ely
/ ;

\end{lstlisting}

The subsets \texttt{frt} and \texttt{feed} are used respectively by the
\texttt{acr} and \texttt{lvs} activities to define the $\mathit{ND2}$
bundle.\footnote{From the point of view of the code, these are used to determine
the mapping sets \texttt{mapi1} and \texttt{mapi2}.} The former contains the
fertilizer commodities and the latter the feed commodities. The subset
\texttt{iw} defines the commodities that can be bundled with the water factor in
the water module. It could contain, for example, the water services commodity
(\texttt{wtr}) from the GTAP database.

The subset \texttt{e} is a critical component of the energy module, see
figures~\ref{fig:NRGNest} and \ref{fig:XCNRGNest}. The subset is also linked to
the \texttt{NRG} set, the subsets \texttt{coa}, \texttt{oil}, \texttt{gas} and
\texttt{ely} and the mapping set \texttt{mape}. Listing~\ref{lst:NRGSets} shows
a potential configuration using the standard energy commodities in the GTAP
database.\footnote{The ordering in the map file is somewhat arbitrary and mostly
up to user discretion, unless there are specific dependencies.} In the current
configuration the set \texttt{NRG} and the name of the subsets \texttt{coa},
\texttt{oil}, \texttt{gas} and \texttt{ely} cannot be modified by the user. The
subsets, however, can be empty. The subset \emph{f} is not used by the model
itself [TBC]. It is used at times in post-simulation to evaluate \COT{}
emissions from the combustion of fuels. In the original GTAP database, this
corresponds to the commodities \texttt{coa}, \texttt{oil}, \texttt{gas},
\texttt{p\_c}, and \texttt{gdt}.

\begin{lstlisting}[language=GAMS,
   caption={An energy bundle example}, label=lst:NRGSets]
set e(commf) "Energy commodities" /
      coa
      oil
      gas
      p_c

      ely
/ ;

set NRG "Energy bundles used in model" /
   coa         "Coal"
   oil         "Oil"
   gas         "Gas"
   ely         "Electricity"
/ ;

set coa(NRG) "Coal bundle used in model" /
   coa         "Coal"
/ ;

set oil(NRG) "Oil bundle used in model" /
   oil         "Oil"
/ ;

set gas(NRG) "Gas bundle used in model" /
   gas         "Gas"
/ ;

set ely(NRG) "Electricity bundle used in model" /
   ely         "Electricity"
/ ;

set mape(NRG,e) "Mapping of energy commodities to energy bundles" /
   COA.(coa)
   OIL.(oil, p_c)
   GAS.(gas)
   ELY.(ely)
/ ;
\end{lstlisting}

The mapping set \texttt{mapzf} is critical for the rural to urban migration
module (if implemented). It would normally correspond to the \texttt{mapz}
mapping set from the earlier part of the mapping file---but corresponding to the
model aggregation, not the data aggregation. If the migration elasticity is set
to infinity, the model will assume perfect labor mobility and the \texttt{mapzf}
mapping set will be ignored.

The top level demand nest for consumer demand is based on a different set of
goods than the commodities defined by the set \emph{i}. This allows for a 'make'
or 'transition' matrix approach to consumer demand specification, see
figure~\ref{fig:ConsNest}. The household commodities are specified over the set
\emph{k}. It is a simple mapping from the supply commodities (\emph{i}) to
consumed commodities (\emph{k}). If there is a one-to-one mapping, the consumer
make matrix is fully diagonal. At the moment, one of the key purposes of the
make matrix is to allow for a consumer energy bundle, with a structure similar
to the energy bundle in production, see figure~\ref{fig:XCNRGNest}. It could
however be used to construct other non-diagonal elements. For example crop
commodities could be combined into a single consumer crop bundle and the
livestock commodities could be combined into a single consumer livestock bundle.
The subsequent CES nests would then allocate the top level demand to the
relevant components. The subset \texttt{fud(k)} can be used by the
\textsc{Envisage} model to focus on food demand. Listing~\ref{lst:consMakeSet}
provides an example of a consumer mapping for energy only.\footnote{Like for the
other activities and commodities, the aggregation facility will automatically
append the '-k' suffix to consumer labels.} N.B. The CPI index, which
can be defined over one or more bundles, is defined with respect
to the core commodity supply, not with respect to the consumer commodities
(i.e., it is defined over $i$, not over $k$).

\begin{lstlisting}[language=GAMS,
   caption={An example of the consumer 'make' aggregation},
    label=lst:consMakeSet]
set k "Household commodities" /
      crp     "Cereals"
      osd     "Oil seeds"
      xcr     "Other crops"
      lvs     "Meat and wool"
      rmk     "Raw milk"
      frs     "Forestry"
      fsh     "Fisheries"
      omn     "Other mining"
      met     "Meat products"
      vol     "Vegetable oils"
      mil     "Dairy products"
      ofd     "Other foods products"
      b_t     "Beverages and tobacco products"
      tex     "Textiles"
      wap     "Wearing apparel"
      lea     "Leather products"
      wdp     "Lumber, paper and paper products"
      crp     "Chemicals, rubber and plastics"
      mmn     "Basic metals and minerals"
      ele     "Electronic equipment"
      mvh     "Motor vehicles"
      xma     "Other industry & manufacturing"
      cns     "Construction"
      ttp     "Trade and transport"
      bsv     "Financial and business services"
      dwe     "Dwellings"
      xsv     "Other services"
      nrg     "Energy bundle"
/ ;

set fud(k) "Household food commodities" /
      crp     "Cereals"
      osd     "Oil seeds"
      xcr     "Other crops"
      lvs     "Meat and wool"
      rmk     "Raw milk"
      fsh     "Fisheries"
      met     "Meat products"
      vol     "Vegetable oils"
      mil     "Dairy products"
      ofd     "Other foods products"
      b_t     "Beverages and tobacco products"
/ ;

set mapk(commf,k) "Mapping from i to k" /
      cer.cer
      osd.osd
      xcr.xcr
      lvs.lvs
      rmk.rmk
      frs.frs
      fsh.fsh
      coa.nrg
      oil.nrg
      gas.nrg
      omn.omn
      met.met
      vol.vol
      mil.mil
      ofd.ofd
      b_t.b_t
      tex.tex
      wap.wap
      lea.lea
      wdp.wdp
      p_c.nrg
      crp.crp
      mmn.mmn
      ele.ele
      mvh.mvh
      xma.xma
      ely.nrg
      cns.cns
      ttp.ttp
      bsv.bsv
      dwe.dwe
      xsv.xsv
/ ;
\end{lstlisting}

The land module depends on user-determined land bundles, see
figure~\ref{fig:LandNest}. The model allows for a fair amount of user
flexibility. There are three nests, but one of the nests allows for a variable
number of land bundles. The mapping of the agricultural activities to the land
bundles is also determined by the user. Listing~\ref{lst:lndBnd} shows an
example of a land bundle that corresponds to that used in the MAGNET
model.\footnote{\url{edepot.wur.nl/310764}, page 74).}

The MAGNET specification has only three bundles (\texttt{L}, \texttt{FCP} and
\texttt{COP}). We have arranged these into five bundles. The top is split
between the \texttt{hrt} bundle and all of the rest (that corresponds to the
\texttt{FCP} bundle). We assume that the top evel CET elasticity in MAGNET,
$\sigma^1$ holds for the top level bundle in \textsc{Envisage}but also for the
bundle composed of activities in the \texttt{hrt} bundle. This has the same
impact as mapping directly the \texttt{hrt} activities to the top level bundle
as in MAGNET. The $\mathit{XNLB}$ bundle will then be composed of the
\texttt{lvs} and \texttt{cer} bundles. MAGNET's CET elasticity, $\sigma^2$ is
then applied to the $\mathit{XNLB}$ and \texttt{lvs} bundles, which has the same
impact as mapping directly the \texttt{lvs} activities to the $\mathit{XNLB}$
bundle as in MAGNET. Finally, MAGNET's $\sigma^3$ elasticity is applied to the
\texttt{cer} bundle. The set \texttt{lb0} is used to map the elasticities in the
parameter file to the model elasticities---the set is not part of the the model.
[This mapping is still under review and users can override these in the model
parameter file].

\begin{lstlisting}[language=GAMS,
   caption={An example of land configuration}, label=lst:lndBnd]
set lb "Land bundles" /
   hrt      "Horticulture and other crops"
   lvs      "Livestock and sugar"
   cer      "Cereals and oil seeds"
/ ;

set lb1(lb) "First land bundle" /
   hrt      "Horticulture and other crops"
/ ;

set maplb(lb,actf) "Mapping of activities to land bundles" /
   hrt.v_f
   htr.ocr
   lvs.lvs
   lvs.sug
   cer.wht
   cer.gro
   cer.osd
/ ;

set lb0   "Default land bundles" / lb1*lb3 / ;
set maplb0(lb, lb0) "Mapping of land bundles to original" /
   hrt.lb1
   lvs.lb2
   cer.lb3
/ ;
\end{lstlisting}

The water module has three basic bundle types:

\begin{enumerate}
   \item Water bundles that have activities mapped to them---for example
         irrigation water in crop activities
   \item Water bundles that are linked to aggregate output
         indices---for example industrial water use
   \item Exogenous bundles not linked directly to the economy---for example
         ground water recharge or water for environmental services.
\end{enumerate}

\noindent These fundamental water bundles are structured in a nested CET nest
for which users have significant control. In the example in
Listing~\ref{lst:watBnd} there is one bundle of the first type (crops), three
bundles of the second type (livestock, municipal and industrial) and two bundles
of the third type (environmental services and ground water recharge). There are
two intermediate bundles that form the top level CET nest---agriculture and
non-agriculture, see figure~\ref{fig:WaterNest}. The set \texttt{wbnd} defines
all of the possible bundles. The set \texttt{wbnd1} defines the top level
bundles---in principle there could be more than two. The set \texttt{wbnd2}
defines the second level bundles. The set \texttt{wbndEx} defines the exogenous
bundles. These will be subtracted from total water supply. The mapping set
\texttt{mapw1} maps fundamental bundles to the top-level intermediate water
bundles. The mapping set \texttt{mapw2} maps all activities to one of the
fundamental bundles. The subset \texttt{wbnda} indicates which water bundles are
mapped directly to activity-based water demand. With the current water database,
only irrigated crops use water directly. The subset \texttt{wbndi} indicates
which water bundles are mapped to output indices. The elasticities for the water
module need to be provided in the user-built parameter file---see below.

\begin{lstlisting}[language=GAMS,
      caption={An example of water configuration}, label=lst:watBnd]
set wbnd "Aggregate water markets" /
   agr      "Agriculture"
   nag      "Non-agriculture"
   env      "Environmental services"
   grd      "Ground water recharge"
   crp      "Crops"
   lvs      "Livestock"
   ind      "Industrial use"
   mun      "Municipal use"
/ ;

set wbnd1(wbnd) "Top level water markets" /
   agr      "Agriculture"
   nag      "Non-agriculture"
/ ;

set wbnd2(wbnd) "Second level water markets" /
   crp      "Crops"
   lvs      "Livestock"
   ind      "Industrial use"
   mun      "Municipal use"
/ ;

set wbndEx(wbnd) "Exogenous water markets" /
   env      "Environmental services"
   grd      "Ground water recharge"
/ ;

set mapw1(wbnd,wbnd) "Mapping of first level water bundles" /
   agr.(crp,lvs)
   nag.(mun,ind)
/ ;

set mapw2(wbnd,actf) "Mapping of second level water bundle" ;
mapw2("crp",acr) = yes ;
mapw2("lvs",alv) = yes ;
mapw2("ind",man) = yes ;
mapw2("mun",actf)$(not (acr(actf) or alv(actf) or man(actf))) = yes ;

set wbnda(wbnd) "Water bundles mapped one-to-one to activities" /
   crp      "Crops"
/ ;

set wbndi(wbnd) "Water bundles mapped to aggregate output" /
   lvs      "Livestock"
   ind      "Industrial use"
   mun      "Municipal use"
/ ;
\end{lstlisting}

The remaining section of the map file relates to the use of the IIASA- or
GIDD-based education projections to shape the growth of skilled and unskilled
labor. This is not fundamental to the model, but is part of defining the dynamic
scenario.

One subset defines skilled labor, \texttt{skl}. This is different from the
\texttt{ul} and \texttt{sl} subsets that are used to allocate labor between the
$\mathit{LAB1}$ and $\mathit{LAB2}$ bundles. The purpose here is only to drive
the relative growth of unskilled and skilled labor. The mapping set,
\texttt{educMap}, determines the mapping between labor skills and the education
projections. There are two different education projections. The IIASA education
projections have four classifications: none, primary, secondary and tertiary
(labeled \texttt{ENONE}, \texttt{EPRIM}, \texttt{ESECN} and \texttt{ETERT} in
the SSP database, but labeled \texttt{ELEV0*ELEV3} in the scenario file.) The
GIDD database has three classifications: 0-6 years of education, 6-9 years of
education and 9 or more years (labeled \texttt{EDUC0\_6}, \texttt{EDUC6\_9}, and
\texttt{EDUC9UP} in the GIDD database, but labeled \texttt{ELEV0*ELEV2} in the
scenario file.) If using the IIASA database, all four education levels should be
mapped to the skills. If using the GIDD database, only three of the levels are
active. The mappings can vary across regions. For example, in high-income
countries, skilled workers might be only tertiary and above. In developing
countries, skilled workers may also include workers with a secondary education.

\subsubsection{Running the aggregation}

The aggregation is coded in GAMS and can be run in the GAMS IDE or from a
Windows command console. For the latter, the command line is:

\begin{verbatim}
   gams aggGTAP --basename=[basename] --ifAlt=[OFF|ON] --model=[GTAP|ENV]
         --ifCSV=[0|1] --ifAggTrade=[0|1]
\end{verbatim}

\noindent The aggregation routine is named \texttt{AggGTAP.gms}. The user needs
to provide the base name of the project, for example \texttt{10x10}. The
aggregation facility will prepare additional output if the user wishes to use
AlterTax. In that case, the \texttt{ifAlt} setting should be set to \texttt{ON},
otherwise it should be set to \texttt{OFF}. Aggregation is handled somewhat
differently for the GTAP and \textsc{Envisage} models. The model option should
take the value \texttt{GTAP} for the GTAP model, and \texttt{ENV} for the
\textsc{Envisage} model. The \texttt{ifCSV} option takes either the value 0 or
1. If it is set to 1, the aggregation facility will output the SAM, energy and
emissions data in a CSV formatted file that can be uploaded into Excel. The
\texttt{ifAggTrade} option takes either the value 0 or 1. If it is set to 1, the
output SAM will collapse bilateral trade to a single trade account, otherwise
the SAM will have the full bilateral trade (on both the import and export side).

If the aggregation is intended for the \textsc{Envisage} Model, the
\emph{aggGTAP} routine will invoke the \emph{convertLabel} program that will
convert the labels in the parameter file to the labels needed for the model.

\subsection{Filtering}

The filtering algorithm was developed by Tom Rutherford to remove small value
flows from the aggregated database (\cite{LanzRutherfordJGEA2016}). The
distributed version has been modified by Wolfgang Britz to handle some
additional features. The user needs to prepare a very short include file with
the algorithms's options (\texttt{[basename]Flt.gms}). Listing~\ref{lst:fltFile}
is an example of the filter options file.

\subsubsection{The filter options file}

The consecutively applied filtering and rebalancing approach is an extension of
the method and code developed by Tom
Rutherford.\footnote{The following explanations are adapted from Britz's
documentation. See
\url{http://www.ilr.uni-bonn.de/em/rsrch/cgebox/cgebox_GUI.pdf}.} It deletes
components of the SAM depending on their shares on specific totals, according to
the 'Relative tolerance' (\texttt{relTol}):

\begin{itemize}
   \item Domestic and imported intermediate demand of a commodity are dropped
         relative to its total output
   \item Private/government/investment domestic respectively import demand of a
         commodity are dropped relative to total Private/government/investment
         domestic respectively import demand
   \item Trade flows of a product are dropped if both shares on total exports of
         that product and its exporter and on imports of that product and its
         importer are below the relative threshold
   \item Production is dropped if net production of a commodity, i.e. after
         intermediate use of that commodity in its own production is deducted,
         is below the relative threshold with regard to total net production
\end{itemize}

\begin{lstlisting}[language=GAMS,
      caption={An example of a filter file}, label=lst:fltFile]
scalars
ifKeepIntermediateConsumption / 1 /
ifKeepPrivateconsumption      / 1 /
ifKeepGovernmentconsumption   / 1 /
ifKeepInvestments             / 1 /
ifGDPKeep                     / 1 /
ifKeepFactorincomeplusbop     / 1 /
ifAdjDepr                     / 1 /
abstol                        / 1e-10 /
relTol                        / 0.005 /
relTolRed                     / 1e-6  /
nsteps                        / 5 /
minNumTransactions            / 50000 /
;

file log / %baseName%flt.log / ;
put log ;

$ontext
$setglobal excRegs
$setglobal excSecs
$offtext

$setglobal excSecs "sol, wnd, xel"
$setGlobal excCombined  1
\end{lstlisting}

The absolute tolerance level, \texttt{absTol}, deletes any trade flow value that
is below the tolerance level in absolute terms. With a value of 1.E-10, that
preliminary deletion step is skipped. It is generally not recommended to use
absolute deletion thresholds above 1.E-6 in combination with rebalancing as the
subsequent relative thresholds will anyhow apply more refined rules.

The filtering process imposes restrictions which should maintain the regional
SAMs balanced. Additional constraints ensure that production activities require
added value and intermediate inputs, if not already otherwise found in the data
base. As filtering systematically removes elements from the SAM and the trade
matrices, the process implies without further corrections shrinking the
economies. During rebalancing, the algorithm can therefore add penalties for
deviations from the following aggregate transactions:

\begin{itemize}
   \item Intermediate consumption
   \item Private consumption
   \item Public consumption
   \item Investment
   \item Factor income plus BOP
   \item GDP
\end{itemize}

\noindent The imposition of these penalties is driven by the relevant flags in
the filter options file. By adding these penalties terms, the non-deleted
entries (and thus most important transactions) tend to be scaled upwards. It is
generally recommended to use these penalties terms. The code will also scale all
non-deleted trade flows to approximately maintain the total volume of
international trade and related international transport margins.

The absolute and relative thresholds are stepwise enforced. For the first few
steps, exponential increases are used, starting with minus half the number of
steps. For six steps, to give an example, the first thresholds applied will the
1.E-3 of the final one, next 1.E-2 and finally 10\%. The remaining steps will
use equal linear increases between 10\% and the desired final ones. Once the
final thresholds are active, filtering is still applied several times until no
small values are found any longer. The code should ensure that the resulting
transactions are still fully consistent with each other, i.e. both the resulting
trade matrices and the SAMs are balanced. The changes imposed by filtering and
subsequent balancing are stored in the log file. Inspecting how the stepwise
enforcement of the thresholds impacts on the number of non-zero items can inform
on an appropriate level for tolerances to be used.

The SAMs used during filtering are---as in the GTAP database---defined in
Million dollars. An absolute threshold of 1.E-6 will hence delete any economic
transactions worth a single dollar or less. In SAMs with high regional and
sectoral detail, even such tiny transactions might make up to 10\% of the
non-zero entries. Increasing the threshold to \$1000 might remove $\text{1/4}$
or more of all non-empty transactions. Similar results are found from using
relative tolerances of 0.001\%.

Thanks to balancing, also rather dis-aggregated versions of the model with large
number of sectors and regions can be used. The biggest impact of the filtering
is typically on transactions related to bilateral trade flows. Here, often 50\%
or more of the flows account for only 1\% of the total value of these
transactions. Thus, tiny changes in the relative tolerance can have a
considerable impact on the number of deleted transaction, and one might need to
experiment with settings in the range around 1.E-1 to 1.E-4 to find a compromise
between sparsity and the implied changes on structure of the economy. For very
large data sets (e.g. a 1:1 version) filtering thresholds above 1\% might be
needed to yield reasonable model sizes. The user can additionally define a
minimum number of transactions to be kept, which reduces the need to experiment
with different thresholds as the filtering process will stop once less than the
desired number of transactions is reached. Tests with the model have shown that
the model in full resolution of the GTAP 8.1 data base without filtering, i.e.
57 sectors and 134 regions, can be solved in partial trade liberalization
scenarios, solution has failed with other shocks on models with more than
400,000 transactions, especially if the global bank mechanism active. A close
look at the filtering statistics is recommended, to avoid sharp impacts on the
structure of the economy. A more detailed discussion on the relation between
model dis-aggregation, filtering, solution behavior and simulated welfare
impacts is provided in \cite{BritzvdmEconMod2016}.

\paragraph{Special treatment for specific regions and sectors}

When building a data base for a project, it might be desirable to apply less
aggressive filtering thresholds for specific regions and/or sectors in the focus
of the application. The algorithm therefore allows defining lists of
regions/sectors with accompanying specific thresholds. The codes for
regions/sectors needs to be inputted in the global defines called
\texttt{excRegs} and \texttt{excSecs}. 'Reduced thresholds only in combination'
will apply the different threshold only to the intersection of the inputted
regions and sectors (\texttt{excCombined}), otherwise, all regions and sectors
inputted will be receive different thresholds. Take an example where you enter
for regions \texttt{xoc} and for sectors \texttt{pdr}. If 'Reduced thresholds
only in combination' is NOT switched on, all transactions of the region
\texttt{xoc} and all transactions for the sector \texttt{pdr} will be treated
differently. If the 'Reduced thresholds only in combination' is active, only the
transaction relating both to \texttt{pdr} and the region \texttt{xoc} are
exemptions. However, filtering for the remaining sectors/regions has still an
impact on these exemptions. For example, if production of a sector in a region
is dropped, the related export flows need to be dropped as well, affecting
potentially transactions in regions and sectors where tighter thresholds are
used. Tests have however indicated that very few transactions are lost in
regions/sector where stringent thresholds are applied as long as the overall
filtering thresholds are not too aggressive.

\paragraph{Diagnostics}

The filter listing file (\texttt{filter.lst}) and the log file
(\texttt{[basename]flt.log}) provide a number of useful diagnostics regarding
the filtering process. Users can also load the resulting 'CSV' file that
contains the SAM and energy/emission values both pre- and post-filtering.

\subsubsection{Running the filter program}

The filter routine is coded in GAMS and can be run in the GAMS IDE or from a
Windows command console. For the latter, the command line is:

\begin{verbatim}
   gams filter --basename=[basename] --ifCSV=[0|1] --ifAggTrade=[0|1]
\end{verbatim}

\noindent The filter routine is named \texttt{filter.gms}. The user needs to
provide the base name of the project, for example \texttt{10x10}. The
\texttt{ifCSV} option takes either the value 0 or 1. If it is set to 1, the
aggregation facility will output the SAM, energy and emissions data in a CSV
formatted file that can be uploaded into Excel. The \texttt{ifAggTrade} option
takes either the value 0 or 1. If it is set to 1, the output SAM will collapse
bilateral trade to a single trade account, otherwise the SAM will have the full
bilateral trade (on both the import and export side).

\subsection{Altering a database}

The third module in the data preparation routine is called Altertax, first
developed by \cite{MalcolmGTAPTP12} for the GTAP model. The Altertax module is
optional. It allows the user to make changes to the structure of the database
that minimizes the distortions from the original database. It is typically used
to change tax rates, for example import tariffs. The distributed version of
Altertax relies on a version of the GTAP model written in GAMS.\footnote{The
GAMS-based GTAP model has been developed by GTAP staff and documentation is
available upon request. It differs from the Rutherford \emph{GTAPinGAMS} model
(\cite{LanzRutherfordJGEA2016}) as it is intended to exactly replicate the
specification of the standard GTAP model in GEMPACK (\cite{CorongetalJGEA2017} and \cite{Hertel1997}).} The
main thrust of Altertax is to convert most of the model elasticities to 1
thereby all CES functions are essentially converted to Cobb-Douglas functional
forms. The latter have the property of conserving value shares. In addition, the
Altertax version of the GTAP model assumes a Cobb-Douglas utility function for
private consumption. A fixed current account is also imposed for the balance of
payment closure. The overrides are provided in the \texttt{AlterTax.gms} file.

\subsubsection{Option file}

If running Altertax, the user needs to prepare an option file that specifies the
nature of the alteration---it is to be named \texttt{[basename]Alt.gms}. The
file can be empty, in which case Altertax would simply re-balance the initital
database---though this will already have been done in the filter routine if it
was used. Listing~\ref{lst:altFile1} shows a very simple change: a rise of 40\%
on the import tariff of motor vehicles in Argentina. One could of course overlay
the entire import tariff schedule for Argentina in this file---including any
bilateral dimensions. Note that the activity and commodity labels will need the
appropriate suffix.

\begin{lstlisting}[language=GAMS,
   caption={An example of an Altertax shock}, label=lst:altFile1]

imptx.fx(s,"mvh-c","arg",tsim) = 1.4*imptx.l(s,"mvh-c","arg",tsim) ;

\end{lstlisting}

A more complicated, though artificial example is provided in
Listing~\ref{lst:altFile2}. This example shows how to phase in the shock to ease
numerical convergence. The shock is a 50\% cut in all tariffs. The user provides
the number of iterations to phase in the shocks, say for example 4. The
iteration count is first checked to see if it is 1, in which case there is no
iteration phase and the shock is imposed in one shot. If the iteration count is
greater than 1, the shock will be phased in. The \texttt{solver} needs to be
invoked for the first $n-1$ iterations, the $n^{\mathit{th}}$ iteration will be
solved in the standard (and final) invocation of the solver.

\begin{lstlisting}[language=GAMS,
   caption={An example of an Altertax file}, label=lst:altFile2]
* -----------------------------------------------------------------------------------------
*  Altertax shock
*
*  If new policy needs to be phased in, the basic implementation is
*
*     p(it) = pfinal*(it/n) + pinitial*(1-it/n)
*
*  See below for an example
*
*  Set the number of iterations on the command line, for example --niter=4

*  Cut initial tariffs by 50%
* -----------------------------------------------------------------------------------------

if(niter(tsim) eq 1,

*  No phase in of cuts

   imptx.fx(r,i,rp,tsim) = 0.5*imptx.l(r,i,rp,"base") ;

else

*  Phase in the shock

   for(iter=1 to niter(tsim),
      imptx.fx(r,i,rp,tsim) = 0.5*imptx.l(r,i,rp,"base") * (iter/niter(tsim))
                            + imptx.l(r,i,rp,"Base") * (1 - iter/niter(tsim)) ;
      if(iter < niter(tsim),
         $$batinclude "solve.gms" gtap
      ) ;
   ) ;
) ;
\end{lstlisting}

\subsubsection{Running Altertax}

The Altertax routine is coded in GAMS and can be run in the GAMS IDE or from a
Windows command console. For the latter, the command line is:

\begin{verbatim}

   gams AlterTax --BaseName=[basename] --niter=1 --ifCSV=[0|1] -idir=GTAPModel

\end{verbatim}

The filter routine is named \texttt{Altertax.gms}. The user needs to provide the
base name of the project, for example \texttt{10x10}. The user needs to provide
the number of iterations for a phase-in of the shock. For most modest shocks, a
value of 1 should be sufficient. Note that it is up to the user to make sure the
Altertax option file contains the necessary code for the phase in of the shock.
The \texttt{ifCSV} option takes either the value 0 or 1. If it is set to 1, the
aggregation facility will output the SAM, energy and emissions data in a CSV
formatted file that can be uploaded into Excel. The \texttt{iDir} option
provides a pointer to the folder containing the GTAP model code. Under default
configurations the model code is a sub-folder in the \emph{Data} directory with
the name \emph{GTAPModel}.

If the \texttt{ifCSV} option is set to 1, the SAM and energy/emissions data will
be output in a CSV-formatted file for input into Excel. The CSV file will have a
'time' dimension that takes three values. 'Year' equal to 1 corresponds to the
base year initialization of model variables and parameters and should correspond
to the input database. 'Year' 2 corresponds to a first simulation with no shock.
It should re-produce the base data as well, i.e. the results in 'Year' 1 and 2
should be identical to within a very small tolerance level. 'Year' equal to 3
will correspond to the post-shock structure of the database and comparison with
either 'Year' 1 or 2 will highlight deviations from the initial database.

\subsubsection{Dealing with process emissions}
\label{sec:pcarb0}

Process emissions are integrated into the production structure,
see for example equation~(\ref{eq:xghg}). However, there is no
price on process emissions in the base data and thus no way
to calibrate the base year parameters. We can use 'Altertax'
to introduce a small tax on process emissions. This is done
in such a way as to raise the unit cost of production
by a small amount---the amount that would be equivalent to the
revenues generated by the process emissions using the low tax
rate.

For this purpose, the GTAP Model in GAMS, that is the core of Altertax
has been modified to include an additional production tax, which
is specific to each activity.\footnote{The standard production tax,
labeled \texttt{prdtx} in the model code, is introduced as
part of the 'make' module.} The additional production
tax, labeled \texttt{ctax}, is tacked onto to the
unit cost of production, \texttt{PX}, and is a
new price wedge that affects the price of output as
it enters the 'make' module. The level of \texttt{ctax}
is endogenous. It is set such that the value
of the revenues associated with \texttt{ctax}
is equal to the value of the revenues that
would be generated by the process emissions given
the user-specified carbon tax. The model therefore
includes the following equation:

\[
\tau^c_{r,a}\mathit{PX}_{r,a}\mathit{XP}_{r,a}
=\displaystyle \sum_{\mathit{em}} {\mathit{PCARB}_r \mathit{prEmi}_{r,\mathit{em},a}}
\]

\noindent where $\tau^c$ is labeled \texttt{ctax}. All
information on the right-hand side is given---the user
provides $\mathit{PCARB}$\footnote{The code reflects
the scaling options for emissions and the value data.} and the data provides
the base year process emissions for each activity. The
other changes in the code reflect necessary changes by
the introduction of \texttt{ctax}. The resulting database
looks like a standard GTAP database, but in the absence
of process emissions, it would not be consistent.

Listing~\ref{lst:pcarb0} provides the code snippet with the shocks that
are introduced into the 'Alt' shock file. The first part
extracts the process emissions from the 'NCO2' database
and calculates the aggregate process emissions for each
GHG and activity. N.B. The user selects the conversion factor, i.e., the
global warming potential. It should be consistent between
the data preparation phase, i.e., Altertax, and the
model simulations. The second part of the code
initializes the 'carbon' tax. In the standard code,
\texttt{ctax} is zero. This code endogenizes \texttt{ctax}
and sets the desired price for the tax on process emissions.

\begin{lstlisting}[language=GAMS, caption={Initial pricing of process emissions in Altertax}, label=lst:pcarb0]
*  Introduce a 'small' tax on process emissions
*  Assume we are using 'AR4' and set a price of 25 cents per tCO2eq

execute_load "%inDir%/%BaseName%NCO2.gdx", gwp, emi_iop, emi_endw, emi_qo ;

ProcEmi0(r,em,a)  = gwp(em,r,"AR4")*cscale
                  *  (sum((i0,a0)$(mapa0(a0,a)), emi_iop(em, i0, a0, r))
                  +   sum((fp,a0)$mapa0(a0,a), emi_endw(em, fp, a0, r))
                  +   sum(a0$mapa0(a0,a), emi_qo(em, a0, r))) ;

pcarb0(r) = 0.25 ;
ytax0(r,"ct")     = 1 ;
ctaxFlag(r,a)$sum(em, pcarb0(r)*(inscale/cscale)*procEmi0(r,em,a)) = yes ;
ctax.l(r,a,tsim)$ctaxFlag(r,a) = 0.0003 ;
ctax.lo(r,a,tsim)$ctaxFlag(r,a) = -inf ;
ctax.up(r,a,tsim)$ctaxFlag(r,a) = +inf ;
\end{lstlisting}

After transferring the data files from the data folder to the
simulation folder, the user needs to initialize the
parameter \texttt{pcarb0} for the simulations---it should
have the same value as that used for Altertax. This can
be set in the 'Prm' file, for example:

\begin{verbatim}
pcarb0(r,ghg,a) = 0.25 ;
\end{verbatim}

The 'check' simulation should be balanced, the calibration
of the GHG bundle should yield small shares, and 'small' revenues
should be generated by the initially low carbon price.

\subsection{Integrated command file}

The distribution is delivered with a Windows command file,
\texttt{makeData.cmd}, that can be used to run all of the modules in sequence.
To run the command, type the following in a Windows console:

\begin{verbatim}

   makeData [baseName] [-ifFilter] [-ifAlt] [-ifEnv]

\end{verbatim}

\noindent This will invoke the \texttt{makeData} command file. There are three
options. To invoke the filter module, enter the \texttt{-ifFilter} option on the
command line. To invoke the Altertax module, enter the \texttt{-ifAlt} option on
the command line. To prepare an aggregation for the \textsc{Envisage} Model,
enter the \texttt{-ifEnv} option on the command line. N.B. We have made every
attempt to make the \texttt{makeData} command file as robust as possible---but
coding a Windows command file is not for the faint-hearted. We would be happy to
have any feedback on its robustness and usefulness.

The \texttt{makeData} command file automates the copying and moving of files.
In a first step, it will create a folder with the name of the aggregation code,
\texttt{[basename]} if it does not exist. It will also create the four
sub-folders: \texttt{Agg}, \texttt{Flt}, \texttt{Alt} and \texttt{Fnl}. The
aggregation routine creates 10 GDX files (and optionally the CSV file). The
filter routine only modifies the five data files: \texttt{[basename]Dat.gdx},
\texttt{[basename]Vole.gdx}, \texttt{[basename]Emiss.gdx},
\texttt{[basename]NCO2.gdx} and \texttt{[basename]Wages.gdx}. The
\texttt{makeData} command file copies the other (non-modified) files from the
\texttt{Agg} folder to the \texttt{Flt} folder. Similarly for Altertax, the
command file will copy the non-modified files from the \texttt{Flt} folder to
the \texttt{Alt} folder. If the respective routines are not invoked, the command
file will copy ALL files from one folder to the next. In a final step, all the
GDX files in the \texttt{Alt} folder will be copied to the \texttt{Fnl} folder
from where the user can copy the final data and parameter files to the working
folder for subsequent simulations.

\section{Model Simulations}

\subsection{Introduction}

We introduce in this section how to run \textsc{Envisage} model simulations.
There are three fundamental types of simulations:

\begin{itemize}
   \item Comparative static. Comparative static involves introducing a shock to
         the benchmark database with no dynamic elements---such as factor
         accumulation, technology and preference changes, etc. (of course a
         comparative static shock could include a shock to one of these
         elements). The key difference between the comparative static and
         dynamic version of the model is the specification of the capital
         account as described in the model description. Capital markets close
         with a CET transformation function in the comparative static version,
         which also has no vintage capital. In the dynamic version, installed
         capital is assumed to be only partially mobile across activities and
         the model explicitly incorporates vintages.
   \item Recursive dynamic with baseline calibration. This version of the model
         is dynamic and the model is used to determine some model parameters
         subject to some targets. For example, GDP growth may be exogenous and
         labor productivity is calibrated to achieve a given growth target,
         and/or the investment to GDP ratio is targeted and the household
         savings rate is adjusted to meet the target, etc.
   \item Recursive dynamic shock scenario with pre-calibrated dynamic
         parameters. This type of dynamic scenario will use the results from the
         baseline calibration scenario for some of the underlying dynamic
         trends, for example labor productivity. In the absence of a shock,
         this type of simulation should re-produce the baseline scenario.
\end{itemize}

There is no single best way to run model simulations---in either comparative
static or dynamic mode as GAMS provides great flexibility. We introduce herein
a unified system that can work for all three types of simulations. This system
is useful because it highlights the differences across the simulation types.
It does have some potential drawbacks that will be highlighted below.

\subsection{Preliminaries}

The model code is composed of a series of GAMS file, this helps with
modularizing the code. Typically, all of the core model code will be available
in a single folder and the user will set the \texttt{idir} option in GAMS to the
location of the core model code, say for example in the \emph{Model} directory.

Table~\ref{tab:modFiles} is a list of the files that constitute the core model
code. The model's declarations and equation specification are contained in the
\texttt{model.gms} file.

\begin{table}[H]
\caption{Distributed model files}
\label{tab:modFiles}
\small
\begin{center}
\rowcolors{2}{TableOdd}{TableEven}
\rowcolors{1}{}{lightblue}
\begin{tabular}{p{3.0cm} p{12.0cm}}
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
{\normalsize \textbf{\emph{File name}}} & {\normalsize \textbf{\emph{Description}}} \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
{cal.gms}      & {Calibration of model parameters} \\
{closure.gms}  & {Default closure assumptions} \\
{compScen.gms} & {'Scenario' file for comparative static simulatons} \\
{getData.gms}  & {File that reads the GDX-based input files.} \\
{init.gms}     & {Initialization of model variables} \\
{initScen.gms} & {Scenario file for dynamic simulations} \\
{InitVar.gms}  & {Inter-period initialization of model variables} \\
{initVint.gms} & {Second period initialization of vintage volume variables} \\
{iterloop.gms} & {Inter-period code} \\
{miscDat.gms}  & {Currently this file contains only an energy conversion table. It is used post-simulation.} \\
{model.gms}    & {Core model specification} \\
{postsim.gms}  & {Post-simulation statements---mostly creation of output CSV files} \\
{recal.gms}    & {Inter-period core code to update vintage technology parameters and potentially other dynamically calibrated parameters such as the Armington preference parameters} \\
{recalnnn.gms} & {Code that updates technology parameters such as \texttt{and1}} \\
{recalnnt.gms} & {Code that updates technology parameters such as \texttt{aland}} \\
{recalnrg.gms} & {Code that updates technology parameters such as \texttt{aNRG}} \\
{recalvat.gms} & {Code that updates technology parameters such as \texttt{axp}} \\
{recalvnn.gms} & {Code that updates technology parameters such as \texttt{ava}} \\
{recalvnt.gms} & {Code that updates technology parameters such as \texttt{ak}} \\
{recalxanrg.gms}  & {Code that updates technology parameters such as \texttt{aeio} with no energy nesting} \\
{recalxanrgn.gms} & {Code that updates technology parameters such as \texttt{aeio} with energy nesting} \\
{sam.gms}      & {Code that writes out the simulation SAMs in CSV format} \\
{SaveParm.gms} & {Code that writes out key parameters} \\
{scale.gms}    & {Code that scales model variables/equations. Currently not used.} \\
{solve.gms}    & {Code that invokes the solver.} \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\end{tabular}
\end{center}
\end{table}

Figure~{\ref{fig:simFlowChart}} provides a schematic view of a simulation. In
the current setup, the user prepares a project specific file with the name
\texttt{[basename]Opt.gms}. This file contains the common options and statements
across all simulations in the project. It is designed to handle both comparative
static and dynamic simulations. Many of the global options can be over-ridden in
subsequent simulation files (for example \texttt{runSim.gms}), however, it is
normally not possible to override set definitions such as time. The first step
in a simulation file, such as \texttt{runSim.gms} is to read the options file.
The options file will also load a number of the core GAMS code and some user
files. The 'Sets' file, which is user-based, is generated by the aggregation
facility and normally requires no further input. The parameter file, described
below does need user input for each project. The core code that is read
includes the model specification (\texttt{model.gms}), reading of
GDX-based input data files (\texttt{getData.gms})\footnote{[1-Dec-2018] Reading
of the base data files was separated from the model initialization routine.
This allows the user to make direct changes to the database before variable
initialization and parameter calibration.}, initialization of model variables
(\texttt{init.gms}), model calibration (\texttt{cal.gms}) and the default
closure rules (\texttt{closure.gms}). After defining the default closure the
model is ready to be solved.

The model is solved over time---even in the case of comparative static
simulations---albeit skipping the first period, which will contain the
initialized and calibrated solution using the base data. A number of statements
are executed at the beginning of each period that initializes variables, may
recalibrate technology parameter (to be described), updates time-based shocks in
the case of dynamic scenarios and introduces shocks for both comparative static
and dynamic simulations. Once all of the period updating is finished, the solver
is invoked. The simulation file will loop over all time periods---as long as the
model converges. After looping over all periods, model results will be
saved---optionally in a CSV file and always in GDX format.

\begin{figure}
\caption{Simulation flow chart}
\label{fig:simFlowChart}
\begin{center}
\begin{tikzpicture}[node distance = 2cm, auto]
\small
% Place nodes
\node [block] (init) {Define time and simulation options ([basename]Opt.gms)};
\node [block, below of=init] (modSpec) {Model specification: sets, parms, model.gms};
\node [cloud, right of=modSpec] (prmFile) {Parameter file};
\node [block, below of=modSpec] (modInit) {Model initialization: getData.gms, init.gms, cal.gms, closure.gms};
\node [cloud, left of=modInit] (aggFile) {Aggregation files};
\node [decision, below of=modInit, node distance=2.4cm] (loop) {loop over time};
\node [block, below of=loop, node distance=2.4cm] (iterloop) {iterloop.gms \\ initvar.gms, recal.gms};
\node [block, below of=iterloop] (shocks) {ifDyn BaUShk.gms, [simName]Shk.gms};
\node [smallblock, right of=iterloop, node distance=5cm] (initvint) {initvint.gms if ifDyn and t=2};
\node [decision, below of=shocks, node distance=2.4cm] (solver) {solver.gms, converge?};
\node [smallblock, right of=solver, node distance=5cm] (stop) {stop};
\node [smallblock, left of=iterloop, node distance=5cm] (timecheck) {Continue if within time frame};
\node [block, below of=solver, node distance=2.4cm] (output) {Output: postsim.gms, sam.gms};
% Draw edges
\path [line] (init) -- (modSpec);
\path [line] (modSpec) -- (modInit);
\path [line] (modInit) -- (loop);
\path [line] (loop) -- (iterloop);
\path [line] (iterloop) -- (shocks);
\path [line] (shocks) -- (solver);
%\path [line] (loop) -| node [near start] {yes} (iterloop);
\path [line,dashed] (solver) -| node [near start, color=black] {yes} (timecheck);
\path [line,dashed] (timecheck) -- (iterloop);
\path [line] (solver) -- node {no}(stop);
\path [line] (solver) -- (output);
\path [line,dashed] (aggFile) -- (modInit);
\path [line,dashed] (prmFile) -- (modSpec);
%\path [line,dashed] (prmFile) |- (modInit);
\path [line,dashed] (initvint) -- (iterloop);
\end{tikzpicture}
\end{center}
\end{figure}

In a typical application, the user will create a project directory with the base
name of the project. The simulation files will be contained in that directory.
The distribution comes with several files that provide examples of how to run
both comparative static and dynamic simulations. Beyond the aggregated data
files, the user needs to prepare a file with the model parameters. This file can
be fairly generic if based on an aggregation of one of the existing parameter
files. However, there a number of options that users need to define to complete
the model specification---such as the labor market closure.

\subsubsection{The user-based parameter file}

While most of the inputs to the model are prepared by the aggregation facility,
it is up to the user to prepare the file with project-specific model parameters.
The file has the name \texttt{[basename]Prm.gms}. There is a generic parameter
file that simply initializes all model parameters to those generated by the
aggregation facility. These can be overridden---after the ones from the
aggregation facility are loaded, but before the initialization of the model
parameters. The read-in parameters will have a suffix of '0'. The model
parameters have no suffix.

The aggregated parameters reflect values used by the OECD's Environment
Directorate Env-Linkages Model (\cite{ChateauetalOECD2014}). The
\texttt{Envisage} Model has some new features not fully reflected in the
original Env-Linkages Model, such as the power and water module. The file does
include some initial levels for the power elasticities, but [for the moment]
does not include the elasticities for the water module. These must be entered by
the user if the water module is active. Another critical set of elasticities is
the natural resource supply elasticities. [NEW] It is the user's responsibility
to enter these elasticities (for the original model aggregation). The user must
enter a pair of elasticities for each natural resource and for all regions. The
parameter to be initialized is \texttt{etanrfx0} that takes three indices:
region, activity and a special one that takes the values of 'lo' and 'hi'. This
latter is represented by the set \texttt{lh}. These refer to the supply
elasticity to apply as a function of market conditions. The 'lo' supply
elasticity is to be used for a market under contraction. The 'up' supply
elasticity is to be used for an expanding market. Intuition suggests that the
'lo' elasticity will be greater than the 'hi' elasticity, i.e. it is easier to
contract supply than to expand it. These should be carefully scrutinized and
potentially adjusted during baseline simulation runs.

[NEW] The user must enter the investment allocation elasticities to be used with
the flexible capital flow specification. The initial elasticities are to be
initialized with the parameter \texttt{epsRor0}. The default value for the GTAP
model is 10.

[NEW] There are a number of parameters to be entered by the user for the
USAGE-inspired capital account closure. The user must enter the bounds on the
growth of capital in any given year. These are entered in the parameters
'\texttt{grKMin0}' and '\texttt{grKMax0}'. Normal trend growth is entered in the
parameter '\texttt{grKTrend0}'. The curvature of the logistic function at the
equilibrium point of the capital supply schedule is entered in the parameter
'\texttt{chigrK0}'. The user must also enter the so-called normal rate of
return, from which the deviations are evaluated. This is entered in the
parameter '\texttt{RoRn0}'.

The comparative static version of the model uses a weighted average of the
vintage-dependent elasticities. Users are free to change the weights, where the
default values are 0.8 for \emph{Old} and 0.2 for \emph{New}.

There are a number of other key assumptions that are included in the parameter
file. The first relates to the labor market assumptions. The user must
initialize the matrix of options in the parameter \texttt{labHyp}. It has a
regional and skill index and 11 attributes described below.

\begin{enumerate}
   \item \texttt{omegam}. This determines labor market segmentation. A finite
         value will implement labor market segmentation---typically defined over
         agricultural versus non-agricultural activities. Perfect labor mobility
         is implemented if the value is infinity (\texttt{INF}). If it is
         finite, this will be the value of the labor mobility elasticity in
         equation~(\ref{eq:migr}), $\omega^m$, the elasticity of rural to urban
         migration with respect to the expected urban wage premium.
   \item \texttt{migr0}. This determines the initial level of migration as a
         percent of the rural labor force. For example, if it is set to 1.0,
         the initial level of rural to urban migration will be set to 1\% of the
         rural labor force. It is ignored if the migration elasticity is
         infinity.
   \item \texttt{uezRur0}, \texttt{uezUrb0}. These parameters provide the
         initial unemployment rate (in percent) in respectively the rural and
         urban labor markets. In the case of full labor mobility, only the urban
         unemployment rate is active and the rural rate is ignored.
   \item \texttt{uezminzRur0}, \texttt{uezminzUrb0}. These parameters provide
         the lower bound for the unemployment rate (in percent) in respectively
         the rural and urban labor markets. The rural rate is ignored in the
         case of full labor mobility. An error will be issued if the initial
         unemployment rate is less than the minimum unemployment rate.
   \item \texttt{resWageRur0}, \texttt{resWageUrb0}. These parameters determine
         the initial level of the reservation wage with respect to the
         prevailing wage. A value of 1 indicates that the reservation wage is
         binding and the the unemployment rate is greater than (or equal to) the
         minimum unemployment rate. A value less than one indicates the distance
         between the initial equilibrium wage and the reservation wage. The
         rural reservation wage is ignored in the case of full labor mobility.
         A value of \texttt{NA} indicates full employment (at all times). An
         error will be issued if the value is greater than 1.
   \item \texttt{omegarwg} \texttt{omegarwue} \texttt{omegarwp}. The reservation
         wage is a function of three indicators---the growth of per capita GDP,
         the unemployment rate and the CPI. The elasticity is positive for
         income growth and the CPI. The reservation wage is negatively related
         to the unemployment rate, i.e. an increase in unemployment would tend
         to dampen the reservation wage. To avoid problems with division by
         zero, the relationship between the reservation wage and unemployment is
         converted to a relationship between the reservation wage and the
         employment rate, i.e. $(1-\mathit{UE})$. Thus if the elasticity of the
         reservation wage is $\omega^{\mathit{ue}}$, the elasticity of the
         reservation wage with respect to the employment rate is
         $-\omega^{\mathit{ue}}\left(1 - \mathit{UE}\right)/\mathit{UE}$. The
         user is expected to enter the elasticity with respect to the employment
         rate and it should be a positive number.
\end{enumerate}

There are three additional parameters that allow for control of the dynamics of
the capital market. The first, \texttt{cap\_out\_Ratio0}, allows for overriding
the initial capital to GDP ratio. The initial capital stock is an estimate
derived from the Penn World
Tables.\footnote{\url{http://www.rug.nl/ggdc/productivity/pwt/}} For some
countries and/or regional aggregations the estimates can lead to significant
jumping off problems in the initial years. A value of \texttt{NA} will ignore
the override. The parameter is entered as a multiplicative adjustment
of the initial capital stock. The default value is 1.0.
The second is the depreciation rate, \texttt{deprT}, which for
some rapidly growing countries is too low. The default GTAP value is 4\%. The
third is an investment target, \texttt{invTarget0}. Users can input this for
particular years, e.g. 2030 and 2050. Code in the 'Opt' file will translate
these targets into linear changes for the investment target, for example between
2011 and 2030 and then between 2030 and 2050, in order to smooth the path
between target years.

The final section allows the user to implement 'twists' to the Armington
preference parameters. There are three sets of twist parameters and one
twist-related regional mapping set. The top-level Armington twists require two
different parameters depending on the value of \texttt{ArmFlag}. In the case of
national sourcing, i.e. when \texttt{ArmFlag} = 0, the relevant twist parameter
is \texttt{twt1}, which is region-, commodity and time-specific. With
agent-based sourcing, i.e. when \texttt{ArmFlag} = 1, the relevant twist
parameter is \texttt{tw1}, that is in addition agent-specific. A positive value,
for example 0.02, would lead to a change in the ratio of imports to domestic
demand of 2~percent---assuming constant prices. The parameter \texttt{tw2} is
applied to the second level nesting. The $r$ index refers to the importing
country. The twist can be applied to one single region, or a group of regions.
The user designates the targeted exporters in the regional mapping set
\texttt{rtwtgt}. The first regional index in the mapping set refers to the
targeted exporters and the second regional index refers to the importer. For
example, to increase the import shares of China, Japan and Korea in the U.S.
using the twist, the relevant mapping is \texttt{(chn,jpn,kor).usa}. Note that
in this implementation, the same twist is applied uniformly across the targeted
exporters.

\subsection{Common options}

The first set of global options are entered as definitions through GAMS'
\texttt{\$setGlobal} statement. The following enumerates the options:

\begin{enumerate}
   \item \textbf{wDir}. By default this is set to the active directory.
   \item \textbf{SSPMOD}. This option defines the choice of the economic model
         used for the SSP GDP projections. There are currently two choices:
         \texttt{OECD} and \texttt{IIASA}.\footnote{The PIK projections have not
         been processed since they reflect a fixed aggregation of 32 regions,
         whereas the OECD and IIASA projections were done for most countries.}
   \item \textbf{SSPSCEN}. This option defines which SSP to use for the GDP
         projections (and will be combined with the model choice). There are
         five valid options: \texttt{SSP1}-\texttt{SSP5}.
   \item \textbf{LABSCEN}. This option influences the relative growth of skilled
         versus unskilled labor. If it is set to one of the SSPs, the education
         profiles from the SSPs---with the user mappings of skilled workers to
         education levels (\texttt{educMap}) together with the \texttt{skLabgrwgt}
         parameter (see below)---will
         determine the growth rate of skilled workers. The growth of unskilled
         workers will be determined residually so that the overall growth or
         workers matches the growth of the working age population. If this
         parameter is not equal to one of the SSPs, both skilled and unskilled
         workers will grow at the same rate as the working age population,
         i.e. no differentiation of growth by skill.
   \item \textbf{POPSCEN}. This option defines which population projection to
         use. There are ten valid options. The IIASA SSP population projections
         are labeled \texttt{SSP1}-\texttt{SSP5}. The scenario file also
         includes four UN population projections: \texttt{UNMED2010},
         \texttt{UNMED2012}, \texttt{UNMED2015} and \texttt{UNMED2017}. Finally, the World Bank's
         GIDD projections are available with the label \texttt{GIDD}. The latter
         is intended to duplicate UNMED2015. It is only available through 2050.
   \item \textbf{OVERLAYPOP}. This option allows to replace GTAP's base year
         population level with that from the scenario database. In any case,
         only the growth rates from the population projections are used from the
         initial base year level.\footnote{There is currently an inconsistency
         in the population levels in the SSP database and GTAP. In the former,
         population is in levels and in the latter it is millions.
         The inputs from the SSP database are currently scaled by a million to
         make them consistent with the GTAP units. The population scale factor
         can be used to improve the population scale on an as-need basis.}
   \item \textbf{TASS}. This option determines the specification for the
         aggregate land supply curve. Valid options are: \texttt{KELAS} for
         iso-elastic supply, \texttt{LOGIST} for logistic supply curve,
         \texttt{HYPERB} for hyperbola supply curve, and \texttt{INFTY} for
         infinitely elastic (i.e. horizontal) supply curve.
   \item \textbf{WASS}. This option determines the specification for the
         aggregate water supply curve. It has the same valid options as the
         aggregate land supply curve.
   \item \textbf{utility}. This option determines the specification of the
         household utility function. Five options are available: \texttt{CD} for
         the Cobb-Douglas utility function, \texttt{LES} for the linear
         expenditure system, \texttt{ELES} for the extended linear expenditure
         system, \texttt{AIDADS} for the AIDADS demand system, and \texttt{CDE}
         for the Constant-difference-in-elasticity demand system. The
         \texttt{CD}, \texttt{LES} and \texttt{AIDADS} are new options. The LES
         is calibrated to the Frisch parameter, which is currently
         parameterized in the calibration routine (\texttt{cal.gms}), but it
         would be preferable to have this entered as user input. AIDADS is
         coded, but there is no calibration. It has been tested assuming the LES
         as one of the special cases of AIDADS. The Cobb-Douglas simply uses the
         base year budget shares to calibrate the marginal budget shares and the
         subsistence minima are set to zero.
   \item \textbf{NRITER}. This option controls the number of iterations when
         running the model convergence in single country mode. As this has not
         been tested with the latest version of the model, it is best to set
         this option to 0.
   \item \textbf{savfFlag}. This option controls the capital account closure.
         Three options are currently available. A value of \texttt{capFix} uses
         the fixed capital account closure rule. A value of \texttt{capFlexGTAP}
         uses the flexible capital account closure rule of the GTAP model. This
         closure allocates global savings in order to equalize expected returns
         across regions. A value of \texttt{capRFix} fixes the ratio of savings
         relative to nominal GDP. A value of \texttt{capFlexUSAGE} uses the flexible
         capital account closure rule inspired by the USAGE model. This closure
         allocates global savings as a function in deviations of the regional
         rate of return from the 'normal' rate of return.
   \item \textbf{intRate}. The user sets this option to the desired value for
         the global real interest rate. The default value is 5\% (i.e. 0.05).
         Note that this parameter is currently only used by the USAGE capital
         account closure.
   \item \textbf{costCurve}. Cost curves are used to implement downward trends
         of new technologies (e.g. renewable electricity). These can be
         implemented using either a hyperbolic (\texttt{HYPERB}) or with a logistic
         function (\texttt{LOGIST}).
   \item \textbf{NTM\_MODULE}. This flag takes the value of \texttt{ON} to implement the
   		 non-tariff measure module, or \texttt{OFF} otherwise. It expects
           to read a GDX-based satellite account with the \emph{basename} followed
           by \texttt{NTM}, e.g., \texttt{ANX1NTM.gdx}.
   \item \textbf{MRIO\_MODULE}. This flag takes the value of \texttt{ON} to implement the
   		 MRIO module, or \texttt{OFF} otherwise. It expects
           to read a GDX-based satellite account with the \emph{basename} followed
           by \texttt{MRIO}, e.g., \texttt{ANX1MRIO.gdx}.
   \item \textbf{RD\_MODULE}. This flag takes the value of \texttt{ON} to implement the
   		 R~\&~D module, or \texttt{OFF} otherwise. It expects
           to read a GDX-based satellite account with the \emph{basename} followed
           by \texttt{R\_D}, e.g., \texttt{ANX1R\_D.gdx}. If the file
           does not exist, it will assume that the cost structure is
           identical to the cost structure for government expenditures
           and scale the costs to some percentage of GDP, which will
           be specified in the \texttt{KnowledgeData0} parameter
           of the user parameter file. The R~\&~D expenses will
           be extracted from government expenditures.
   \item \textbf{DEPL\_MODULE}. This flag takes the value of \texttt{ON} to implement the
   		 resource depletion module for coal
            oil and gas resources, or \texttt{OFF} otherwise. It expects
           to read a GDX-based satellite account with the \emph{basename} followed
           by \texttt{DEPL}, e.g., \texttt{ANX1DEPL.gdx}.
   \item \textbf{CLIM\_MODULE}. This flag takes the value of \texttt{ON} to implement the
   		 climate module. The module is initialized from a
         GAMS file, which is calibrated for a specific reference year, for example,
         2014. (For the moment, there is no version available for GTAP V11 with a 2017 reference year.)
   \item \textbf{DAMAGE\_MODULE}. This flag takes the value of \texttt{ON} to implement the
   		climate damage and adaptation module, or \texttt{OFF} otherwise. This is under development.
   \item \textbf{FBS\_MODULE}. This flag takes the value of \texttt{ON} to implement the
   		 nutrition module, or \texttt{OFF} otherwise. It expects
           to read a GDX-based satellite account with the \emph{basename} followed
           by \texttt{FBS}, e.g., \texttt{ANX1FBS.gdx}.
   \item \textbf{ifBKSTP}. This flag takes the value of \texttt{ON} to implement backstops, or \texttt{OFF} otherwise. This is under development.
   \item \textbf{ifDEPR0}. This flag takes the value of \texttt{ON} to run the
   model on a gross investment basis, or \texttt{OFF} to run the
   model on a net investment basis. When set to \texttt{ON}, the incoming \texttt{VDEP} array is set to 0.
   \item \textbf{ifVINT}. This flag takes the value of 1 to run
   dynamic simulations under the vintage capital assumption, or 0 to run dynamic simulations with a single vintage.
\end{enumerate}

The remaining global options are entered as scalars. The first set provide the
context for the model: comparative static and recursive dynamic with or without
dynamic calibration.

\begin{enumerate}
   \item \textbf{ifDyn}. This option takes two values. A value of 0 indicates a
         comparative static model. A value of 1 indicates a dynamic model. In
         the standard package, this will be set automatically when the
         simulation is invoked and the user sets the \texttt{simType} option.
         Valid values are \texttt{CompStat} and \texttt{RcvDyn}.
   \item \textbf{ifCal}. This option takes two values and is only meaningful for
         dynamic scenarios. A value of 0 runs a dynamic scenario with
         pre-calibrated trends (generated by a baseline). A value of 1 runs a
         dynamic calibration scenario where specific dynamic trends are
         calibrated to exogenous indicators such as GDP. This value will be set
         in dynamic variables by setting the \texttt{ifCal} option when invoking
         the simulation.
   \item \textbf{ifVint}. This options takes the value 0 or 1. It is set
         automatically when the simulation is invoked by the user. A value of 1
         implements vintage capital, which is valid only for dynamic
         simulations. It should be set to 0 for comparative static simulations.
\end{enumerate}

The remaining global options are typically invariant across simulations. The
following list enumerates the options.

\begin{enumerate}
   \item \textbf{inScale}. Scale factor for input data. The input SAM is
         typically in millions. A scale of $10^{-6}$ has been found to be a
         useful scaling factor.
   \item \textbf{outScale}. Scale factor for output data. This is typically just
         the inverse of \texttt{inScale}.
   \item \textbf{popScale}. Scale factor for population. Often set to $10^{-6}$,
         though need to check on the population level inconsistencies.
   \item \textbf{lScale}. Scale factor for labor volumes. [Need to verify scale
         in 'wages' database.]
   \item \textbf{eScale}. Scale factor for energy. The energy volumes are in
         million tons of oil equivalent (MTOE). A scale factor of 0.001 is
         typically used.
   \item \textbf{watScale}. Scale factor for water, typically $10^{-12}$ is
         used. [Check units of volume database.]
   \item \textbf{cScale}. Scale factor for emissions, typically 0.001 is used.
         [Check units for emissions.]
   \item \textbf{ifCEQ}. Convert emissions to CEq. Input emissions are in
         \COT{}eq. If this flag is set to 1, the units will be converted to Ceq.
         The climate module [tbd] is based on emissions in Ceq.
   \item \textbf{ArmFlag}. Set to 1 for agent-based Armington. If the flag is
         set to 0, the top level Armington sourcing is done at the aggregate
         level. [This is a new option.]
   \item \textbf{MRIO}. Set to 1 for agent-based second-level Armington, i.e.
   	     to use the MRIO version of the model. [This is a new option.]
   \item \textbf{ifNRG}. Set to 1 to use energy volumes. This will provide a
         volume/price split for energy commodities.
   \item \textbf{ifNRGNest}. Set to 1 for energy nesting. A value of 0 will have
         only a single nested energy nest.
   \item \textbf{ifMCP}. Set to 1 for MCP. A value of 0 will use NLP. The
         objective function is Walras' Law.
   \item \textbf{ifLandCET}. Set to 1 to use CET for land allocation. A value of
         0 will use the additive CET specification.
   \item \textbf{ifSUB}. Set to 1 to substitute out equations. A value of 0 will
         have the full model specification without substitution. This will
         considerably increase the size of the model.
   \item \textbf{IFPOWER}. Set to 1 for power module, which requires the power
         database, else set to 0.
   \item \textbf{IFWATER}. Set to 1 for water module, which requires the water
         database, else set to 0
   \item \textbf{ifAggTrade}. Set to 1 to aggregate trade in SAM. A value of 0
         will have the full bilateral trade matrices output as part of the SAM.
   \item \textbf{skLabgrwgt}. Set to between 0 and 1. This determines the growth
         assumptions for skilled and unskilled labor. The growth of skilled
         labor is driven by the growth of the appropriate education categories.
         The growth of unskilled labor will then be calculated by residual since
         the growth of overall labor will be determined by the growth of the
         working age population (15-64). One can use this parameter to modulate
         this calculation. If the weight is set to 1, then the growth rate of
         skilled labor will match exactly the growth of the corresponding
         education categories, ignoring any resulting impact on the growth of
         unskilled labor. At the other extreme, if the weight is set to 0, the
         growth of both skilled and unskilled will be identical and equal to the
         growth rate of total labor, i.e. the education profiles are fully
         ignored. Users can choose an intermediate value between 0 and 1.
    \item \textbf{EXR}. This is an exchange rate, which defaults to 0. It can be useful to present results in a different currency, e.g., euro, yen, rands, etc., when working on a study for a particular country or region.
\end{enumerate}

\subsection{Comparative static simulations}

In the current setup, there is very little difference between running
comparative static and simulations dynamic simulations. Both the
\texttt{runsim.gms} and \texttt{[basename]Opt.gms} files are coded to run both
types of simulations. One of the key differences between the two is the time
framework. The standard comparative static simulation has three 'time' periods
labeled \texttt{base}, \texttt{check} and \texttt{shock}. The user is free to
modify these in the 'Opt' file. One of the primary purposes of the comparative
static version of the model is to test model initialization, calibration and
homogeneity. It is also extremely useful to test new model specifications or
parameterizations. With a new model version---for example a new aggregation, new
specification or parameterization, it is always recommended practice to do a
full diagnostic check.

A standard diagnostic check is to run the comparative static model with a single
homogeneity shock in the \texttt{shock} time period. The \texttt{base} year is
never run, it is meant to be able to replicate the initial database. The
\texttt{check} simulation replicates \texttt{base} if the initialization and
calibration are working correctly. For this reason, it is important to look at
the largest residual in the listing file (or console). Open the listing file and
do a search for \texttt{LOOPS}. This should take you to the diagnostics for the
first simulation, i.e. the \texttt{check} simulation. Model diagnostics will
appear by scrolling down---for example model size. The key diagnostic is
\texttt{INITIAL POINT STATISTICS}. The maximum of \texttt{F} should be 0 or near
zero. The largest error should reflect more or less the precision of the input
SAM. One may also want to observe the initial Jacobian to see the range of the
minimum and maximum elements. The range should be relatively narrow. A good
maximum should be no larger than \texttt{1.0e003}. A larger number is an
indication of a scaling issue.

A second check of the model is to look at the values for the \texttt{LHS} in the
list code, which stands for the left-hand side. This is controlled by the
\texttt{LIMROW} option. It may default to either 0 or 3. In the case of 0, no
equations will be listed. In the case of 3, up to 3 in any block will be listed.
Setting \texttt{LIMROW} to a higher number will increase the number of equations
printed in a block, for example: \texttt{Options limrow=100 ;}. The equations
listing shows the value of the residual of an equation, i.e. it collects all
endogenous variables on the left-hand side and evaluates the expression and it
collects all additive exogenous variables and parameters on the right-hand side
and evaluates the right-hand side expression. It then displays the value of the
left-hand side that should match the displayed right-hand side. In most cases,
the right-hand side will evaluate to 0, but it does not have to.\footnote{For
example the labor equilibrium condition will have the exogenous supply of labor
on the right-hand side.} If there is a serious initialization/calibration
problem, it may be necessary to increase \texttt{limrow} and visually go through
the equation listings. For a quick inspection, do a search for \texttt{LHS} to
find the first equation in the listing file. Then search for \texttt{****}. The
four asterisks indicate an 'infeasible' solution. Note that in most cases, the
infeasibility is likely to be a very small number---and typically reflects the
accounting precision of the incoming SAM. To avoid nuisance infeasibility, one
can increase the tolerance level by using the \texttt{tolinfrep} attribute of a
model. In the default settings, the infeasibility tolerance has been set to
\texttt{1.0e-005}, and with a well-balanced SAM, this will generally avoid any listed
infeasibilities.

The homogeneity test requires a shock file. The shock file should have the same
name as the simulation. Thus if the simulation is assigned the name
\texttt{COMP}, the user should create the a file named \texttt{COMPShk.gms}.
Listing~\ref{lst:homShock} illustrates one way of implementing the homogeneity
shock. It tests the value of the time period, and then increases the value of
the exogenous {num\'eraire} by 50\%.

\begin{lstlisting}[language=GAMS, caption={Homogeneity shock}, label=lst:homShock]

if(sameas(tsim,"shock"),
   pnum.fx(tsim) = 1.5*pnum.l(tsim) ;
) ;

\end{lstlisting}

It is useful to do a quick check of the diagnostics by loading the output CSV
file into Excel---and most convenient in Excel's pivot tables. The first thing
to look at is the resulting SAM's. All accounts should be perfectly balanced for
each individual region and for each time period. The second diagnostic is to
compare the \texttt{base} values with the \texttt{check} values. They should be
identical to within vary narrow margins. A third check is to compare the
\texttt{check} values with the \texttt{shock} values. All volume variables
should be identical and all value variables and prices should have increased by
the same percentage amount as the {num\'eraire}, for example 50\%.

These are minimal diagnostics, but the user may want to do others---particularly
if there is a change in specification. These would include shocks to taxes, for
example tariffs, shock to factor stocks, productivity shocks, etc.

The distribution comes with an option file for the '10x10' aggregation, as well
as the generic \texttt{runsim.gms} file. The latter is set to handle many
different situations but users may find it useful and/or necessary to make a
copy of it and insert modifications. The distribution also comes with a command
file that is needed to run the file in a Windows console. To run the homogeneity
test, the command line could be the following:

\begin{verbatim}

   runsim Homog Comp CompStat 0

\end{verbatim}

\noindent The first argument will be the simulation name. In comparative static
simulations the second argument is ignored, but must be present. In dynamic
simulations it is the name of the baseline file. The third argument must be
\texttt{CompStat} for comparative static simulations. The fourth argument is
ignored for comparative static simulations, it is used for dynamic simulations.
It is best to set it to zero.

Users will need to modify the \texttt{runsim} command file for their
installations. An example is depicted below.

\begin{verbatim}

   gams runSim --simName=%1 --BauName=%2 --simType=%3 --ifCal=%4 --baseName=10x10
      --odir=v:\Output\EnvLink\10x10 -idir=..\model5n
      -scrdir=v:\Output\EnvLink\10x10 -ps=9999 -pw=150

\end{verbatim}

\noindent The \texttt{runSim} command file expects at least the four arguments as described
above. It is setup for a specific project. In this case it is setup for a
project named '10x10'. The user needs to specify a folder for the output
directory. Use '.' to specify the current directory. It is also required to
specify the model directory. In the example above, the model directory is at the
same level as the simulation directory and named \texttt{model5n}. The remaining
parameters are optional and the user is free to add others.\footnote{Simulation
output can be voluminous depending on the aggregation and the time span of a
simulation. With increasing use of backups and the cloud, it is sometimes useful
to store output on non-critical storage in order to minimize bandwidth problems
and exceeding allowed storage capacity.}

[NEW 01-Dec-2018] The code in the 'Opt' file has been modified somewhat to improve
the handling of starting point for the model simulation. The old code allowed to
start a simulation by reading in a previous baseline using the
\texttt{execute\_loadpoint} option of GAMS. This is handy if you are running shock
simulations starting in a future year relative to the reference year. The new
code allows the user to specify any simulation as a starting point. The
user can identify the starting simulation on the command line with the
\texttt{startName} option. The Windows command file \texttt{runsimR.cmd} shows
an example of how to use an existing comparative static simulation as a starting
point. If there is no additional shock, the model should solve immediately.

\subsection{Dynamic simulations}

Dynamic simulations are in principle only somewhat more complicated than
comparative static simulations---though in practice raise considerably more
problems. There are two key differences. The first is the time dimension. This
is under the discretion of the user. For GTAP V9, the starting year should be
set at 2011. The terminal year and the intermediate years are at full
discretion. The model is setup to handle year step sizes of more than 1 [though
this probably needs additional testing since it hasn't been used in a while].
One potential problem with multi-year time steps could be convergence, though
this has proven to be less of a problem further out when the model has reached
some sort of steady state. The second key difference is the implementation of
the vintage capital formulation. This in principle should be transparent to the
user.

In principle there is nothing to change in the 'Opt' file nor in the
\texttt{runsim.gms} file. There are default statements that are implemented in
the file \texttt{iterloop.gms} that generate the necessary closures for dynamic
simulations---either the baseline, or pre-calibrated scenarios. Users have some
control in shaping the baseline by modifying or adding statements in the
\texttt{BaUShk.gms} file. In the distributed file, there are two adjustments to
the standard baseline. The first can phase out net capital flows between two
years. The second targets the investment to GDP ratio for
some given future year---both the target and the year are provided by the user.
It endogenizes the savings rate in order to achieve the desired investment
ratio.

Other key dynamic assumptions are embedded in the \texttt{initScen.gms} file
that is in the \emph{Model} directory. In particular the default assumptions on
labor productivity wedges (\texttt{glAddShft} and \texttt{glMltShft}),
autonomous yield growth (\texttt{yexo}), autonomous energy efficiency
improvement (\texttt{aeei} and \texttt{aeec}) and improvements in trade
margins (\texttt{tteff}) are included in this file.[We may revisit this looking
ahead as it is not satisfactory to have these assumptions included in the core
model code.]

The mechanics of the baseline are fairly straightforward---shaping the baseline
is not always straightforward. One of the key issues to arise is the growth of
the capital stock. Base year conditions may lead to extreme jumping off
conditions. For example over-investment may lead to sharply declining rates of
return, and under-investment the reverse. The initial growth of the capital
stock will depend on base year investment (and savings) rates, net capital
flows, the initial stock of capital and the depreciation rate. On balance, one
would like to have as a starting point for the baseline relatively steady
returns to capital, unless there is a good reason to expect rates of return to
rise or drop. It may involve adjusting the initial capital stock and rates of
depreciation. It is not possible to change the initial savings ate including the
capital account, but these can be adjusted over time to yield a desired path for
capital accumulation and rates of return. This is one of the purposes for using
a long-run target for the investment to GDP.

To run the baseline simulation, the command line could be the following:

\begin{verbatim}

   runsim BaU BaU RcvDyn 1

\end{verbatim}

The first argument and second arguments are the name of the baseline. In the
case of running the baseline, the second argument is redundant, but necessary.
The third argument is to invoke a dynamic-type scenario. The fourth argument
invokes the code for dynamic calibration. On occasion, the model will fail
to converge to the terminal year and typically this is due to factor prices
going to some extreme---notably zero for capital in the case of investment
exceeding demand for capital. One may have to restrict the simulation to an
intermediate year and assess intermediate results to understand the nature of
the problem. This can be done by restricting the time loop, for example
\texttt{loop(tsim\$(years(tsim) le 2020)}.

Once the user has a satisfactory baseline, dynamic shock simulations can be
implemented. They are associated with a specific shock file with a base name
linked to the simulation name, \texttt{[simName]Shk.gms}, for example
\texttt{[SSP2ccShk.gms]} to run the SSP2 baseline with climate change impacts.
To run a pre-calibrated dynamic scenario, the command line could be the
following:

\begin{verbatim}

   runsim SSP2CC BaU RcvDyn 0

\end{verbatim}

The first argument is the name of the simulation, and \texttt{runSim.gms} will
try and  open and implement a shock file with a filename that incorporates the
simulation name. The second is the name of the baseline file. At a minimum this
is necessary because the shock simulation needs to extract from the baseline
calibrated information from the baseline---notably the labor productivity
parameter and real government expenditures. Both are assumed to be exogenous
in the shock simulations.\footnote{Users can extract other information from
the baseline on an as-need basis.}

[NEW 01-Dec-2018] The code in the 'Opt' file has been modified to allow for
more flexibility in terms of starting from an existing simulation. The old
code only allowed for starting from the baseline simulation. The new code
allows for starting from any simulation (including the baseline). An existing
simulation is not always the best starting point for solving for a given
year, particularly for a future year. The code allows the user to provide a
year until which the simulation starts from an existing simulation or the
solution from a previous period. To test the baseline simulation, for example,
one could re-run the baseline with no shock but using the calibrated variables
from the baseline, for example:

\begin{verbatim}

   runsimrd noShk BaU RcvDyn 0 BaU 2030

\end{verbatim}

\noindent where the command file \texttt{runsimrd.cmd} is used to invoke
GAMS. This says to run a calibrated recursive dynamic scenario using the
calibrated variables from the baseline scenario called BaU. In addition,
use as the starting point the BaU scenario through the year 2030.
If the dynamics is set up correctly, the
model should solve within 1 iteration in each period. In effect, the
\emph{noShock} scenario is similar in concept to the \emph{Check} scenario for
comparative statics. The rule of thumb is that you can use the baseline till the
first year of a shock. In most cases, initializing with the previous period's
result is better once the shock has been implemented as the shock tends to lead
to sharp deviations from the baseline. For example, if a shock starts in the year 2020,
use the baseline values through 2020 as a starting point, then for subsequent
years, the model with initialize values with the solution from the previous
period---not the baseline simulation. The Windows command file \texttt{runAll.cmd}
contains the batch commands to run the baseline and the no-shock scenario
in sequence. Note that it will make a copy of the 'runSim.gms' file for each
of the simulations and thus the list files will have separate names.

\section{Post-simulation processing}

There is some rudimentary post-simulation processing that is still under development. It
involves two steps. The first step is a GAMS file that reads in a solution and produces
a number of model-based indicators and stores them in different CSV cubes. The CSV
cubes can hold results from one or more simulations. These can be loaded into
Excel files, preferably into pivot tables, and/or alternatively they can be loaded
into statistical or graphical packages such as R for automated generation of figures.

\subsection{User inputs}

The user typically prepares two files---a Windows command file, which facilitates
automating the processing of the GDX file(s), and a user-based option file that
is specific to the simulations. The user-based option file is assumed to have
the name 'baseNameTab.gms', where 'baseNameTab' is replaced with the base name
for the set of simulations, for example '10x10'. Listing~\ref{lst:tabOpt} provides
an example of a 'Tab' file. There are a number of global options that first need
to be initialized.

\begin{enumerate}
\item \textbf{xclDir}. This sets the directory for holding the Excel files. N.B. For
the moment it is best to use the full path name as testing with relative paths
has created errors. For example do not use \texttt{".\textbackslash Doc\textbackslash"} or \texttt{"Doc\textbackslash"}.
This seems to be an issue with the use of the VB scripts under Windows.
\item \textbf{inDir}. This sets the directory for the CSV files. Note that this
will be initialized from the command line parameter '\%oDir\%'.
\item \textbf{wDir}. This sets the working directory. It normally defaults to
the directory that was used to invoke the 'makCSV' program.
\item \textbf{simTgt}. The following set of options initialize the fields for
the pivot tables. \texttt{simTgt} should be set to the code for a valid simulation
or scenario, such as \texttt{BaU}.
\item \textbf{regTgt}. \texttt{regTgt} should be set to the code for a valid region
in the model. Refer to the 'Sets' file to see the valid regions for a specific aggregation.
\item \textbf{timeTgt}. \texttt{timeTgt} should be set to a valid reporting year. Typically
this will be the base, or reference, year.
\item \textbf{actTgt}. \texttt{actTgt} should be set to a valid activity, which
can also be referenced in the 'Sets' file.
\end{enumerate}

The user next provides the reporting years. The set \texttt{tr} is a subset of the
full simulation time framework, which can include all solution years. The time
framework also differs between comparative static and dynamic scenarios. The next
option also permits sub-setting the number of activities reported. It defaults to
all activities and activity aggregations. The user also needs to specify a
conversion factor that is used to convert output from 'primary' electricity
activities. 'Primary' electric activities are those that do not rely on
energy inputs such as coal or gas. The latter have a conversion loss typically
assumed to be a factor of 3, i.e. it takes 3 MTOE of coal or gas to produce
1 MTOE of electricity.\footnote{See \url{https://unstats.un.org/unsd/envaccounting/londongroup/meeting13/LG13_12a.pdf.}}
This factor is only valid for the power-enabled version of the model.

The final set of options is for the cubes (i.e. tables) that will be extracted from
the GDX files. The set \texttt{tables} contains the full list of tables that are
available in the \texttt{makTab.gms} file. The user determines which of the
tables to produce by defining the table subset \texttt{ifTab}.

\begin{lstlisting}[language=GAMS, caption={'Tab' file example for creating CSV cubes}, label=lst:tabOpt]

* ------------------------------------------------------------------------------
*
*     Options for creating CSV cubes
*
*     Users typically select years to output and CSV cubes to create
*
* ------------------------------------------------------------------------------

*  Set folder for Excel files

$setGlobal xclDir "v:\env10\10x10\doc\"

*  Options for CreatePivot file

$setGlobal indir     %oDir%
$setGlobal wdir      %system.fp%
$setGlobal modDir    "..\Model"

*  AgMIP cube?
$setGlobal AgMIP No

$setGlobal DEPLFlag  ON
$setGlobal simTgt    BaU
$setGlobal regTgt    EastAsia
$setGlobal timeTgt   2011
$setGlobal actTgt    Agriculture-a

*  Select report years

$iftheni "%simType%" == "compStat"

   set tr(t)  "Reporting years" / base, check, shock / ;
   set trb(t) "Bilateral trade years" / check, shock / ;
   set trm(t) "MRIO years" / check, shock / ;

$elseifi "%simType%" == "RcvDyn"

   set tr(t) "Reporting years" / 2014, 2017, 2020, 2025, 2030 / ;
   set trb(t) "Bilateral trade years" / 2014, 2030 / ;
   set trm(t) "MRIO years" / 2014, 2030 / ;

$endif

*  Select reporting activities (a subset of aga -- activities + aggregate activities

set aggaga(aga) "Activities to report" ;

*  Report all

aggaga(aga) = yes ;

*  Select MRIO reporting commodities

set mrioc(r,i) "Commodities to report" ;
mrioc(r,i) = no ;

scalar elyPrmNrgConv "Primary electric conversion factor" / 3 / ;

set cpiLab / CPIFUD, CPINFD, CPITOT / ;
set mapCPILab(CPINDX,CPILAB) / TOT.cpiFUD, TOT.CPINFD, TOT.CPITOT / ;

set fpagg / nsk, skl, cap, nrs, lnd / ;
set mapfp(fpagg,fp) /
   nsk.nsk
   skl.skl
   cap.cap
   nrs.nrs
   lnd.lnd
/ ;

*  Pivot tables to create

*  List of tables

set tables /
   gdppop      "Macro data"
   factp       "Factor prices"
   kappah      "Household direct tax rate"
   rgovshr     "Government expenditures"
   savinv      "Savings investment balance"
   xp          "Output by activity"
   va          "Value added by activity and factor"
   inv         "Investment"
   emi         "Emissions"
   cost        "Production costs"
   ydecomp     "Growth decomposition"
   trade       "Trade by sector"
   fdem        "Final demand"
   bilat       "Bilateral trade"
   lab         "Labor demand"
   pow         "Power module"
   sam         "SAM module"
   MRIO        "MRIO table"
   tot         "Terms of trade module"
   nrg         "Energy module"
   depl        "Depletion variables"
   climate     "Climate module"
   shock       "For future use"
   demand      "Demand"
   fbs         "Nutrition module"
   AgMIP       "Cube for AgMIP submission"
/ ;

*  Selected tables

set ifTab(tables) /
   gdppop      "Macro data"
   emi         "Emissions"
   sam         "SAM module"
*  MRIO        "MRIO table"
*  climate     "Climate module"
*  factp       "Factor prices"
*  kappah      "Household direct tax rate"
*  rgovshr     "Government expenditures"
*  savinv      "Savings investment balance"
*  xp          "Output by activity"
*  va          "Value added by activity and factor"
*  inv         "Investment"
*  cost        "Production costs"
*  ydecomp     "Growth decomposition"
*  tot         "Terms of trade"
*  trade       "Trade by sector"
*  fdem        "Final demand"
*  bilat       "Bilateral trade"
*  lab         "Labor demand"
   pow         "Power sector variables"
   nrg         "Energy module"
*  depl        "Depletion variables"
*  shock       "For future use"
   fbs         "Nutrition module"
*  AgMIP       "Cube for AgMIP submission"
/ ;

\end{lstlisting}

\subsection{Extracting the indicators}

The user can invoke the \texttt{makCSV} GAMS program by entering the following
command (or equivalent in the GAMS IDE):

\begin{verbatim}

   gams makCSV --simname=BaU --BaUName=BaU --simType=RcvDyn --ifCal=1
      --ifAppend=0 --BaseName=10x10 --odir=z:\Output\Env10\10x10 -idir=..\Model

\end{verbatim}

Many of the command line options are identical to the \texttt{runsim} command. The user
specifies the name of the simulation (\texttt{simname}), the name of the baseline
simulation, potentially the same (\texttt{BaUname})\footnote{The baseline is on occasion
used to calculate indicators relative to the baseline.}, the simulation type (\texttt{simType}),
and the dynamic calibration flag (\texttt{ifCal}). One of the key command line
arguments is \texttt{ifAppend}. If \texttt{ifAppend} is set to 0, all CSV cubes will be
created anew---erasing any existing CSV cubes. If \texttt{ifAppend} is set to 1, the list
of indicators being extracted will be appended to the end of an existing CSV file---thus
enabling the concatenation of indicators from multiple scenarios in a single cube. If
running from a Windows command file---the first invocation of \texttt{makCSV} should
set the append parameter to 0, and all subsequent invocations should set the append
parameter to 1. The output directory should be where the GDX files are located and will
also be the location of the output CSV files.

Once the CSV cubes have been created, a new command file will also have
been created the contains the commands to convert the CSV cubes into Excel files,
or, if the Excel files already exist, will 'refresh' the pivot tables contained
in the Excel file. This command file will only work in a Windows-based terminal
window as the commands rely on VB scripts. To invoke the command, simply
type 'baseNamePivot', for example '10x10Pivot'. The command file will have been created by the
'makCSV' program. It will only invoke the appropriate commands for the requested
tables. Sample 'runtab.cmd' files will automatically invoke the command.

The whole system relies on four GAMS files and one 'VBS' file that are typically located in the
'Model' directory. The five files are:

\begin{enumerate}
\item \textbf{makCSV}. \texttt{makCSV.gms} is the master GAMS file that reads the options, invokes the
indicator extraction file (makTab) and creates the 'baseNamePivotPivot.cmd' file.
\item \textbf{makTab}. \texttt{makTAB.gms} is the core GAMS file that will extract the
data from GDX files, create indicators, and save them to the CSV files.
\item \textbf{setupPivot}. \texttt{setupPivot.gms} is invoked by the \texttt{makCSV.gms} to
create the command lines for the 'baseNamePivot.cmd' file. It is a small file
invoked using 'batinclude' with arguments that simplifies the creation of the command file.
\item \textbf{CreatePivot}. \texttt{createPivot.gms} writes the VB script that creates
the Excel files with the built-in pivot tables. It is only invoked for Excel files
that are being created for the first time. Otherwise, the 'refresh' VB script is invoked.
\item \textbf{refresh}. \texttt{refresh.vbs} is a VB script that refreshes a
pivot table in an Excel file (without opening Excel).
\end{enumerate}

\subsection{Standard indicators}

The GAMS file 'makCSV.gms' is the file that contains code to create indicators from
simulation results. It extracts selected model results from a simulation (stored as a
GDX container), creates an indicator (potentially without transformation) and in
most cases will also aggregate across user-defined regions and sectors. Classes of
indicators are stored together in CSV cubes. There are several advantages to
having indicators in separate cubes. First, it keeps the sizes of the CSV files
to a reasonable size; making them easier and quicker to load. Second, the
geometry of the cube can be tailored to specific indicators. For example, macroeconomic
indicators typically do not need sector or other qualifiers. Table~\ref{tab:CSVCubes} describes
the current list of CSV cubes.

The following sections describe each of the indicators. The left-hand side
should be thought of as being indexed by aggregate region ($R$), time and simulation.
Normally each modeled region is mapped to its own aggregate region, but could also
be mapped to a true aggregate region that would be composed of 1 or more modeled regions.
The right-hand side is normally composed of a model indicator. There is often a one-to-one
mapping, i.e. the aggregation is just a simple sum of a model indicator.

\subsubsection{The GDPPop cube}

The formulas below calculate the indicators contained in the \texttt{GDPPop} cube. The
formulas need little explanation. GDP at 2005 PPP exchange rates uses the base year
PPP exchange rate derived from the SSP scenario file. The first two population indicators, \texttt{P1564}
and \texttt{PopT}, refer to the exogenous information that is used as input for
a model simulation. The indicator \texttt{Pop} refers to the population that
emerges from the model. This could differ from \texttt{PopT} depending on the
initial level of the population---though the growth rates should be identical.

\[
\mathit{RGDPMP}_R = \sum_{r \in R} {\mathit{RGDPMP}_r}
\]

\[
\mathit{RGDPMPPPP}_R = \sum_{r \in R} {\mathit{RGDPMP}_r \mathit{PPP}}
=\sum_{r \in R} {\mathit{RGDPMP}_r
	\frac{\mathit{GDPScen}_{\mathit{Mod},\mathit{SSP},\mathit{GDPPPP05},r,t0}}{\mathit{GDPScen}_{\mathit{Mod},\mathit{SSP},\mathit{GDP},r,t0}} }
\]

\[
\mathit{GDPMP}_R = \sum_{r \in R} {\mathit{GDPMP}_r}
\]

\[
\mathit{PGDPMP}_R = \sum_{r \in R} {\mathit{GDPMP}_r} \bigg/ \sum_{r \in R} {\mathit{RGDPMP}_r}
\]

\[
\mathit{P1564}_R = \sum_{r \in R} {\mathit{PopT}_{r,\mathit{P1564}}}
\]

\[
\mathit{PopT}_R = \sum_{r \in R} {\mathit{PopT}_{r,\mathit{PTOTL}}}
\]

\[
\mathit{Pop}_R = \sum_{r \in R} {\mathit{Pop}_{r}}
\]

\[
\mathit{RGDPPC}_R = \sum_{r \in R} {\mathit{RGDPMP}_r} \bigg/ \sum_{r \in R} {\mathit{Pop}_{r}}
\]

The GDP cube also contains some indicators of welfare.
The indicators $\mathit{EV}$, $\mathit{EVG}$ and $\mathit{EVI}$
represent the equivalent variation for households, government and
investment expenditures, respectively. The household welfare indicator
is derived from the indirect utility function for the user-chosen
utility function. Government and investment expenditure functions have
a simple formula for equivalent variation based on the CES preference function.
Note that the model
allows for multiple households, though the standard GTAP database only
includes a single representative household.
The remaining three indicators measure the volume of private,
public and investment expenditures.

\[
\mathit{EV}_R = \sum_{r \in R} \sum_{h} {\mathit{EV}_{r,h}}
\]

\[
\mathit{EVG}_R = \sum_{r \in R} {\mathit{YFD}_{r,\mathit{gov}}
	\frac{\mathit{YFD}_{r,\mathit{gov},t0}}{\mathit{YFD}_{r,\mathit{gov}}}}
\]

\[
\mathit{EVI}_R = \sum_{r \in R} {\mathit{YFD}_{r,\mathit{inv}}
	\frac{\mathit{YFD}_{r,\mathit{inv},t0}}{\mathit{YFD}_{r,\mathit{inv}}}}
\]

\[
\mathit{EVT}_R = \mathit{EV}_R + \mathit{EVG}_R + \mathit{EVI}_R
\]

\[
\mathit{XFD}_R = \sum_{r \in R} \sum_h {\mathit{XFD}_{r,\mathit{h}}}
\]

\[
\mathit{XFDG}_R = \sum_{r \in R} {\mathit{XFD}_{r,\mathit{gov}}}
\]

\[
\mathit{XFDI}_R = \sum_{r \in R} {\mathit{XFD}_{r,\mathit{inv}}}
\]

\subsubsection{The FactP cube}

The \texttt{FactP} cube provides aggregate (or economy-wide) factor prices. The labels
for capital, land and water return are hard-coded. The labels for the aggregate
wages will be the same as the labels for the labor types (e.g. \texttt{nsk} and \texttt{skl}).

\[
\mathit{AW}_{R,l} = \sum_{r \in R} {\sum_a{\mathit{PF}_{r,l,a}\mathit{XF}_{r,l,a}}} \bigg/ \sum_{r \in R} {\sum_a{\mathit{XF}_{r,l,a}}}
\]

\[
\mathit{TRENT}_{R} = \sum_{r \in R} {\sum_a{\mathit{PF}_{r,\mathit{cap},a}\mathit{XF}_{r,\mathit{cap},a}}} \bigg/ \sum_{r \in R} {\sum_a{\mathit{XF}_{r,\mathit{cap},a}}}
\]

\[
\mathit{PTLand}_{R} = \sum_{r \in R} {{\mathit{PTLand}_{r} \mathit{TLand}_{r}}} \bigg/ \sum_{r \in R} {\mathit{TLand}_{r}}
\]

\[
\mathit{PTNRS}_{R} = \sum_{r \in R} {\sum_a{\mathit{PF}_{r,\mathit{nrs},a}\mathit{XF}_{r,\mathit{nrs},a}}} \bigg/ \sum_{r \in R} {\sum_a{\mathit{XF}_{r,\mathit{nrs},a}}}
\]

\[
\mathit{PTH2O}_{R} = \sum_{r \in R} {\sum_a{\mathit{PF}_{r,\mathit{wat},a}\mathit{XF}_{r,\mathit{wat},a}}} \bigg/ \sum_{r \in R} {\sum_a{\mathit{XF}_{r,\mathit{wat},a}}}
\]

\subsubsection{The Kappah cube}

This cube contains only the average rate of transfer between households and
government.\footnote{The main purpose of this is to assess the impacts of the
standard closure rule that has the government deficit fixed and net household
transfers adjust to meet the fiscal target.}

\[
\mathit{Kappah}_{R} = \sum_{r \in R} {\kappa^h_r \mathit{YH}_{r}} \bigg/ \sum_{r \in R} {\mathit{YH}_{r}}
\]

\subsubsection{The RGovShr cube}

This cube contains only the average ratio of real
government expenditure to real GDP.\footnote{In the standard baseline, this
ratio is fixed and drives the growth of real government expenditures.
In shock simulations, the ratio is endogenous and real government
expenditures are fixed to baseline levels.}

\[
\mathit{RGovShr}_{R} = 100 \cdot \sum_{r \in R} {\mathit{XFD}_{r,\mathit{gov}}} \bigg/ \sum_{r \in R} {\mathit{RGDPMP}_{r}}
\]

\clearpage

\begin{table}[H]
\caption{CSV cubes}
\label{tab:CSVCubes}
\begin{center}
\small
\rowcolors{2}{TableOdd}{TableEven}
\rowcolors{1}{}{lightblue}
\begin{tabular}{p{2.0cm} p{13.0cm}}
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
{\normalsize \textbf{\emph{File name}}} & {\normalsize \textbf{\emph{Description}}} \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
GDPPop & Contains GDP and population including: real GDP at market price (\texttt{rgdpmp}),
nominal GDP at market price (\texttt{gdpmp}),
GDP at market price deflator (\texttt{pgdpmp}),
working age population (\texttt{P1564}),
input population (\texttt{PopT}),
simulated population (\texttt{Pop}), and
real GDP per capital (\texttt{rgdppc}). \\
Factp & Contains aggregate factor prices including: wages identified by skill,
capital (\texttt{trent}), land (\texttt{ptland}), natural resources (\texttt{ptnrs}) and water, if available (\texttt{pth2o}). \\
kappah & Contains net direct transfers to housholds as a share of income (\texttt{kappah}). \\
RGovShr & Contains real government expenditures as a share of real GDP (\texttt{rgovshr}). \\
savinv & Contains various indicators relating to savings and investment including: nominal GDP at market price (\texttt{gdpmp}),
real GDP at market price (\texttt{rgdpmp}),
real investment as a share of real GDP (\texttt{rinvshr}),
aggregate real investment (\texttt{rinv}),
aggregate nominal investment (\texttt{inv}),
aggregate nominal household saving (\texttt{savh}),
household savings rate (\texttt{aps}),
nominal government saving (\texttt{savg}),
nominal foreign saving (\texttt{savf}) and
nominal depreciation (\texttt{deprY}). \\
Output & Contains various indicators relating to output: unweighted output (\texttt{xp}),
output weighted by base year prices (\texttt{xpw}),
nominal output (\texttt{xpd}),
output price using unweighted volumes (\texttt{px}),
output price using base year price-weighted volumes (\texttt{pxn}),
GAPS unweighted volume (\texttt{xpg\_GAPS}), and
Envisage output using GAPS base year volume (\texttt{xpg\_Env}). \\
VA & Contains various indicators relating to value added by activity and factor: nominal value added (\texttt{va\_d}),
value added weighted by base year prices (\texttt{va\_n}),
price of value added using base-year price-weighted volumes (\texttt{pva\_n}),
unweighted volumes (\texttt{va}), and
price of value added using unweighted volumes (\texttt{pva}). \\
INV & Contains various indicators relating to investment by sector: volume of sectoral investment (\texttt{inv\_sec}),
nominal investment by sector (\texttt{invd\_sec}),
sectoral share of aggregate nominal investment (\texttt{invd\_shr}),
sectoral share of nominal value added (\texttt{va\_shr}), and
ratio of sectoral investment share and value added share (\texttt{invRatio}). \\
EMI & Contains various indicators relating to greenhouse gas emissions: total emissions (\texttt{emi}),
emissions linked to intermediate and final demand (\texttt{emi\_io}),
emissions linked to factor use (\texttt{emi\_fp}), and
emissions linked to output (\texttt{emi\_xp}). \\
Cost & Contains various indicators relating to decomposing production cost: change in production cost (\texttt{delpx}),
change in output (\texttt{delxp}),
contribution of change in cost arising from change in input price (\texttt{pcshr}),
contribution of change in cost arising from change in technology mix (\texttt{xcshr}), and
cost share of input (\texttt{cshr}). \\
YDecomp & Contains various indicators relating to decomposing GDP growth: nominal GDP at
factor cost (\texttt{gdpfc}),
real GDP at factor cost (\texttt{rgdpfc}),
real GDP at factor cost deflator (\texttt{pgdpfc}),
contribution of GDP growth from factor growth (\texttt{qdel}), and
contribution of GDP growth from factor productivity  (\texttt{ldel}). \\
Trade & Contains various indicators relating to trade: nominal exports (\texttt{exp\_d}),
real exports (\texttt{exp}),
export tax rate (\texttt{etax}),
nominal imports at FOB prices (\texttt{imp\_fob\_d}),
real imports at FOB prices (\texttt{imp\_fob}),
nominal imports at CIF prices (\texttt{imp\_cif\_d}),
real imports at CIF prices (\texttt{imp\_cif})
import tariff (\texttt{mtax}) and
domestic absorption  (\texttt{Absorb}). \\
Lab & Contains various indicators relating to labor markets: labor supply (\texttt{ls}),
wage (\texttt{twage}),
real wage (\texttt{trwage}),
rural to urban migration (\texttt{migr}),
labor supply by zone (\texttt{lsz}),
average wage by zone (\texttt{awage}),
equilibrium wage by zone (\texttt{ewage})
average real wage (\texttt{arwage}) and
average equibrium wage  (\texttt{aewage}). \\
Power & Contains various indicators relating to power: output (\texttt{XP}), and
average cost (\texttt{PX}). \\
\arrayrulecolor{TableBorder}\specialrule{1pt}{0pt}{0pt}
\end{tabular}
\end{center}
\end{table}

\subsubsection{The SavInv cube}

The \texttt{SavInv} cube contains the indicators below. Note that
investment should equal aggregate savings (household, government and foreign)
plus depreciation for any regional aggregation. Moreover, the sum of
foreign saving at the world level should equal 0.

\[
\mathit{RGDPMP}_R = \sum_{r \in R} {\mathit{RGDPMP}_r}
\]

\[
\mathit{GDPMP}_R = \sum_{r \in R} {\mathit{GDPMP}_r}
\]

\[
\mathit{RInvShr}_{R} = 100 \cdot \sum_{r \in R} {\mathit{XFD}_{r,\mathit{inv}}} \bigg/ \sum_{r \in R} {\mathit{RGDPMP}_{r}}
\]

\[
\mathit{RInv}_{R} = \sum_{r \in R} {\mathit{XFD}_{r,\mathit{inv}}}
\]

\[
\mathit{Inv}_{R} = \sum_{r \in R} {\mathit{YFD}_{r,\mathit{inv}}}
\]

\[
\mathit{SavH}_{R} = \sum_{r \in R} {\mathit{S}^h_{r}}
\]

\[
\mathit{SavG}_{R} = \sum_{r \in R} {\mathit{S}^g_{r}}
\]

\[
\mathit{SavF}_{R} = \sum_{r \in R} {\mathit{PW}^{\mathit{sav}}\mathit{S}^f_{r}}
\]

\[
\mathit{DeprY}_{R} = \sum_{r \in R} {\mathit{DeprY}_{r}}
\]

\[
\mathit{APS}_{R} = 100 \cdot \sum_{r \in R} {\mathit{S}^h_{r}}  \bigg/ \sum_{r \in R} {\mathit{YD}_{r}}
\]

\subsubsection{The Output cube}
The output cube contains various indicators related to output. Three
reflect different measures of the level of output---nominal (\texttt{XPD}),
unweighted real (\texttt{XP}) and weighted real (\texttt{XPW}).
For most purposes the appropriate index is the weighted real---particularly
when aggregating across activities using different units. Potential
exceptions are when aggregating energy indicators as these may be
evaluated in the same units, for example MTOE or GWhr.
Similarly there
are two price indices: unweighted (\texttt{PX}) and weighted  (\texttt{PXN}).
The cube also contains the total factor productivity parameter (for installed
or \emph{Old} capital).

\[
\mathit{XP}_{R,A} =
\sum_{r \in R} {\sum_{a \in A} {\mathit{XP}_{r,a}}}
\]

\[
\mathit{XPW}_{R,A} =
\sum_{r \in R} {\sum_{a \in A} {\mathit{PX}_{r,a,0}\mathit{XP}_{r,a}}}
\]

\[
\mathit{XPD}_{R,A} =
\sum_{r \in R} {\sum_{a \in A} {\mathit{PX}_{r,a}\mathit{XP}_{r,a}}}
\]

\[
\mathit{PX}_{R,A} =
\sum_{r \in R} {\sum_{a \in A} {\mathit{PX}_{r,a}\mathit{XP}_{r,a}}}
\bigg/
\sum_{r \in R} {\sum_{a \in A} {\mathit{XP}_{r,a}}}
\]

\[
\mathit{PXN}_{R,A} =
\sum_{r \in R} {\sum_{a \in A} {\mathit{PX}_{r,a}\mathit{XP}_{r,a,0}}}
\bigg/
\sum_{r \in R} {\sum_{a \in A} {\mathit{PX}_{r,a,0} \mathit{XP}_{r,a,0}}}
\]

\[
\mathit{lambdaxpOld}_{R,A} =
\sum_{r \in R} {\sum_{a \in A}
{\lambda^{\mathit{xp}}_{r, a, \mathit{Old}} \mathit{PXv}_{r,a, \mathit{Old},0}\mathit{XPv}_{r,a, \mathit{Old}}}}
\bigg/
\sum_{r \in R} {\mathit{PXv}_{r,a, \mathit{Old},0}\mathit{XPv}_{r,a, \mathit{Old}}}
\]

\noindent [Optional] There are two additional volume indicators linked
to an external estimate of base year volumes.\footnote{This is particularly
useful where the external estimate of base year volumes is in recognizable
units---such as tons, joules, etc.} The first indicator is the external
indicator itself---in its own units and with its own growth trends (e.g. from
an FAO or IEA projection). The second is the growth trend using the Envisage
results but re-based to that of the external data. This allows for easier
comparison of trends between institutions. In the case of the comparison
with the FAO GAPS projections, the FAO projections are labeled \texttt{xpg\_GAPS}
and the Envisage projections are labeled \texttt{xpg\_Env}. Note that the base
years for GAPS and Envisage do not line up (2012 versus 2011), nor do the time
steps line up.

\subsubsection{The VA cube}
The value added cube contains various indicators related to value added. In addition
to the various endowments that are part of the model definition, the indicators
also include aggregations for labor (\texttt{tlab}), all non-labor factors (\texttt{tcap}) and all factors (\texttt{tot}). In most cases, the
$\mathit{VA\_N}$ indicator is the most appropriate for assessing
aggregate value added. The $\mathit{VA}$ indicator can be
used in some cases to evaluate labor in person years
depending on the calibration choices of the user.

\[
\mathit{VA\_D}_{R,A,V} =
\sum_{r \in R} {\sum_{a \in A} {\sum_{f \in V} {\mathit{PF}_{r,f,a}\mathit{XF}_{r,f,a}}}}
\]

\[
\mathit{VA\_N}_{R,A,V} =
\sum_{r \in R} {\sum_{a \in A} {\sum_{f \in V} {\mathit{PF}_{r,f,a,0}\mathit{XF}_{r,f,a}}}}
\]

\[
\mathit{PVA\_N}_{R,A,V} =
\sum_{r \in R} {\sum_{a \in A} {\sum_{f \in V} {\mathit{PF}_{r,f,a}\mathit{XF}_{r,f,a}}}}
\bigg/
\sum_{r \in R} {\sum_{a \in A} {\sum_{f \in V} {\mathit{PF}_{r,f,a,0}\mathit{XF}_{r,f,a}}}}
\]

\[
\mathit{VA}_{R,A,V} =
\sum_{r \in R} {\sum_{a \in A} {\sum_{f \in V} {\mathit{XF}_{r,f,a}}}}
\]

\[
\mathit{PVA}_{R,A,V} =
\sum_{r \in R} {\sum_{a \in A} {\sum_{f \in V} {\mathit{PF}_{r,f,a}\mathit{XF}_{r,f,a}}}}
\bigg/
\sum_{r \in R} {\sum_{a \in A} {\sum_{f \in V} {\mathit{XF}_{r,f,a}}}}
\]

\subsubsection{The INV cube}
The investment cube contains investment by sector---both in volume
and value terms. The formulas take into account multi-year step sizes.
The \texttt{InvRatio} indicator measures an activity's share of investment
relative to its share of value added (in nominal terms).

\[
\mathit{INV\_SEC}_{R,A} =
\sum_{r \in R} {\sum_{a \in A} {
\frac{\delta_{r,t-n}}{1-\left(1-\delta_{r,t-n}\right)^n}\left[
\sum_v{K^v_{r,a,v,t}} - \left(1-\delta_{r,t-n}\right)^n\sum_v{K^v_{r,a,v,t-n}}\right]
\frac{1}{\chi^k_r}
}}
\]

\[
\mathit{INVD\_SEC}_{R,A} =
\sum_{r \in R} {\sum_{a \in A} {
\frac{\delta_{r,t-n}}{1-\left(1-\delta_{r,t-n}\right)^n}\left[
\sum_v{K^v_{r,a,v,t}} - \left(1-\delta_{r,t-n}\right)^n\sum_v{K^v_{r,a,v,t-n}}\right]
\frac{\mathit{PFD}_{r,\mathit{inv},t-n}} {\chi^k_r}
}}
\]

\[
\mathit{INVD\_SHR}_{R,A} = \frac{
\sum_{r \in R} {\sum_{a \in A} {
\frac{\delta_{r,t-n}}{1-\left(1-\delta_{r,t-n}\right)^n}\left[
\sum_v{K^v_{r,a,v,t}} - \left(1-\delta_{r,t-n}\right)^n\sum_v{K^v_{r,a,v,t-n}}\right]
\frac{\mathit{PFD}_{r,\mathit{inv},t-n}} {\chi^k_r}
}}}
{
\sum_{r \in R} {\sum_{a} {
\frac{\delta_{r,t-n}}{1-\left(1-\delta_{r,t-n}\right)^n}\left[
\sum_v{K^v_{r,a,v,t}} - \left(1-\delta_{r,t-n}\right)^n\sum_v{K^v_{r,a,v,t-n}}\right]
\frac{\mathit{PFD}_{r,\mathit{inv},t-n}} {\chi^k_r}
}}}
\]

\[
\mathit{VA\_SHR}_{R,A} = \frac{
\sum_{r \in R} {\sum_{a \in A} {\sum_f{\mathit{PF}_{r,f,a}\mathit{XF}_{r,f,a}}}}}
{
\sum_{r \in R} {\sum_{a} {\sum_f{\mathit{PF}_{r,f,a}\mathit{XF}_{r,f,a}}}}}
\]

\[
\mathit{InvRatio}_{R,A} = \frac{\mathit{INVD\_SHR}_{R,A}}
{\mathit{VA\_SHR}_{R,A}}
\]

\subsubsection{The Emissions cube}

The emissions cube contains 5 indicators:
total emissions, emissions linked to consumption
of intermediate and final demand, emissions
linked to factor-use and emissions linked to
output. Emission indicators are output for all types of emissions. Physical emissions are all
denominated in unit of gigatons.\footnote{Base
non-greenhouse gas emissions are in units
of gigagrams. They are divided by 1000 to
convert to gigatons.}
Greenhouse gases are also output in units
of CEq and CO2eq. If the model uses units
of CEq, CO2eq is calculated by multiplying
the emission level by a factor of 44/12. In
the contrary case, emissions are converted to
CEq using the factor 12/44.


\[
\mathit{Emi}_{R,\mathit{Tot},\mathit{em}}
= \sum_{r \in R} {\mathit{EmiTot}_{r,\mathit{em}}}
\]

\[
\mathit{Emi\_io}_{R,\mathit{A},\mathit{em}}
= \sum_{r \in R} {\sum_{a \in A} {\sum_i {\mathit{Emi}_{r,\mathit{em},i,a}}}}
\]

\[
\mathit{Emi\_io}_{R,\mathit{fd},\mathit{em}}
= \sum_{r \in R} { {\sum_i {\mathit{Emi}_{r,\mathit{em},i,\mathit{fd}}}}}
\]

\[
\mathit{Emi\_fp}_{R,\mathit{A},\mathit{em}}
= \sum_{r \in R} {\sum_{a \in A} {\sum_{\mathit{fp}} {\mathit{Emi}_{r,\mathit{em},\mathit{fp},a}}}}
\]

\[
\mathit{Emi\_xp}_{R,\mathit{A},\mathit{em}}
= \sum_{r \in R} {\sum_{a \in A}  {\mathit{Emi}_{r,\mathit{em},\mathit{Tot},a}}}
\]

\subsubsection{The Trade cube}

The first set of equations relate to exports.
These are aggregated over regions and commodities,
where the index $I$ is an aggregate commodity,
which may be an individually modeled commodity.
The first two measure aggregate exports
by commodity $I$ at current FOB prices and
at constant FOB prices. The third formula
measures the export tax.

\[
\mathit{EXP\_D}_{R,I} =
\sum_{s \in R} {\sum_{i \in I} {
\sum_d
{\mathit{PWE}_{s,i,d} \mathit{XW}_{s,i,d}}
}}
\]

\[
\mathit{EXP}_{R,I} =
\sum_{s \in R} {\sum_{i \in I} {
		\sum_d
		{\mathit{PWE}_{s,i,d,0} \mathit{XW}_{s,i,d}}
}}
\]

\[
\mathit{ETAX}_{R,I} =
100 \cdot \sum_{s \in R} {\sum_{i \in I} {
		\sum_d
		{\mathit{PWE}_{s,i,d} \mathit{XW}_{s,i,d}}
}} \bigg/
\sum_{s \in R} {\sum_{i \in I} {
		\sum_d
		{\mathit{PE}_{s,i,d} \mathit{XW}_{s,i,d}}
}} - 100
\]

The next set of five equations relate to
imports. The first two equations evaluate current
and constant imports at FOB prices, i.e. these indicators
ignore the trade and transport margins.
The next two equations use CIF import prices.
The final equation evaluates the import tariff
in percentage terms.
Note that the variable $\mathit{XW}$ represents
the supply of exports and is adjusted
by the iceberg parameter to convert to demand
for imports.

\[
\mathit{IMP\_FOB\_D}_{R,I} =
\sum_{d \in R} {\sum_{i \in I} {
		\sum_s
		{\mathit{PWE}_{s,i,d} \lambda^w_{s,i,d} \mathit{XW}_{s,i,d}}
}}
\]

\[
\mathit{IMP\_FOB}_{R,I} =
\sum_{d \in R} {\sum_{i \in I} {
		\sum_s
		{\mathit{PWE}_{s,i,d,0} \lambda^w_{s,i,d} \mathit{XW}_{s,i,d}}
}}
\]

\[
\mathit{IMP\_CIF\_D}_{R,I} =
\sum_{d \in R} {\sum_{i \in I} {
		\sum_s
		{\mathit{PWM}_{s,i,d} \lambda^w_{s,i,d} \mathit{XW}_{s,i,d}}
}}
\]

\[
\mathit{IMP\_CIF}_{R,I} =
\sum_{d \in R} {\sum_{i \in I} {
		\sum_s
		{\mathit{PWM}_{s,i,d,0} \lambda^w_{s,i,d} \mathit{XW}_{s,i,d}}
}}
\]

\[
\mathit{MTAX}_{R,I} =
100 \cdot \sum_{d \in R} {\sum_{i \in I} {
		\sum_s
		{\mathit{PDM}_{s,i,d} \lambda^w_{s,i,d} \mathit{XW}_{s,i,d}}
}} \bigg/
\sum_{s \in R} {\sum_{i \in I} {
		\sum_s
		{\mathit{PWM}_{s,i,d} \lambda^w_{s,i,d} \mathit{XW}_{s,i,d}}
}} - 100
\]

Domestic absorption is defined as the sum
of demand by source, i.e. domestic and imported.
Its evaluation depends on the Armington trade
specification. The first formula evaluates
domestic absorption in the case of the agent-specific
Armington specification. The second
formula measures domestic absorption in the case
of the national-agent Armington specification.

\[
\mathit{Absorb}_{R,I} =
\sum_{d \in R} {\sum_{i \in I} {
		\sum_{\mathit{aa}}
		{\gamma^{\mathit{edd}}_{r,i,\mathit{aa}} \mathit{PDT}_{r,i} \mathit{XD}_{r,i,\mathit{aa}} +
			\gamma^{\mathit{edm}}_{r,i,\mathit{aa}} \mathit{PMT}_{r,i} \mathit{XM}_{r,i,\mathit{aa}}
		}
}}
\]

\[
\mathit{Absorb}_{R,I} =
\sum_{d \in R} {\sum_{i \in I} {
		\sum_{\mathit{aa}}
		{\gamma^{\mathit{eda}}_{r,i,\mathit{aa}} \mathit{PAT}_{r,i} \mathit{XA}_{r,i,\mathit{aa}}
		}
}}
\]

\subsection{Calculating the indicators}

Calculating the indicators involves running the \texttt{makCSV} file for each simulation.
The command line arguments are similar to those used to run the simulations themselves.
One key argument is the \texttt{ifAppend} argument. Typically it is set to '0' for the
first simulation and '1' for subsequent simulations. This forces the results to
be concatenated in the CSV cubes. The sequence is easiest to run by using an existing
command file that contains the full suite of commands to create the CSV cubes.
In addition, the command file contains the code to create or refresh the Excel files
and the pivot tables in the Excel file. If the Excel file already exists, the
command file will request a refresh of the pivot table(s). The advantage of this is
that it will preserve any worksheets, charts, tables that a user may have created and
saved using a previous CSV cube. The \texttt{refresh.vbs} script is invoked
to refresh an existing Excel file. If the Excel file does not exist, a new one will be
created with a single pivot table.

\subsection{Creating the Excel files}
The user can request a new Excel file by modifying the code in \texttt{CreatePivot.gms}.
The basic purpose of the GAMS program is to create a Visual Basic script (vbs) that
will automatically create a pivot table in an Excel file based on the relevant
CSV cube. Each cube has its own geometry and there is a set of built-in
geometries in the GAMS file---for example \texttt{VarByCost} or \texttt{VarByActivity}.
When using \texttt{CreatePivot.gms}, a specific geometry must be chosen for each
CSV cube that corresponds to the geometry of the cube. Users are free to add new
geometries, using the existing ones as a guideline. Some of the geometries allow
for labels to be sorted---see for example \texttt{VarByActivity}. The pivot tables
that are created all have two dimensions---a row and a column. The rows will have
the position number 1, columns position number 2, and the values position number 5.
All other dimensions normally default to position number 3. Users can modify the
pivot table geometry once the file has been created (and this will be preserved when
the files are refreshed). It can be convenient to have some of the labels sorted
automatically---though VB script can sometimes be fussy about this. Regions are sorted
in all cases.\footnote{Only the model core regions are sorted, it would be nice to have
sorting for the aggregate regions as well.} Some of the geometries allow for
sorting by either activity or commodity.

\subsection{Installing a 'CSV' driver for Excel}

Creating Pivot tables in Excel requires the installation of the appropriate data base
driver. Most Excel implementations include drivers for Excel and Access files, but
not for CSV files. The so-called ODBC driver can be installed from a package
available from Microsoft at \url{https://www.microsoft.com/en-us/download/details.aspx?id=54920}.\footnote{Last accessed
on 20-Jan-2022} Depending on the computer, it is possible to download either the 32-bit
or 64-bit driver, with, respectively, file names of \texttt{accessdatabaseengine.exe} and
\texttt{accessdatabaseengine\_X64.exe}. Once installed, the user must make the driver 'active'.
To do this, the user enters \texttt{ODBC Data Sources} in the search box of the task
bar. This will open a dialog box that indicates the existing ODBC drivers. If the
\texttt{MS Access Text Driver} is already available, nothing further needs to be done.
If the \texttt{MS Access Text Driver} is not yet available, installation requires
clicking on the \texttt{Add\ldots} button. This should bring up a list of drivers including
\texttt{Microsoft Access Text Driver (*.txt, *.csv)}. Finish entering the required
information---\texttt{Data
Source Name} and \texttt{Description}, for example \emph{MS Access Text Driver} and
\emph{*.txt and *.csv files},
and press the \texttt{OK} button when done. N.B. Some installations may
require Administrator privileges to be able to install an ODBC driver.

\subsection{Creating graphs in R}

A number of R scripts are available to create and save figures automatically. Most
of these will generate a single graph for each region (both model regions and the
agggregate regions) as well as for each simulation. The scripts are designed
to save all the graphs for a simulation in a simulation folder. The scripts have
the following outline:

\begin{itemize}
\item The scripts are called from a command line and the only argument is the name of
CSV cube, for example \texttt{GDPPop}, without the \texttt{.csv} extension.
\item Each script will read a script common to all that sets some global parameters,
such as input and output directories. This common script is called \texttt{PlotOpt.R}. It
normally only needs to be reviewed for a new model configuration.
\item Each script also relies on two user-based files that contain the list of regions
(\texttt{regions.csv}) and the time periods (years.csv). These files are aggregation
specific.
\item The script relies on two libraries---\texttt{sqldf} and \texttt{ggplot2}. The first
allows for reading CSV files as if they are cubes and users can then use the standard
SQL commands to select and filter the incoming data.\footnote{The alternative is to use
the standard \texttt{read.csv} function. The downside to this is that it will read the
entire cube, even if only a small slice is desired.} The graphs are created using
the \texttt{ggplot2} package.
\item The function \texttt{read.csv.sql} is used to read in the CSV cube. This
allows to skip some fields altogether and/or to select specific rows of the cube.
For example, the \texttt{plotRGDPoc.R} script reads only two variables in the
cube---\texttt{Pop} and \texttt{rgdpmp}.\footnote{Unfortunately, \texttt{read.csv.sql}
does not strip double quotes from the incoming cube so the R script has been
designed to handle the string labels with double quotes.}
\item The body of the script loops over all possible simulations and regions and
creates a figure for each combination based on the indicators read in from the CSV
cube.
\item The figures are stored by simulation. If the parent folder is called \texttt{PROJNAME\textbackslash{DOC}} then
the figures will be stored in \texttt{PROJNAME\textbackslash{DOC}\textbackslash{SIM1}}, \texttt{PROJNAME\textbackslash{DOC}\textbackslash{SIM2}}, ...,
\texttt{PROJNAME\textbackslash{DOC}\textbackslash{SIMn}}. There could be other ways to organize the folder structure depending
on the specific needs of the user.
\end{itemize}

\noindent Running of the scripts can be automated. See for example the file
\texttt{plotAll.cmd}.




